{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Transformations d'ensembles de données\n",
    "\n",
    "scikit-learn fournit une bibliothèque de transformateurs, qui peuvent nettoyer (voir [6.3. Prétraitement des données](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)), réduire (voir [6.5. Réduction de dimensionnalité non supervisée](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction)), étendre (voir [6.7. Approximation du noyau](https://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation)) ou générer (voir [6.2. Extraction de caractéristiques](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction)) des représentations d'entités.\n",
    "\n",
    "Comme d'autres estimateurs, ceux-ci sont représentés par des classes avec une méthode d'ajustement `fit`, qui apprend les paramètres du modèle (par exemple, la moyenne et l'écart type pour la normalisation) à partir d'un ensemble d'apprentissage, et une méthode de transformation `transform` qui applique ce modèle de transformation à de nouvelles données. `fit_transform` peut être plus pratique et efficace pour modéliser et transformer simultanément les données d'apprentissage.\n",
    "\n",
    "La combinaison de tels transformateurs, en parallèle ou en série, est traitée dans [6.1. Pipelines et estimateurs composites](https://scikit-learn.org/stable/modules/compose.html#combining-estimators). [6.8. Les métriques par paires, es Affinités et les Noyaux](https://scikit-learn.org/stable/modules/metrics.html#metrics) couvrent la transformation des espaces de caractéristiques en matrices d'affinité, tandis que la [6.9. transformation de la cible de prédiction (y)](https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets) considère les transformations de l'espace cible (par exemple, les étiquettes catégorielles) à utiliser dans scikit-learn.\n",
    "\n",
    "✔ 6.1. Pipelines et estimateurs composites\n",
    "* ✔ 6.1.1. Pipeline : estimateurs de chaînage\n",
    "* ✔ 6.1.2. Transformer la cible en régression\n",
    "* ✔ 6.1.3. FeatureUnion : espaces d'entités composites\n",
    "* ✔ 6.1.4. ColumnTransformer pour les données hétérogènes\n",
    "* ✔ 6.1.5. Visualisation des estimateurs composites\n",
    "\n",
    "✔ 6.2. Extraction de caractéristiques\n",
    "* ✔ 6.2.1. Chargement de caractéristiques à partir de dicts\n",
    "* ✔ 6.2.2. Hachage des caractéristiques\n",
    "* ✔ 6.2.3. Extraction de caractéristiques de texte\n",
    "* ✔ 6.2.4. Extraction de caractéristiques d'image\n",
    "\n",
    "6.3. Prétraitement des données\n",
    "* 6.3.1. Standardisation, ou suppression de la moyenne et mise à l'échelle de la variance\n",
    "* 6.3.2. Transformation non linéaire\n",
    "* 6.3.3. Normalisation\n",
    "* ✔ 6.3.4. Encodage des caractéristiques catégorielles\n",
    "* 6.3.5. Discrétisation\n",
    "* 6.3.6. Imputation des valeurs manquantes\n",
    "* 6.3.7. Génération de caractéristiques polynomiales\n",
    "* 6.3.8. Transformateurs personnalisés\n",
    "\n",
    "6.4. Imputation des valeurs manquantes\n",
    "* 6.4.1. Imputation univariée vs imputation multivariée\n",
    "* 6.4.2. Imputation de caractéristique univariée\n",
    "* 6.4.3. Imputation de caractéristiques multivariées\n",
    "* 6.4.4. Références\n",
    "* 6.4.5. Imputation des plus proches voisins\n",
    "* 6.4.6. Marquage des valeurs imputées\n",
    "* 6.4.7. Estimateurs qui gèrent les valeurs NaN\n",
    "\n",
    "6.5. Réduction de dimensionnalité non supervisée\n",
    "* 6.5.1. ACP : analyse en composantes principales\n",
    "* 6.5.2. Projections aléatoires\n",
    "* 6.5.3. Agglomération de caractéristiques\n",
    "\n",
    "6.6. Projection aléatoire\n",
    "* 6.6.1. Le lemme de Johnson-Lindenstrauss\n",
    "* 6.6.2. Projection aléatoire gaussienne\n",
    "* 6.6.3. Projection aléatoire clairsemée\n",
    "* 6.6.4. Transformation inverse\n",
    "\n",
    "6.7. Approximation du noyau\n",
    "* 6.7.1. Méthode Nystroem pour l'approximation du noyau\n",
    "* 6.7.2. Noyau de fonction de base radiale\n",
    "* 6.7.3. Additif Chi Squared Kernel\n",
    "* 6.7.4. Noyau au carré de chi asymétrique\n",
    "* 6.7.5. Approximation du noyau polynomial via Tensor Sketch\n",
    "* 6.7.6. Détails mathématiques\n",
    "\n",
    "6.8. Métriques par paires, affinités et noyaux\n",
    "* 6.8.1. Similitude cosinus\n",
    "* 6.8.2. Noyau linéaire\n",
    "* 6.8.3. Noyau polynomial\n",
    "* 6.8.4. Noyau sigmoïde\n",
    "* 6.8.5. Noyau RBF\n",
    "* 6.8.6. Noyau laplacien\n",
    "* 6.8.7. Noyau du chi carré\n",
    "\n",
    "✔ 6.9. Transformer la cible de prédiction (y)\n",
    "* ✔ 6.9.1. Binarisation des étiquettes\n",
    "* ✔ 6.9.2. Encodage des étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.9. Transformer la cible de prédiction (y) | Transforming the prediction target (y)\n",
    "\n",
    "Ce sont des transformateurs qui ne sont pas destinés à être utilisés sur des caractéristiques, uniquement sur des cibles d'apprentissage supervisé. Voir aussi [6.1. Transformer la cible en régression](https://scikit-learn.org/stable/modules/compose.html#transformed-target-regressor) si vous souhaitez transformer la cible de prédiction pour l'apprentissage, mais évaluer le modèle dans l'espace d'origine (non transformé)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9.1. Binarisation des étiquettes | Label binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9.1.1. LabelBinarizer\n",
    "\n",
    "[`LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer) est une classe utilitaire permettant de créer une [matrice d'indicateurs d'étiquettes](https://scikit-learn.org/stable/glossary.html#term-label-indicator-matrix) à partir d'une liste d'étiquettes [multiclasses](https://scikit-learn.org/stable/glossary.html#term-multiclass) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([1, 2, 6, 4, 2])\n",
    "# LabelBinarizer()\n",
    "lb.classes_\n",
    "# array([1, 2, 4, 6])\n",
    "lb.transform([1, 6])\n",
    "# array([[1, 0, 0, 0],\n",
    "#       [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de ce format peut permettre une classification multiclasse dans les estimateurs qui prennent en charge le format de matrice d'indicateur d'étiquette.\n",
    "\n",
    "**Avertissement** : LabelBinarizer n'est pas nécessaire si vous utilisez un estimateur qui prend déjà en charge les données [multiclasses](https://scikit-learn.org/stable/glossary.html#term-multiclass).\n",
    "\n",
    "Pour plus d'informations sur la classification multiclasse, reportez-vous à la section [1.12.1. Classification multiclasse](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9.1.2. MultiLabelBinarizer\n",
    "\n",
    "Dans l'apprentissage [multiétiquette](https://scikit-learn.org/stable/glossary.html#term-multilabel), l'ensemble conjoint de tâches de classification binaire est exprimé avec un tableau d'indicateurs binaires d'étiquette : chaque échantillon est une ligne d'un tableau 2d de forme `(n_échantillons, n_classes)` avec des valeurs binaires où l'un, c'est-à-dire les éléments non nuls, correspond au sous-ensemble d'étiquettes pour cet échantillon. Un tableau tel que `np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])` représente l'étiquette 0 dans le premier échantillon, les étiquettes 1 et 2 dans le deuxième échantillon, et aucune étiquette dans le troisième échantillon.\n",
    "\n",
    "La production de données multiétiquettes sous la forme d'une liste d'ensembles d'étiquettes peut être plus intuitive. Le transformateur [`MultiLabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer) peut être utilisé pour convertir entre une collection de collections d'étiquettes et le format d'indicateur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[2, 3, 4], [2], [0, 1, 3], [0, 1, 2, 3, 4], [0, 1, 2]]\n",
    "MultiLabelBinarizer().fit_transform(y)\n",
    "# array([[0, 0, 1, 1, 1],\n",
    "#        [0, 0, 1, 0, 0],\n",
    "#        [1, 1, 0, 1, 0],\n",
    "#        [1, 1, 1, 1, 1],\n",
    "#        [1, 1, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour plus d'informations sur la classification multiétiquette, reportez-vous à la section [1.12.2. Classification multiétiquette](https://scikit-learn.org/stable/modules/multiclass.html#multilabel-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9.2. Encodage des étiquettes | Label encoding\n",
    "\n",
    "[`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) est une classe utilitaire permettant de normaliser les étiquettes de sorte qu'elles ne contiennent que des valeurs comprises entre 0 et n_classes-1. Ceci est parfois utile pour écrire des routines Cython efficaces. [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) peut être utilisé comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "# LabelEncoder()\n",
    "le.classes_\n",
    "# array([1, 2, 6])\n",
    "le.transform([1, 1, 2, 6])\n",
    "# array([0, 0, 1, 2])\n",
    "le.inverse_transform([0, 0, 1, 2])\n",
    "# array([1, 1, 2, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il peut également être utilisé pour transformer des étiquettes non numériques (tant qu'elles sont hachables et comparables) en étiquettes numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "# LabelEncoder()\n",
    "list(le.classes_)\n",
    "# ['amsterdam', 'paris', 'tokyo']\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
    "# array([2, 2, 1])\n",
    "list(le.inverse_transform([2, 2, 1]))\n",
    "# ['tokyo', 'tokyo', 'paris']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

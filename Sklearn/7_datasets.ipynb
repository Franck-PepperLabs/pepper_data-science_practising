{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\\. [**Utilitaires de chargement de jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb)</br>([*Dataset loading utilities*](https://scikit-learn.org/stable/datasets.html))\n",
    "\n",
    "Le package `sklearn.datasets` intègre certains petits jeux de données de démonstration, comme introduits dans la section [**Premiers pas**](https://scikit-learn.org/stable/tutorial/basic/tutorial.html#loading-example-dataset).\n",
    "\n",
    "Ce package propose également des fonctions d'aide pour télécharger des jeux de données plus volumineux, couramment utilisés par la communauté de l'apprentissage automatique pour évaluer les algorithmes sur des données provenant du \"monde réel\".\n",
    "\n",
    "Pour évaluer l'impact de l'échelle du jeu de données (`n_samples` et `n_features`) tout en contrôlant les propriétés statistiques des données (typiquement la corrélation et l'informativité des caractéristiques), il est également possible de générer des données synthétiques.\n",
    "\n",
    "**API générale des jeux de données.** Il existe trois principaux types d'interfaces de jeux de données qui peuvent être utilisées pour obtenir des jeux de données en fonction du type souhaité.\n",
    "\n",
    "**Les chargeurs de jeux de données.** Ils permettent de charger de petits jeux de données standard, décrits dans la section [**Jeux de données jouets** (7.1)](https://scikit-learn.org/stable/datasets/toy_dataset.html).\n",
    "\n",
    "**Les téléchargeurs de jeux de données.** Ils permettent de télécharger et de charger des jeux de données plus volumineux, décrits dans la section [**Jeux de données du monde réel** (7.2)](https://scikit-learn.org/stable/datasets/real_world.html).\n",
    "\n",
    "Les fonctions de chargeurs et de téléchargeurs renvoient toutes deux un objet [**`Bunch`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html) contenant au moins deux éléments : un tableau de forme `n_samples * n_features` avec la clé `data` (sauf pour `20newsgroups`) et un tableau Numpy de longueur `n_samples` contenant les valeurs cibles, avec la clé `target`.\n",
    "\n",
    "L'objet Bunch est un dictionnaire qui expose ses clés en tant qu'attributs. Pour plus d'informations sur l'objet Bunch, consultez la documentation sur [**`Bunch`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html).\n",
    "\n",
    "Il est également possible, pour presque toutes ces fonctions, de contraindre la sortie à être un tuple contenant uniquement les données et la cible, en définissant le paramètre `return_X_y` sur `True`.\n",
    "\n",
    "Les jeux de données contiennent également une description complète dans leur attribut `DESCR` et certains contiennent `feature_names` et `target_names`. Consultez les descriptions des jeux de données ci-dessous pour plus de détails.\n",
    "\n",
    "**Les fonctions de génération de jeux de données.** Elles permettent de générer des jeux de données synthétiques contrôlés, décrits dans la section [**Jeux de données générés** (7.3)](https://scikit-learn.org/stable/datasets/sample_generators.html).\n",
    "\n",
    "Les fonctions de génération de jeux de données. Elles peuvent être utilisées pour générer des jeux de données synthétiques contrôlés, décrits dans la section \"Jeux de données générés\".\n",
    "\n",
    "Ces fonctions renvoient un tuple `(X, y)` composé d'un tableau Numpy `X` de forme `n_samples * n_features` et d'un tableau de longueur `n_samples` contenant les cibles `y`.\n",
    "\n",
    "De plus, il existe également des outils divers pour charger des jeux de données au format ou à partir d'emplacements autres, décrits dans la section [**Chargement d'autres jeux de données**](https://scikit-learn.org/stable/datasets/loading_other_datasets.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Volume** : 35 pages, x exemples\n",
    "* **Reste** : 35 pages, x exemples\n",
    "\n",
    "✘ 7.1. [**Jeux de données jouets**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#toy_dataset)\n",
    "([*Toy datasets*](https://scikit-learn.org/stable/datasets/toy_dataset.html))\n",
    "* **Volume** : 11 pages, x exemples\n",
    "* **Reste** : 11 pages, x exemples\n",
    "* ✘ 7.1.1. [**Jeu de données des prix des maisons de Boston**]()\n",
    "([*Boston house prices dataset*]())\n",
    "* ✘ 7.1.2. [**Jeu de données des plantes d'Iris**]()\n",
    "([*Iris plants dataset*]())\n",
    "* ✘ 7.1.3. [**Jeu de données sur le diabète**]()\n",
    "([*Diabetes dataset*]())\n",
    "* ✘ 7.1.4. [**Jeu de données de reconnaissance optique de chiffres écrits à la main**]()\n",
    "([*Optical recognition of handwritten digits dataset*]())\n",
    "* ✘ 7.1.5. [**Jeu de données de Linnerrud**]()\n",
    "([*Linnerrud dataset*]())\n",
    "* ✘ 7.1.6. [**Jeu de données de reconnaissance de vins**]()\n",
    "([*Wine recognition dataset*]())\n",
    "* ✘ 7.1.7. [**Jeu de données du Wisconsin pour le diagnostic du cancer du sein**]()\n",
    "([*Breast cancer wisconsin (diagnostic) dataset*]())\n",
    "\n",
    "✘ 7.2. [**Jeux de données du monde réel**]()\n",
    "([*Real world datasets*]())\n",
    "* **Volume** : 15 pages, x exemples\n",
    "* **Reste** : 15 pages, x exemples\n",
    "* ✘ 7.2.1. [**Jeu de données des visages Olivetti**]()\n",
    "([*The Olivetti faces dataset*]())\n",
    "* ✘ 7.2.2. [**Jeu de données de texte des 20 newsgroups**]()\n",
    "([*The 20 newsgroups text dataset*]())\n",
    "* ✘ 7.2.3. [**Jeu de données de reconnaissance faciale Labeled Faces in the Wild**]()\n",
    "([*The Labeled Faces in the Wild face recognition dataset*]())\n",
    "* ✘ 7.2.4. [**Jeu de données des types de couverture forestière**]()\n",
    "([*Forest covertypes*]())\n",
    "* ✘ 7.2.5. [**Jeu de données RCV1**]()\n",
    "([*RCV1 dataset*]())\n",
    "* ✘ 7.2.6. [**Jeu de données Kddcup 99**]()\n",
    "([*Kddcup 99 dataset*]())\n",
    "* ✘ 7.2.7. [**Jeu de données de l'immobilier californien**]()\n",
    "([*California Housing dataset*]())\n",
    "\n",
    "✘ 7.3. [**Jeux de données générés**]()\n",
    "([*Generated datasets*]())\n",
    "* **Volume** : 3 pages, x exemples\n",
    "* **Reste** : 3 pages, x exemples\n",
    "* ✘ 7.3.1. [**Générateurs pour la classification et le clustering**]()\n",
    "([*Generators for classification and clustering*]())\n",
    "* ✘ 7.3.2. [**Générateurs pour la régression**]()\n",
    "([*Generators for regression*]())\n",
    "* ✘ 7.3.3. [**Générateurs pour l'apprentissage de variétés**]()\n",
    "([*Generators for manifold learning*]())\n",
    "* ✘ 7.3.4. [**Générateurs pour la décomposition**]()\n",
    "([*Generators for decomposition*]())\n",
    "\n",
    "✘ 7.4. [**Chargement d'autres jeux de données**]()\n",
    "([*Loading other datasets*]())\n",
    "* **Volume** : 6 pages, x exemples\n",
    "* **Reste** : 6 pages, x exemples\n",
    "* ✘ 7.4.1. [**Images d'exemple**]()\n",
    "([*Sample images*]())\n",
    "* ✘ 7.4.2. [**Jeux de données au format svmlight / libsvm**]()\n",
    "([*Datasets in svmlight / libsvm format*]())\n",
    "* ✘ 7.4.3. [**Téléchargement de jeux de données depuis le dépôt openml.org**]()\n",
    "([*Downloading datasets from the openml.org repository*]())\n",
    "* ✘ 7.4.4. [**Chargement depuis des jeux de données externes**]()\n",
    "([*Loading from external datasets*]())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toy-datasets'></a> 7.1. Jeux de données jouets\n",
    "\n",
    "scikit-learn est livré avec quelques petits jeux de données standards qui ne nécessitent pas de téléchargement depuis un site externe.\n",
    "\n",
    "Ils peuvent être chargés à l'aide des fonctions suivantes :\n",
    "\n",
    "* [**`load_iris`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données iris (classification) [40 exemples].\n",
    "* [**`load_diabetes`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)`(*[, return_X_y, as_frame, scaled])` : Charge et renvoie le jeu de données diabetes (régression) [15 exemples].\n",
    "* [**`load_digits`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)`(*[, n_class, return_X_y, as_frame])` : Charge et renvoie le jeu de données digits (classification) [27 exemples].\n",
    "* [**`load_linnerud**`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données Linnerud sur l'exercice physique [aucun exemple].\n",
    "* [**`load_wine`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données wine (classification) [3 exemples].\n",
    "* [**`load_breast_cancer`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données breast cancer wisconsin (classification) [3 exemples].\n",
    "\n",
    "Ces jeux de données sont utiles pour illustrer rapidement le comportement des différents algorithmes implémentés dans scikit-learn. Cependant, ils sont souvent trop petits pour être représentatifs des tâches d'apprentissage automatique du monde réel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='iris-plants-dataset'></a> 7.1.1. Jeu de données des plantes Iris\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 150 (50 dans chacune des trois classes)\n",
    "* **Nombre d'attributs** : 4 attributs numériques prédictifs et la classe\n",
    "* **Informations sur les attributs** :\n",
    "    * longueur du sépale en cm\n",
    "    * largeur du sépale en cm\n",
    "    * longueur du pétale en cm\n",
    "    * largeur du pétale en cm\n",
    "    * classe :\n",
    "        * Iris-Setosa\n",
    "        * Iris-Versicolour\n",
    "        * Iris-Virginica\n",
    "* **Statistiques sommaires** :\n",
    "    * longueur du sépale : 4.3, 7.9, 5.84, 0.83, 0.7826\n",
    "    * largeur du sépale : 2.0, 4.4, 3.05, 0.43, -0.4194\n",
    "    * longueur du pétale : 1.0, 6.9, 3.76, 1.76, 0.9490  (élevé !)\n",
    "    * largeur du pétale : 0.1, 2.5, 1.20, 0.76, 0.9565  (élevé !)\n",
    "* **Valeurs manquantes** : Aucune\n",
    "* **Répartition des classes** : 33,3 % pour chacune des 3 classes.\n",
    "* **Créateur** : R.A. Fisher\n",
    "* **Donateur** : Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
    "* **Date** : Juillet 1988\n",
    "\n",
    "La célèbre [base de données Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set), utilisée pour la première fois par Sir [R.A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher). Le jeu de données est extrait de l'article de Fisher. Notez qu'il est identique à celui utilisé dans R, mais différent de celui du référentiel [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), qui comporte deux points de données incorrects.\n",
    "\n",
    "Il s'agit peut-être de la base de données la plus connue dans la littérature de la reconnaissance de formes. L'article de Fisher est un classique dans le domaine et est encore fréquemment cité à ce jour (voir, par exemple, Duda & Hart). Le jeu de données contient 3 classes de 50 instances chacune, où chaque classe correspond à un type de plante iris. Une classe est linéairement séparable des deux autres ; ces dernières ne sont PAS linéairement séparables entre elles.\n",
    "\n",
    "### Références\n",
    "\n",
    "* Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); également dans \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\n",
    "* Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley & Sons. ISBN 0-471-22361-1. Voir la page 218.\n",
    "* Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='diabetes-dataset'></a> 7.1.2. Jeu de données sur le diabète\n",
    "\n",
    "Dix variables de base, l'âge, le sexe, l'indice de masse corporelle, la pression artérielle moyenne et six mesures de sérum sanguin, ont été obtenues pour chacun des n = 442 patients atteints de diabète, ainsi que la variable d'intérêt, une mesure quantitative de la progression de la maladie un an après le début.\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 442\n",
    "* **Nombre d'attributs** : Les 10 premières colonnes sont des valeurs prédictives numériques\n",
    "* **Cible** : La colonne 11 est une mesure quantitative de la progression de la maladie un an après le début\n",
    "* **Informations sur les attributs** :\n",
    "    * âge en années\n",
    "    * sexe\n",
    "    * indice de masse corporelle (IMC)\n",
    "    * pression artérielle moyenne\n",
    "    * s1 tc, cholestérol total du sérum sanguin\n",
    "    * s2 ldl, lipoprotéines de basse densité (LDL)\n",
    "    * s3 hdl, lipoprotéines de haute densité (HDL)\n",
    "    * s4 tch, cholestérol total / HDL\n",
    "    * s5 ltg, possiblement le logarithme du niveau de triglycérides sériques\n",
    "    * s6 glu, taux de sucre dans le sang\n",
    "\n",
    "Remarque : Chacune de ces 10 variables prédictives a été centrée sur la moyenne et mise à l'échelle par l'écart-type multiplié par la racine carrée de `n_samples` (c'est-à-dire que la somme des carrés de chaque colonne est égale à 1).\n",
    "\n",
    "URL source : https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "\n",
    "Pour plus d'informations, voir : Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (avec discussion), 407-499. (https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='optical-recognition-of-handwritten-digits-dataset'></a> 7.1.3. Jeu de données de reconnaissance optique des chiffres manuscrits\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 1797\n",
    "* **Nombre d'attributs** : 64\n",
    "* **Informations sur les attributs** : Image 8x8 de pixels entiers dans la plage de 0 à 16.\n",
    "* **Valeurs d'attributs manquantes** : Aucune\n",
    "* **Créateur** : Alpaydin (alpaydin ‘@’ boun.edu.tr)\n",
    "* **Date** : Juillet 1998\n",
    "\n",
    "Il s'agit d'une copie de l'ensemble de test des jeux de données de chiffres manuscrits de l'UCI ML (https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "Le jeu de données contient des images de chiffres manuscrits : 10 classes où chaque classe correspond à un chiffre.\n",
    "\n",
    "Des programmes de prétraitement mis à disposition par le NIST ont été utilisés pour extraire des images normalisées de chiffres manuscrits à partir d'un formulaire pré-imprimé. Sur un total de 43 personnes, 30 ont contribué à l'ensemble d'entraînement et 13 autres à l'ensemble de test. Les images de 32x32 pixels sont divisées en blocs non superposés de 4x4 pixels et le nombre de pixels allumés est compté dans chaque bloc. Cela génère une matrice d'entrée de 8x8 où chaque élément est un entier dans la plage de 0 à 16. Cela réduit la dimensionnalité et confère une invariance aux petites distorsions.\n",
    "\n",
    "Pour plus d'informations sur les routines de prétraitement du NIST, voir M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.\n",
    "\n",
    "### Références\n",
    "\n",
    "* C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their Applications to Handwritten Digit Recognition, MSc Thesis, Institute of Graduate Studies in Science and Engineering, Bogazici University.\n",
    "* Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
    "* Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionality reduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.\n",
    "* Claudio Gentile. A New Approximate Maximal Margin Classification Algorithm. NIPS. 2000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='linnerrud-dataset'></a> 7.1.4. Jeu de données Linnerrud\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 20\n",
    "* **Nombre d'attributs** : 3\n",
    "* **Valeurs d'attributs manquantes** : Aucune\n",
    "\n",
    "Le jeu de données Linnerrud est un jeu de données de régression multi-sortie. Il se compose de trois variables d'exercice (données) et de trois variables physiologiques (cibles) collectées auprès de vingt hommes d'âge moyen dans un club de fitness :\n",
    "* **Physiologique - Fichier CSV contenant 20 observations sur 3 variables physiologiques** :\n",
    "    * Poids, Tour de taille et Pouls.\n",
    "* **Exercice - Fichier CSV contenant 20 observations sur 3 variables d'exercice** :\n",
    "    * Tractions, Redressements assis et Sauts.\n",
    "\n",
    "### Références\n",
    "\n",
    "* Tenenhaus, M. (1998). La régression PLS : théorie et pratique. Paris : Éditions Technic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='wine-recognition-dataset'></a> 7.1.5. Jeu de données Wine Recognition\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "- **Nombre d'instances** : 178\n",
    "- **Nombre d'attributs** : 13 (numériques) + la classe\n",
    "- **Information sur les attributs**\n",
    "    - Les attributs représentent différentes mesures chimiques des vins.\n",
    "    - Alcohol (Alcool)\n",
    "    - Malic acid (Acide malique)\n",
    "    - Ash (Cendres)\n",
    "    - Alcalinity of ash (Alcalinité des cendres)\n",
    "    - Magnesium (Magnésium)\n",
    "    - Total phenols (Phénols totaux)\n",
    "    - Flavanoids (Flavonoïdes)\n",
    "    - Nonflavanoid phenols (Phénols non flavonoïdes)\n",
    "    - Proanthocyanins (Proanthocyanidines)\n",
    "    - Color intensity (Intensité de la couleur)\n",
    "    - Hue (Teinte)\n",
    "    - OD280/OD315 of diluted wines (OD280/OD315 des vins dilués)\n",
    "    - Proline\n",
    "- Il n'y a aucune valeur manquante dans le jeu de données.\n",
    "- **Répartition des classes** : class_0 (59), class_1 (71), class_2 (48).\n",
    "\n",
    "**Résumé statistique** :\n",
    "|Attribut|Minimum|Maximum|Moyenne|Écart type|\n",
    "|---|---|---|---|---|\n",
    "|Alcohol|11.0|14.8|13.0|0.8|\n",
    "|Malic Acid|0.74|5.80|2.34|1.12|\n",
    "|Ash|1.36|3.23|2.36|0.27|\n",
    "|Alcalinity of Ash|10.6|30.0|19.5|3.3|\n",
    "|Magnesium|70.0|162.0|99.7|14.3|\n",
    "|Total Phenols|0.98|3.88|2.29|0.63|\n",
    "|Flavanoids|0.34|5.08|2.03|1.00|\n",
    "|Nonflavanoid Phenols|0.13|0.66|0.36|0.12|\n",
    "|Proanthocyanins|0.41|3.58|1.59|0.57|\n",
    "|Colour Intensity|1.3|13.0|5.1|2.3|\n",
    "|Hue|0.48|1.71|0.96|0.23|\n",
    "|OD280/OD315 of diluted wines|1.27|4.00|2.61|0.71|\n",
    "|Proline|278|1680|746|315|\n",
    "\n",
    "Ce jeu de données est une copie des ensembles de données UCI ML Wine Recognition (https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data). Il présente les résultats d'une analyse chimique de vins cultivés dans la même région en Italie par trois producteurs différents. Il existe treize mesures différentes pour les différents constituants des trois types de vin.\n",
    "\n",
    "### Références\n",
    "\n",
    "- Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.\n",
    "- Lichman, M. (2013). UCI Machine Learning Repository [https://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "- S. Aeberhard, D. Coomans and O. de Vel, Comparison of Classifiers in High Dimensional Settings, Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Technometrics).\n",
    "- S. Aeberhard, D. Coomans and O. de Vel, “THE CLASSIFICATION PERFORMANCE OF RDA” Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Journal of Chemometrics)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='wine-recognition-dataset'></a> 7.1.6. Jeu de données du cancer du sein du Wisconsin (diagnostic)\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "- **Nombre d'instances** : 569\n",
    "- **Nombre d'attributs** : 30 attributs numériques prédictifs et la classe\n",
    "- **Informations sur les attributs** :\n",
    "    - rayon (moyenne des distances du centre aux points sur le périmètre)\n",
    "    - texture (écart-type des valeurs d'échelle de gris)\n",
    "    - périmètre\n",
    "    - surface\n",
    "    - lissage (variation locale des longueurs de rayon)\n",
    "    - compacité (périmètre^2 / surface - 1.0)\n",
    "    - concavité (gravité des parties concaves du contour)\n",
    "    - points concaves (nombre de parties concaves du contour)\n",
    "    - symétrie\n",
    "    - dimension fractale (\"approximation de la ligne côtière\" - 1)\n",
    "\n",
    "Les moyennes, les erreurs standard et les \"pires\" ou les plus grandes valeurs (moyenne des trois pires/plus grandes valeurs) de ces caractéristiques ont été calculées pour chaque image, donnant ainsi 30 caractéristiques. Par exemple, le champ 0 correspond au rayon moyen, le champ 10 au rayon SE et le champ 20 au pire rayon.\n",
    "\n",
    "- **Classes** :\n",
    "    - WDBC-Maligne\n",
    "    - WDBC-Bénigne\n",
    "- **Valeurs manquantes d'attributs** : Aucune\n",
    "- **Répartition des classes** :\n",
    "    - 212 - Maligne\n",
    "    - 357 - Bénigne\n",
    "- **Créateurs** :\n",
    "    - Dr. William H. Wolberg\n",
    "    - W. Nick Street\n",
    "    - Olvi L. Mangasarian\n",
    "- **Donateur** : Nick Street\n",
    "- **Date** : Novembre 1995\n",
    "\n",
    "Il s'agit d'une copie des ensembles de données [UCI ML Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). Les caractéristiques sont calculées à partir d'une image numérisée d'une aspiration à l'aiguille fine (FNA) d'une masse mammaire. Elles décrivent les caractéristiques des noyaux cellulaires présents dans l'image.\n",
    "\n",
    "Le plan de séparation décrit ci-dessus a été obtenu à l'aide de la méthode Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], une méthode de classification qui utilise la programmation linéaire pour construire un arbre de décision. Les caractéristiques pertinentes ont été sélectionnées en effectuant une recherche exhaustive dans l'espace des 1 à 4 caractéristiques et des 1 à 3 plans de séparation.\n",
    "\n",
    "Le programme linéaire réel utilisé pour obtenir le plan de séparation dans l'espace tridimensionnel est décrit dans : - - [K. P. Bennett et O. L. Mangasarian : \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "Cette base de données est également disponible via le serveur FTP de l'UW CS :\n",
    "\n",
    "    ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "### Références\n",
    "\n",
    "- W.N. Street, W.H. Wolberg et O.L. Mangasarian. Extraction de caractéristiques nucléaires pour le diagnostic des tumeurs mammaires. IS&T/SPIE 1993 Symposium international sur l'imagerie électronique : science et technologie, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "- O.L. Mangasarian, W.N. Street et W.H. Wolberg. Diagnostic et pronostic du cancer du sein par programmation linéaire. Operations Research, 43(4), pages 570-577, juillet-août 1995.\n",
    "- W.H. Wolberg, W.N. Street et O.L. Mangasarian. Techniques d'apprentissage automatique pour diagnostiquer le cancer du sein à partir d'aspirations à l'aiguille fine. Cancer Letters 77 (1994) 163-171."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

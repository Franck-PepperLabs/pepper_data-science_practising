{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours\n",
    "\n",
    "OC DS P4 - 4297211 [Entraînez un modèle prédictif linéaire](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Contrôlez la complexité de votre modèle\n",
    "\n",
    "Inconvénients de la régression linéaire :\n",
    "* coefficients corrélés ⇒ coefficients peu stables ⇒ interprétation compliquée\n",
    "* nombre de variables $p$ > nombre d’observations $n$ : $X^\\top X$ non inversible ⇒ solution non unique ⇒ pbs de surapprentissage\n",
    "\n",
    "Solution : **régularisation** : au terme d’erreur à minimiser (somme des carrés), on ajoute un terme, dit de régularisation, qui mesure la complexité du modèle.\n",
    "\n",
    "⇒ comment définir précisément ce terme ?\n",
    "\n",
    "Rappel : plus un modèle est complexe plus il court le risque du sur-apprentissage.\n",
    "\n",
    "La méthode consiste à compléter le terme à minimiser $(y - X\\beta)^\\top (y - X \\beta)$ des moindres carrés ordinaires par un terme d'erreur qui est une mesure de la complexité du système, pour former une nouvelle fonction objective à minimiser :\n",
    "\n",
    "$\\arg \\min_{\\beta \\in \\mathbb{R}^{p+1}} \\left((y - X\\beta)^\\top (y - X \\beta) + \\lambda \\text{ Regularisateur}(\\beta)\\right)$\n",
    "\n",
    "le régularisateur est une fonction des poids $\\beta$ du modèle.\n",
    "\n",
    "le facteur $\\lambda$ est appelé **coefficient de régularisation**. Il contrôle l'importance relative du terme d'erreur quadratique et du terme de régularisation. S'il est faible voire nul, on retombe sur les coefficients des moindres carrés cordinaires. C'est un nouvel hyperparamètre, à déterminer à l'aide d'une recherche en grille avec validation croisée.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Réduisez l'amplitude des poids affectés à vos variables\n",
    "\n",
    "Méthode de la régression de crête (*ridge regression*).\n",
    "\n",
    "On utilise le carré de la norme 2 du coefficient de régression comme mesure de la complexité du modèle.\n",
    "\n",
    "Soit :\n",
    "* un jeu de données avec $n$ points et $p$ variables : $X \\in \\mathbb{R}^{n \\times p}$\n",
    "* un ensemble d'étiquettes : $y \\in \\mathbb{R}^n$\n",
    "\n",
    "Régression linéaire = minimisation de la somme des moindres carrés.\n",
    "\n",
    "Expression matricielle : $\\min_{\\beta \\in \\mathbb{R}^{p+1}} (y - X\\beta)^\\top (y - X \\beta)$\n",
    "\n",
    "Expression équivalente, en tant que norme 2 : $\\min_{\\beta \\in \\mathbb{R}^{p+1}} ||y - X\\beta||^2_2$\n",
    "\n",
    "Rappel (mais je ne me souviens pas de la première fois^^) :\n",
    "* $\\beta$ vecteur de dimension  $p+1$ :\n",
    "$\\beta=\\begin{pmatrix}\\beta_0\\\\\\beta_1\\\\\\vdots\\\\\\beta_p\\end{pmatrix}$\n",
    "* Ajout aux données $X$ d'une première colonne de 1 :\n",
    "$\n",
    "  X =\n",
    "   \\begin{pmatrix}\n",
    "    1 & x^1_1 & x^1_2 & \\cdots & x^1_p\\\\\n",
    "    1 & x^2_1 & x^2_2 & \\cdots & x^2_p\\\\\n",
    "    \\vdots & \\vdots & \\cdots & \\vdots & \\\\\n",
    "    1 & x^n_1 & x^n_2 & \\cdots & x^n_p\\\\\n",
    "  \\end{pmatrix} \n",
    "$\n",
    "\n",
    "On ajoute au terme d'erreur un régularisateur qui est le carré de la norme 2 de $\\beta$, i.e. la somme des carrés de ses composantes :\n",
    "\n",
    "$||\\beta||^2_2=\\sum_{j=0}^p{\\beta^2_j}$\n",
    "\n",
    "Nous allons pénaliser les solutions qui minisent bien la somme des moindres carrés, mais avec de grandes amplitudes de valeur pour les entrées de $\\beta$ (<mark>pas bien compris la fin de la phrase</mark>).\n",
    "\n",
    "Pour jouer sur l'importance relative des deux critères, erreur de prédiction et complexité du modèle, on introduit le coefficient de régularisation $\\lambda$, toujours positif. Plus il est important, plus les coefficients de $\\beta$ sont pénalisés et seront donc petits :\n",
    "\n",
    "$\\min_{\\beta \\in \\mathbb{R}^{p+1}} \\left(||y - X\\beta||^2_2+\\lambda||\\beta||^2_2\\right)$\n",
    "\n",
    "⇒ régularisation de Tikhonov, ou *régression d'arête*, ou *ridge regression*\n",
    "\n",
    "Elle précise en texte que cela rappelle le *weiht decay* (dégradation / modération des pondérations) utilisées dans les réseaux de neurones.\n",
    "\n",
    "Liens collectés pour la traduction, mais qui seront utiles pour mes approfondissements :\n",
    "* https://fr.wikipedia.org/wiki/Régression_linéaire\n",
    "* https://en.wikipedia.org/wiki/Linear_regression\n",
    "* https://en.wikipedia.org/wiki/Ridge_regression\n",
    "* https://en.wikipedia.org/wiki/Tikhonov_regularization\n",
    "* https://fr.wikipedia.org/wiki/Régularisation_de_Tikhonov\n",
    "\n",
    "⇒ elle a fait une erreur sur le nom de Tikhonov, et je sais maintenant que Google traduit mal ridge regression, qui n'est pas régression de crête, mais régression d'arête.\n",
    "\n",
    "\n",
    "Elle dit : la fonction que nous cherchons à minimiser est convexe en $\\beta$... hum... là ça ne va de soi d'interpréter ce qu'elle vient de dire.\n",
    "\n",
    "Elle dit : il nous suffit donc d'annuler son gradient. Là ça me renvoie à des notions de prépa et d'école d'ingé que je n'ai pas révisées depuis bien longtemps : gradient, divergence, rotationnel et laplacien : p 145 dans mon formulaire Chambadal.\n",
    "\n",
    "*Dans mon Warusfel, c'est le chapitre 23 (le dernier de l'analyse) Calculs de champs de vecteurs, p 667 et suivantes.*\n",
    "\n",
    "*Là un topo math bien fait, avec de nombreux exemples et des exercices : https://personal.math.ubc.ca/~CLP/CLP4/clp_4_vc/sec_graadDivCurl.html*\n",
    "\n",
    "\n",
    "* https://www.sangakoo.com/en/unit/gradient-of-a-scalar-field-divergence-and-rotational-of-a-vector-field\n",
    "* https://openclassrooms.com/forum/sujet/gradient-divergent-rotationnel-laplacien\n",
    "* La signification physique du gradient : https://www.youtube.com/watch?v=x0zhe3thgB8\n",
    "\n",
    "*Je termine la vidéo sans tout comprendre donc, mais je mets en réserve ce travail de révision des fondamentaux mathémtiques sous-jacents.*\n",
    "\n",
    "Il nous suffit donc d'annuler son gradient :\n",
    "* gradient du terme d'erreur, cf. régression linéaire : $\\nabla_\\beta||y - X\\beta||^2_2 = -2X^\\top(y-X\\beta)$\n",
    "* terme de régularisation : également le gradient d'une forme quadratique : $\\nabla_\\beta\\lambda||\\beta||^2_2 = 2\\lambda\\beta$\n",
    "\n",
    "En texte, elle précise que le gradient d'une forme quadratique se calcule de manière analogue à la dérivée d'un polynôme de degré 2.\n",
    "\n",
    "On cherche à annuler la somme de ces deux termes : $\\lambda\\beta-X^\\top(y-X\\beta)=0$\n",
    "\n",
    "\n",
    "$\\Leftrightarrow (\\lambda I + X^\\top X)\\beta=X^\\top y$\n",
    "\n",
    "Si $(\\lambda I + X^\\top X)$ est inversible, alors : $\\beta = (\\lambda I + X^\\top X)^{-1}X^\\top y$\n",
    "\n",
    "Elle dit : ça tombe bien, si $\\lambda > 0$, on garantit l'inversibilité de cette matrice.\n",
    "\n",
    "Pourquoi ? Ca ne me suffit pas, j'ai besoin de comprendre !\n",
    "\n",
    "A l'instinct, mais je manque de maîtrise, je dirais qu'on doit démontrer, avec un argument de diagonalisation, que le déterminant est le produit de termes diagonaux nécessairement strictement positifs.\n",
    "\n",
    "Scatter $\\lambda$ décroissant / $\\beta$ croissant. Elle rappelle que la grandeur de $\\lambda$ pèse sur les coefficients $\\beta_i$. Plus $\\lambda$ est proche de 0, plus c'est le fait de minimiser l'erreur de prédiction qui contera.\n",
    "\n",
    "Si $\\lambda$ est très grand, $\\beta$ vaut 0, ce qui n'est pas intéressant, car on obtient un modèle qui ne prédit rien.\n",
    "\n",
    "A mesure que $\\lambda$ décroît, $\\beta$ croit, et peut prendre des valeurs importantes.\n",
    "\n",
    "J'ai du mal à la suivre sur ses variables $j=1$, $j=2$, etc quelles sont ces variables ?\n",
    "\n",
    "Suivant les variables, $\\beta$ plus ou moins grand, et peut même être négatif.. là j'avance sans comprendre car je ne comprends pas l'idée d'un $\\beta$ variable suivant ... la variable.. kezako ?\n",
    "\n",
    "Je viens de comprendre à 3:38.\n",
    "\n",
    "Si je prends une 4ème variable fortement corrélée par exemple de $j=2$, alors leur $\\beta$ seront proches.\n",
    "\n",
    "Les variables sont bien les variables au sens des colonnes de $X$, et les $\\beta$ sont les coefficients de $\\beta$ correspondants. Pas une bonne pédagogue. J'aurais parlé de la variable $X_j$ et du coefficient $\\beta_j$. Pourquoi créer de l'ambiguïté et donc de la confusion alors que l'on est sur un haut degré d'abstraction ? Au contraire, il faut être plus que jamais précis et concis, clair, à la Gauss.\n",
    "\n",
    "Elle dit que ce rapprochement des valeurs des coefficients de $\\beta$ entre deux variables corrélée vaut si $\\lambda$ est suffisamment important. Ce qu'il manque, c'est une démonstration : pourquoi les coefficients seraient-ils proches si les variables sont corrélées ? Où est le lien ? Et pourquoi cela fonctionnerait dans le cadre de la régularisation de Tikhonov, mais pas pour la régression ordinaire ?\n",
    "\n",
    "\n",
    "\n",
    "L'évolution du modèle en fonction de $\\lambda$ est appelé le chemin de régularisation.\n",
    "\n",
    "\n",
    "En résumé, les deux avantages à l'introduction de $\\lambda \\ge 0$ :\n",
    "* assure l'existence d'une solution unique pour $\\beta$.\n",
    "* produit un effet de regroupement des coefficients pour les variables corrélées.\n",
    "\n",
    "Utiliser d'autres normes que la norme 2 produit d'autres effets de régularisation : cf. suite du cours.\n",
    "\n",
    "\n",
    "Je vais arrêter là, car mon cerveau surchauffe.\n",
    "\n",
    "Il faudra que je repasse complètement dessus.\n",
    "\n",
    "Elle ajoute notamment un argument intéressant dans le texte pour expliquer qu'en régression, si on amplifie par un scalaire une variable $x_j$ de $X$, alors on réduit d'autant son coefficient $\\beta_j$.\n",
    "\n",
    "Je pense qu'on ne peut pas bien se représenter ces abstractions sans des exemples concrets simples, martice 2 x 3 ou 3 x 3. Ce sera aussi l'occasion de pratique Numpy sur les opérations matricielles standard.\n",
    "\n",
    "Dans mon exemple, il ne faudra pas oublier de produire des variables corrélées => petite fonction cf. mon $\\mathcal{N}(\\mu,\\sigma^2)$ pour génerer.\n",
    "\n",
    "Le next step maintenant, va être de l'utiliser sur P4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Réduisez le nombre de variables utilisées par votre modèle\n",
    "\n",
    "Ridge ⇒ permet de réduire les poids des coefficients $\\beta_i$ associés à chacune des variables $\\boldsymbol{x}_i$\n",
    "\n",
    "Ces coefficients peuvent être très proches de 0 sans êtres nuls, ce qui signifie que toutes les variables seront utilisées dans le modèle.\n",
    "\n",
    "L'effet des variables à coefficients quasi nuls est négligeable.\n",
    "\n",
    "Objectif du chapitre : étude des méthodes qui permettent d'annuler les coefficients quasi nuls : on parle de méthodes *parcimonieuses* (*Sparse* en anglais)  ⇒  Lasso, ElasticNet.\n",
    "\n",
    "On repart de la formulation Ridge :\n",
    "\n",
    "Soit :\n",
    "* un jeu de données avec $n$ points et $p$ variables : $X \\in \\mathbb{R}^{n \\times p}$\n",
    "* un ensemble d'étiquettes : $y \\in \\mathbb{R}^n$\n",
    "* un coefficient de régularisation $\\lambda \\ge 0$\n",
    "\n",
    "On cherche $\\beta=\\begin{pmatrix}\\beta_0\\\\\\beta_1\\\\\\vdots\\\\\\beta_p\\end{pmatrix}$ qui minimise $\\left(||y - X\\beta||^2_2+\\lambda||\\beta||^2_2\\right)$\n",
    "\n",
    "\n",
    "On remplace la norme $\\ell_2$ de $\\beta$ par sa norme $\\ell_1$ : $||\\beta||_1=\\displaystyle\\sum_{j=0}^p |\\beta_j|$\n",
    "\n",
    "\n",
    "Attention : plus de solution analytique exacte, même si de nombreuses méthodes permettent d'obtenir une solution approchée, dont notamment l'**algorithme du gradient**.\n",
    "\n",
    "**NB** > le problème du Lasso n'est pas strictement convexe, et n'a donc pas de solution unique.\n",
    "En revanche $\\boldsymbol{X}\\beta$ est unique. En outre, deux solutions on nécessairement le même signe sur leur support (les coefficients non nuls).\n",
    "\n",
    "Cette méthode s'appelle le Lasso (*Least Absolue Shrinkage and Selection Operator*).\n",
    "\n",
    "*Shrinkage* comme réduction des poids proches de 0 pour les annuler.\n",
    "\n",
    "Ce faisant, cela élimine les variables de coefficients nuls et permet donc de faire une *Selection*\n",
    "\n",
    "C'est donc une méthode 1/ de sélection de variables 2/ de réduction de dimension supervisée.\n",
    "\n",
    "Cette méthode s'appelle également (en traitement du signal), la **pousuite de base** (*basis pursuit*).\n",
    "\n",
    "Comment ça marche ?\n",
    "\n",
    "La formulation est équivalente à minimiser le terme d'erreur $||y - X\\beta||^2_2$ sous la contrainte de $||\\beta||_1 \\le t, t \\ge 0$, où $t$ dépend de $\\lambda$.\n",
    "\n",
    "Elle précise pour les curieux qui souhaitent approfondir que cette équivalence s'obtient par dualité et selon les conditions de [Karush-Kuhn-Tucker](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions) qui est une généralisation des multiplicateurs de Lagrange.\n",
    "\n",
    "Illustration graphique en dimension 2 : $|\\beta_1| + |\\beta_2| \\le t$ définit la **région adminissible** qui prend la forme d'un carré dont les sommets sont $(\\beta_1, 0)$, $(\\beta_2, 0)$, $(-\\beta_1, 0)$, $(-\\beta_2, 0)$.\n",
    "\n",
    "\n",
    "La suite est une *monstration* intuitive, pas une démonstration.\n",
    "\n",
    "\n",
    "Etant donnée la solution $(\\beta_1, \\beta_2)$ de la régression liénaire ordinaire (supposée hors la région admissible, i.e. ne satisfaisant pas la contrainte).\n",
    "\n",
    "Nous devons donc augmenter la valeur de l'erreur quadratique pour la rapproche de la région admissible.\n",
    "\n",
    "Comme l'erreur est justement *quadratique*, on peut tracer ses lignes de niveau qui sont des ellipses. Sur chacune de ces lignes de niveau, l'erreur quadratique est la même, et elle augemente à mesure que l'on s'éloigne de la solution (le minimum sans contrainte).\n",
    "\n",
    "Une de ces lignes de niveau va 'toucher' la région adminissible, et notre solution est à ce point d'intersection là.\n",
    "\n",
    "La forme carrée avec coins de la zone admissible (en fait une boule $\\ell_1$ de rayon $t$ c'est-à-dire un hypercube), qui résulte de la norme 1, entraîne que la probabilité est forte que l'intersection s'opère avec l'un de ces coin (par opposition avec la forme sphérique de la zone admissible avec la norme 2). C'est le 'truc' clé qui fait que la norme 2 n'annule pas un coefficient proche de 0 contrairement à la norme 1.\n",
    "\n",
    "Comme pour Ridge, on peut tracer un chemin de régularisation.\n",
    "\n",
    "Quand $\\lambda$ s'annule, on retombe idem sur la régression ordinaire.\n",
    "\n",
    "En revanche, à mesure que $\\lambda$ décroit, les variables vont rester nulles plus longtemps, et rentrer dans le modèle les unes après les autres.\n",
    "\n",
    "Si plusieurs variables sont corrélées, le Lasso va en choisir une aléatoirement et éliminer les autre. Il n'y a donc pas l'effet de sélection groupée du Ridge (toutes les variables corrélées sont sélectionnées et obtiennent un poids partagé identique).\n",
    "\n",
    "Pour bénéficier des deux propriétés, parcimonie et sélection groupée, il suffit de combiner Ridge et Lasso.\n",
    "\n",
    "On introduit un paramètre $\\alpha, 0 \\le \\alpha \\le 1$ et on on combine les termes de régularisation Ridge et Lasso :\n",
    "\n",
    "$\\displaystyle\\min_{\\beta \\in \\mathbb{R}^{p+1}} \\left(||y - X\\beta||^2_2+\\lambda\\left((1-\\alpha)||\\beta||_1+\\alpha||\\beta||^2_2\\right)\\right)$\n",
    "\n",
    "Si $\\alpha = 0$ on retriuve le Lasso, si $\\alpha = 1$, on retrouve le Ridge.\n",
    "\n",
    "La région admissible est elle aussi une combinaison entre le carré du Lasso et la sphère du Ridge (un carré bombé).\n",
    "\n",
    "Cette méthode combinée s'appelle l'**Elastic Net**.\n",
    "\n",
    "La contrepartie d'avoir les avantages des deux méthodes Ridge et Lasso, c'est de devoir trouver un couple de deux hyperparamètres $\\alpha$ et $\\lambda$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 TP - Comparez le comportement du lasso et de la régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4.385147</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>3.896909</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>4.684443</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.907447</td>\n",
       "      <td>3.396185</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.463853</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5.143124</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.882564</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>68</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>5.477509</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3.471966</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>68</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5.582932</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    col    lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "0     1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0   \n",
       "1     2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0   \n",
       "2     3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20   \n",
       "3     4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0   \n",
       "4     5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0   \n",
       "..  ...       ...       ...  ...       ...  ...       ...      ...    ...   \n",
       "92   93  2.830268  3.876396   68 -1.386294    1  1.321756        7     60   \n",
       "93   94  3.821004  3.896909   44 -1.386294    1  2.169054        7     40   \n",
       "94   95  2.907447  3.396185   52 -1.386294    1  2.463853        7     10   \n",
       "95   96  2.882564  3.773910   68  1.558145    1  1.558145        7     80   \n",
       "96   97  3.471966  3.974998   68  0.438255    1  2.904165        7     20   \n",
       "\n",
       "        lpsa train  \n",
       "0  -0.430783     T  \n",
       "1  -0.162519     T  \n",
       "2  -0.162519     T  \n",
       "3  -0.162519     T  \n",
       "4   0.371564     T  \n",
       "..       ...   ...  \n",
       "92  4.385147     T  \n",
       "93  4.684443     T  \n",
       "94  5.143124     F  \n",
       "95  5.477509     T  \n",
       "96  5.582932     F  \n",
       "\n",
       "[97 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('TP_1_prostate_dataset.txt', sep='\\t')\n",
    "display(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection et normalisation données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:, 1:-3]\n",
    "y = raw_data.iloc[:, -2]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = std_scale.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression ordinaire comme baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erreur baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7178476430763839\n"
     ]
    }
   ],
   "source": [
    "# erreur **RSS** (*Residual Sum of Squares*)\n",
    "import numpy as np\n",
    "baseline_err = np.mean((lr.predict(X_test) - y_test) ** 2)\n",
    "print(baseline_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recherche des hyperparamètres optimaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 50\n",
    "alphas = np.logspace(-5, 5, 50)   # distribution logarithmique entre 10^-5 et 10^5\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "coefs, errors = [], []\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "    errors.append(np.mean((ridge.predict(X_test) - y_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_err, baseline_err])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmin : 31 -> 0.5849450759284021 -> alpha : 21.209508879201927\n"
     ]
    }
   ],
   "source": [
    "i = np.argmin(errors)\n",
    "err = errors[i]\n",
    "print('argmin :', i, '->', err, '-> alpha :', alphas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemin de régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 50\n",
    "alphas = np.logspace(-5, 5, 50)   # distribution logarithmique entre 10^-5 et 10^5\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "coefs, errors = [], []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append(np.mean((lasso.predict(X_test) - y_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_err, baseline_err])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmin : 19 -> 0.5565646069428607 -> alpha : 0.07543120063354623\n"
     ]
    }
   ],
   "source": [
    "i = np.argmin(errors)\n",
    "err = errors[i]\n",
    "print('argmin :', i, '->', err, '-> alpha :', alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzxElEQVR4nO3dd3wc1b338c+ZrZJWq94sWZaEG+64AS4QWmxTLoQeSIHQCXmSmwY3N9zkpsKTPDftQggdEnoJdsBAKMHYxt3Ylm25SrYlN/UurXZ3zvPHyrZsq9la7Wp3f29e+9rZ2bMzv8HSd0dnZs4orTVCCCGinxHuAoQQQoSGBL4QQsQICXwhhIgREvhCCBEjJPCFECJGSOALIUSMsIa7gN6kp6frgoKCcJchhBARY926ddVa64zu3hvSgV9QUMDatWvDXYYQQkQMpdTent6TLh0hhIgREvhCCBEjJPCFECJGSOALIUSMkMAXQogYIYEvhBAxYkiflnm6Pio5jN/sedhnpdSx6ePm9zB9pNXxTygVeEepQJvAc6CB0fmeYXRpoxQWpQLvdbaxGApDgcVQWA0DwwCrYXS+VlgtCpvFwG4xMIyu1QohxKmJysC/78XPafP6w11G0B35ErBbDBw2C06bQZzNgtNmIc5mwWEzSLBbSXRaSXTaOp+tuJ02kuJtZCQ6yHA5yEh04LRZwr05QogQi8rAf+OeWZj9uLFL1yYa3cP8I/P0Ca87P6UD87QOtDk6feQ9DWbnfFNrtNaYZmA68AC/GZj2+TV+U+PXGp+p8flNfH6N1zTx+jRev4nXb+LxdT68ftp9fto6/LR7TZrafRxubKep3UdTu49mj6/HbU90WslIdJDtdlKQnkBRegKF6QkUZbjIS4nDZpHePiGiTVQG/rhh7nCXMCT4TU1zu4/Gdi/1rV6qmz1UNXmoOvLc5OFAQxvvFh+krtV79HNWQ5GfFs9Zw1OYWZjCjIJUCtMTjusKE0JEnqgMfBFgMRRJ8YHunOGpvbeta+mgtLqFsuoWyqqb2XG4mX9tr+SN9RUApLscR8P/knFZ5KXEh2ALhBDBpIbyPW2nT5+uZSyd8NFas7uqmdVldazZU8vqslr217ehFMwZmc610/KYNz5bjgcIMYQopdZprad3+54EvjgV+2pa+fvn+3ltXTkVdW24nVauOiuX66cPZ/wwt3T7CBFmEvgi6ExTs6K0hlfXlvPu5kN0+ExmFKTw86smMDZbjqEIES69BX5QTsVQSs1XSm1XSu1SSj3QQ5svKKU2KKW2KKWWBGO9InwMQzF7ZDp/uPEs1vzoYn56xTh2VTZz2R+X8ct3ttLSyxlCQojwGPAevlLKAuwALgEqgDXAl7XWW7u0SQY+A+ZrrfcppTK11pV9LVv28CNLXUsHD7+3jZfXlJOT5OQnV4xj3vhs6eYRIoQGew9/JrBLa12qte4AXgauPKHNTcCbWut9AP0JexF5UhLsPHTNJN6451yS4mzc/bf1fOPZNeyraQ13aUIIghP4uUB5l9cVnfO6Gg2kKKU+UUqtU0p9raeFKaXuVEqtVUqtraqqCkJ5ItSmjUjl7W/N4ceXncnqslou++NS1u+rC3dZQsS8YAR+d3+vn9hPZAWmAZcB84AHlVKju1uY1vpxrfV0rfX0jIxub8soIoDVYnD73CLe//fzSHPZ+dpTq1m7pzbcZQkR04IR+BXA8C6v84AD3bR5T2vdorWuBj4FJgdh3WKIy0uJ55W7ziXT7eBrT69mZWlNuEsSImYFI/DXAKOUUoVKKTtwI7DohDYLgblKKatSKh44GygJwrpFBMhyO3n5znPITY7jlmdWs3xXdbhLEiImDTjwtdY+4D7gfQIh/qrWeotS6m6l1N2dbUqA94BNwGrgSa315oGuW0SOzEQnL915DiNSE/jGs2tYskOOzwgRanLhlQip2pYObn5yFbsrm/nLV6dxwdjMcJckRFQZ9AuvhOiv1AQ7L91xNqOzXdz517U88WkpZi83qxFCBI8Evgi55Hg7L9x+DheNzeKXi0v4+jOrqWxsD3dZQkQ9CXwRFklxNv78lan8+uqJrN1Tx/w/LOXDrYfDXZYQUU0CX4SNUoovz8znH9+aQ06Sk9ufX8uDb22mPQpvTynEUCCBL8JuZKaLN++dxR1zC/nryr1c8adlLC4+SIfPDHdpQkQVOUtHDClLd1bxwBvF7K9vI91l55qpedwwYzhFGa5wlyZERJDx8EVE8ZuaT3dU8dLqfXy0rRK/qTm7MJUbZw5n/vgc4uxyhy0heiKBLyJWZVM7r6+r4JU15eytaSXOZuGCsRnMn5DDhWMzcTnktsxCdCWBLyKeaWpWldWyuPgg7205RFWTB7vV4LxR6SyYkMPFZ2aRFG8Ld5lChJ0EvogqflOzfl9dIPw3H+JgQzsWQzGzIJWLx2Vx8ZmZjEhLCHeZQoSFBL6IWqap2VhRzwdbD/NhyWF2HG4GYFSmi4vHZXHllGFyj10RUyTwRczYW9PChyWVfFRymFVltViU4r3vzJWzfETMkLF0RMwYkZbAbXMKefGOc1h2/wU4bAb/tXALQ3nHRohQkcAXUSsnKY7vf3EMy3ZV807xwXCXI0TYSeCLqPaVc0Ywfpibn7+9lWaPL9zlCBFWEvgiqlkMxS+umkBlk4fff7Aj3OUIEVYS+CLqnZWfwo0zhvPMZ3vYdqgx3OUIETYS+CIm/HDeWNxOKw++tVkO4IqYJYEvYkJKgp0HFoxlzZ463li/P9zlCBEWURn4fq95/MN3wsN/7GF2fZgafeQhe4FR57ppw5man8yvF5fQ0OoNdzlChFxUjjz15Pc+xdcR5LHUFSgApTqfAzfwCDx3nVZHXysDlKGOThuGQhkKw1AYlq7TBharwmI1MKzHpi1WA6vdgtUeeLZ1TtscFuxxVhzxRx42HPFWbA5LoA7RLcNQ/PyqCVzxp2X85p/b+MVVE8NdkhAhFZWBP/PyIkwzEPgn7ajr7l90baf1sRm6SzOtNeiu8zTaDExqrcEMPGvo8pcCR/9iCPwFAaY/8J5paky/xvQH/vLwtvoC014Tv1/j95r4vH58nsD7fVGGIs5lIyHZEXgk2Y9OJ6Y6Sc1JID7JHtNfCuOHJfH1WQU8+9kebptTRGG6jLkjYkdUBv5ZX8wPdwlBZ5oaX4cfX4eJ1+Ono82Hp9WLp82Hp/XIw0tbYwctDR001bZzuKyBtqbjuy4c8VZSshNIzYkndZiLtNwEsoqSsMXQGPO3zSnkmeV7+Ne2SgrnFIa7HCFCJioDPxoZhsLutGJ3ntrn/F6TlkYPjVVt1B1qpfZAC7UHWyjdWM3W5YGrTw2rIqcoibyxqeSNTSFzRCKGJSoP7wCQlxJPQVo8y3dV8w0JfBFDJPCjnMVm4E6Lw50WR97Y1OPea2vqoHJfExXb6qjYVsuqRaWsWgR2p4XcMSmMPSeHgklpURn+c0al8/f1+/H6TWxRuH1CdEcCP4bFJdoZMT6NEePTAGhr7mD/9nrKt9Wyt7iGso3VuFIcTDg/l3GzhxGXaA9zxcEzZ2Q6f1u5jw3l9cwoSO37A0JEAQl8cVScy87IaZmMnJaJ6TfZU1xD8ScVrHyrlNVvlzFqWhYTv5BHVmHkjy9/blE6hoKlO6sl8EXMkMAX3TIsBkVTMiiakkHtwRY2L9nPthUH2b7qEIWT0zn/pjEkJDnCXeZpS4q3MTEvmeW7qvnuJaPDXY4QISGdl6JPqTkJnHfjaG55aDbnXFXEvi21vPSzVexccziiL1CbMzKNDeX1NLXLRVgiNkjgi36zx1mZNr+AG348g+TMeP751Bbef2IzbU0d4S7ttMwZmYHf1KwsrQ13KUKEhAS+OGUp2Qlc/f2pnPulMyjbVM1LP1vF7vWV4S7rlE0dkUyczcLyXdXhLkWIkJDAF6fFsBhMnTeC6380A1eKk/ce38wnL25Hm5HTxeOwWphZmMrSnVXhLkWIkJDAFwOSNszFNfdPY8ol+Wz5dD/L39wVUf36c0ams7uqhYMNbeEuRYhBJ4EvBsxiMZh19RlMvCCPjR+Ws+69veEuqd/mjEoHYNlO6dYR0S8oga+Umq+U2q6U2qWUeqCXdjOUUn6l1LXBWK8YOpRSzL1uFKPPzmLVwlI2L6kId0n9MiYrkXSXXfrxRUwY8Hn4SikL8AhwCVABrFFKLdJab+2m3cPA+wNdpxialKG48Gtn0tHqY8nLO3DE2xg1IyvcZfXKMBSzR6azbFcNWuuYHklURL9g7OHPBHZprUu11h3Ay8CV3bT7FvAGEHmnc4h+s1gM5t0xgWEjk/nwma3s3VIT7pL6NHtkOtXNHrYfbgp3KUIMqmAEfi5Q3uV1Ree8o5RSucCXgMf6WphS6k6l1Fql1NqqKjl7IhJZ7RYuvXcSqbkJvPdYMQd31Ye7pF7NGSn9+CI2BCPwu/sb+MTTNH4P3K+19ve1MK3141rr6Vrr6RkZGUEoT4SDI87KFd+aQkKKg8WPFdPeMnSvZh2WHEdRRgLLpB9fRLlgBH4FMLzL6zzgwAltpgMvK6X2ANcCjyqlrgrCusUQFu+2M//OiXhavKx5uyzc5fRqzsh0VpXW0tGPO4sJEamCEfhrgFFKqUKllB24EVjUtYHWulBrXaC1LgBeB+7VWr8VhHWLIS49z8X4ubkUL9lPzYHmcJfTozkj02nz+lm/ry7cpQgxaAYc+FprH3AfgbNvSoBXtdZblFJ3K6XuHujyReSb+W+F2J0Wlr+2c8helHXOGWlYDCWnZ4qoFpTz8LXWi7XWo7XWZ2itf9k57zGt9UkHabXWt2itXw/GekVkiHPZmXlFIeUldZRtHJqB6nbamJyXxFI5cCuimFxpK0Ji/Hm5pOQksPz1nfi8fR67D4s5I9PZVFFPQ9vQPcAsxEBI4IuQsFgM5l4/isbqdjZ+VN73B8JgzqgMTA0rS4f+tQNCnA4JfBEyw89MpXByOmvf3UtLvSfc5ZxkQm7g1o27q4buwWUhBkICX4TU7GtHYvpNVry1O9ylnCTebiXRaaWyceh9GQkRDBL4IqSSMuKZclE+21ce4lBZQ7jLOUmW28nhxvZwlyHEoJDAFyE3bcEI4pPsLH15x5C7YUq228khCXwRpSTwRcjZnVZmXT2Syr1NrFm8J9zlHCfT7ZAuHRG1JPBFWIyemcWYs7NZ804Ze4qHzrnv2Z1dOuYQ+8tDiGCQwBdhoZTi/JvHkJbr4sNnttJQNTRuMZjlduIzNbWtHeEuRYigk8AXYWOzW1hw10QA3v1LMd6O8F+QleV2AnCoQfrxRfSRwBdhlZQRx8W3jqNmfzNLXtge9rF2stwOACqbJPBF9JHAF2FXMDGdGZcVsn3VIbZ8uj+stRzbw5cDtyL6SOCLIWHGpQWMmJDG0ld3cqg0fOfnZyQ6UAo5F19EJQl8MSQoQ3HxreNwpTh47y/FNNWGJ3BtFoO0BId06YioJIEvhgxngo35d02kw+PnlV+upmxjeO5pnJ3kkIO2IipJ4IshJWN4Itf/xwzcaXEs/nMxS1/dgd8b2tsOZiU6OSwXX4koJIEvhpzkrHiu+cE0Jl2Qx6aPK3jjN+uoP9wasvVnJcl4OiI6SeCLIcliM5h7w2guvWcijdVtvPqrNexYfSgk685KdFLT0iE3NBdRRwJfDGmFkzO44cczSc9z8cHTW1kZgmGVs5PkXHwRnSTwxZCXmOrkqu+exbjZOax7by9blg7uufqZnefiSz++iDbWcBcgRH8YFoPzbxpDc72HJS/twJ0Wx/BxqYOyrqzEQOBXSj++iDKyhy8ihmExmHf7BFJzEnjv8WJq9g/OrQizkzqvtpXAF1FGAl9EFHuclcu+OQmrw8Lbj2ykZRCGQEiJt2G3GNKlI6JOVHbptH5e2f87Kamu0+r4WerEdur4+Z3z1NHXKjBPBaaV6maeocAIzDsyffTZosCiUIYReLYolLVzWnUtJrYlpjq5/JuTefO361j86Cau+u5UbA5L0JavlCLT7ZBTM0XUicrAr3tzJzrEF+sMOquBshooW+BLQNktGA4LymHBsAeelcOCEWfFSLBhSbBhxNswEmwYCVYsLnvgyyNKZOQn8sXbJ7D4z5v44OktzL9rIoYRvC9FubetiEZRGfhZ/z6t5zd7Gn5XH/d0fLuuH9HHN9T6hHldprXWx+ZpAn91mCdO68C0X6P9gXnHXpton0b7TLTPBG/gWXtNdIcfs8OP9vjxNnagPX5Mjx/d7ju+3i4Mtx1rihNrigNLqjMwnebENsyF4Yy8H4XCSenMuW4Uy17dyaqFuzn3SyODtuxst5OSQ41BW54QQ0Hk/Zb3gzXVGe4SwkabGrPNh9nixWz1YrZ48bd4MRs78NV58NW249nTiH9j1XFfDNb0OGx5Luy5idjzXIEvgSB2kwyWyRcOp3Z/M5//cx8jp2WRkZ8YlOVmuh0s2SF9+CK6RGXgxzJlKCydXTq90X4Tf70Hb3Ub3opmOvY301HWQNuGzgHLDHAUJhE3IZ248elY3PYQVH96Zl0zkrJN1Sx5aTvX/GBa4JjIAGW7nTR7fDR7fLgc8msiooP8JMcoZTGwpsVhTYsjbsyx89n9TR2B8N/TQNuWGuoX7qZ+0W7s+W7iJqYTNyENa/LQ+gvKEW9j1jUj+ejZEkpWHGTc7GEDXmbW0Yuv2nFluAa8PCGGAgl8cRxLop24sanEjU3FPa8AX2UrbcXVtG2uoeHtUhreLsU5NhX3F0dgHzZ0gnDM2dlsXXaAFW/upmhKBs4+/sLpS2bnrQ4PN7ZzhgS+iBLRc9qGCDqlFLasBNwXjyDrO1PJ+v503Bfn49nTSOUfP6fmxRK8VaEbxbI3SinO//IYPG2+oIy3k91lD1+IaCF7+KLfbOlx2C4egWt2Lk2fVtC8fD9txdXET83CfVF+2A+Wp+W6mHRBHhs/LufM2cPIKnCf9rKyZDwdEYWiMvA9paU9n34J0ONFTKr7ySPtu3s+dtVVlwutjjyMwAVWR14bRufFV0bntNF50ZXRebGVJTA9xC+yMuKsJM0rwDV7GE2fVNC88gCtGypJPC8P9yUjgnLQ9HTNvLyQnWsP8+lL27nm/umnfW5+gsNKosMqd74SUSUqA7/smmvRbW3hLuP0WSyBLwCrFWWxoKxWsFlRVhvKag08HA6Uw45hdwSmnY7AdJwTIyEBIyEBS+ezkZCA4UrEmpqCJTUVS0oKhss14C8Wi8tO8uVFuObm0vjeHpr+VY73YAupN44J23n99jgrs68dyQdPbWXrsgNMOC/3tJeV6ZZ724roEpTfSqXUfOAPgAV4Umv90Anv3wzc3/myGbhHa70xGOvuzrBf/xpMf7fv6T4uvOpsdPIb+vjnoxdVHZkXuAIrcCHVkdca0OaxeeaR+SbaNDtfm2i/CaYf7feD3ww8m360z4/2+8DnQ3t9aN+Rhxfd4UW3t6M9HvyNjegqD7q9HbOtDbOlBbO1tde/cpTNhiUlBUt6GvbcXGy5edjy8rDl5WLPy8OWm4sRF9fX/2oArEkOUm8Ygz0/kfp/7KbyzxtJ//r4sHXxjJqexdZlB1j51m7OOCuDuMTTO6U0O8kpe/giqgw48JVSFuAR4BKgAlijlFqktd7apVkZcL7Wuk4ptQB4HDh7oOvuiXv+vMFadMTQpolua8Pf0hL4Amhqwl9Xh6+2Dn9tLf66Wnx1dfiqqvCUltG8dBm6/fhwsxcW4pw4gbgJE3FOnIDzzDMxnD2HuOvcYVjT46h5YRuVj3xO2lfG4ShMGuxNPYlSivNuGMMrv1jNir/v5sKvnXlay8lKdLKqrDbI1QkRPsHYw58J7NJalwIopV4GrgSOBr7W+rMu7VcCeUFYr+iFMgxUZ3dOf2it8VdX01FRgbdiPx379tK+ZSutK1bSuOgfgUZWK45Ro0iYdS7u+fNxTphwUreQc1QKmd+cTM1zW6l6spiUL40kYXp2sDevT6nDEph4YR4bPypnxuWFJJ7GXxtZSU4qm9rRWg/54ypC9EcwAj8XKO/yuoLe995vA94Nwnp7VvKPHrt0gF4O2vb4gX4sR3UzX3XfTqkuz13mHZ1vdDnoe+LjyHwLGJZjz0enrWCxg8UKhg0stsCz0fsZuEoprBkZWDMy4KyzjnvPe/gw7Zs301ZcTNvGjdQ+9zy1Tz2NbdgwEufNwz1/Hs5Jk46Goi0jnsx7J1Pz4jbqXt+Jr7qNpPmFva5/MEz6Qh4bPyxn+8qDTL/01NeflejA69fUtnSQ5nIMQoVChFYwAr+7NOy281gpdQGBwJ/T48KUuhO4EyA/P//0KnrzTvAOjfPDhwzDCtY4sDrA1vlsjQObExyJYHeBwx2YdrgCz/HpkJCBLSEN27RRJM49F+zx+Ovrafr4XzS+/x61f/sbtc88gzUnh+QvfYnUW2/BkpiIEW8j/dYJ1C/cRdMnFVgz4kmYlhXSTXanx5E7OpmSFYeYtqDglPfSu56aKYEvokEwAr8CGN7ldR5w4MRGSqlJwJPAAq11TU8L01o/TqCPn+nTp/dzUPsT3PFxLwcsT3GR/VlObwd5T2p35GCvPmFe4ADucdNHX5tHD/6iAwd40f4uz2bnsy/w8HsDD9N7bNrvAZ8HfO3gbQ88+9oDX4ztjdCwHzqawdMUePT0/8mWgCUpj+TUQpKvKsB//W007WykceU2qh99lLoXXiDtzjtJufkmDKeT5KtG4qtuo/6tXYFB2bL618UULGfOyuHDZ0s4uKueYaNSTumzWUnHLr4aN+z0z+kXYqgIRuCvAUYppQqB/cCNwE1dGyil8oE3ga9qrXcEYZ29yzy9g3Sik9aB0G+tCTxaqjof1YHn+n1QtwfKlmLxtpAMJBdAW3I8VdscVP7mN9Q+9RfS77yV5Ju+QeqNYzn8x/XUvLCNzPumYNhDNwpn0dRMbC/voGT5wVMPfLnaVkSZAQe+1tqnlLoPeJ/AaZlPa623KKXu7nz/MeC/gDTg0c4/q31a6+kDXbcYJEqB0x14pPbS96114Augbg/UlhJ3qJj8iWtp2bCZqvUdHHroD9Q++nsyLhtN6uy7qP7ITf3C3aReNzpkm2KzWxg1LZMdaw4z98bR2E/h+oDMxEA3jtzbVkSLoJyHr7VeDCw+Yd5jXaZvB24PxrrEEKIUuDIDj+EzYfKNACT4vcQfKqb5H69S9dIH7H9pJ2kb7iJx4rU0rbsGR3wFCfPnBg4oh8DYWcPYuvwgu9ZVntJImjaLQbrLLsMriKghg6eJ4LPYULlTSbz7IQo/XEnydddSU5JI05bPsRtbqF/qx/vwhfDO9+DA570PgxEE2UVukrPi2bbi4Cl/Vm51KKKJBL4YVMpmI/tnPyPzgftp2lpFy87lKIeNmo4fYK5/DR7/AvxlLqx+AtrqB6cGpRh7bjYHdzVQf/jUzt6SwBfRRAJfDDqlFGm33ELeI4/g2b2VtvXP42tPoX7kO+gFvw00Wvx9+H9j4M27YM/yoO/1jz0nB6U45b38QOBLl46IDhL4ImQSL7yAghdfwGzeQ8eud2ndWE+LvgzuXgZ3fgJTboJt78Czl8ITF0DJ24FTToMgIdnB8HFpbFt5CNPs/5dJlttBTYsHrz84dQgRThL4IqScY8dS+OorKKMU36Fi6hfuwlPaAMPOgst/B9/fDpf/Htrq4JWb4bHZUPx671dO99OZs3JoqfdQUdL/8XGy3E60hqom2csXkU8CX4ScNSODEc89A55VmE2VVD+3CV99Zz+5PQGm3wr3rYOrnwhcaPbGbfC/02H9XwMXkZ2mwknpOBKslJxCt86RO1/JqZkiGkjgi7Aw4uLIe/T3+Pb9HbOljeonN2B2dNmLt1hh0vVwzwq4/q+BoR4W3QdPXAjVO09rnRabweiZ2ZRtqKa9pX9fHEfubVspgS+igAS+CBtrSgp5jzyEZ9sreKs6qH1x88n3KzAMGPdvcOcSuP55aCiHv5wHn//ttA7snnluDn6fyc41h/vV/ugevoyLL6KABL4IK/vw4eT++jt07HyH9m2NNH1U1n1DpWDclXDPZ5A7DRZ+M9DV095wSuvLyE8kLc9FyWf969ZJibdjsygOSx++iAIS+CLs4iZOJONbC/DuX0fDB+W0lVT33Ng9DL62EC58ELa8BY/NgfI1p7S+M8/NoWpfE3WHWvpsaxiKzEQnh2UPX0QBCXwxJLgv+AJJC3IxG/dT89wmvFW9XCBlWOC878M33gsM6vn0PFjzZL/XNWJCGgAHdtb3q32W28FhubetiAIS+GLISL3pOpwjGzA97VT+7yrM1j4OrA6fCXcvhaLz4b0fQUNFv9aTlBmHM8HG4bLGfrXPTpKLr0R0kMAXQ0rmd+9GNy3BbIPqZzcFbvDem7hkuOIPgIZPHurXOpRSZBW5OVTav/5/6dIR0UICXwwpSimyf3Q3nk0v0rGvlfpFu08+c+dEyfkw/Ruw4YV+n7KZXZhE3aHWfp2emeV20uTx0eLx9WvZQgxVEvhiyHEUFeJeMAHPjndpWXWI5uUn3UDtZHO/H7hl48e/6Nc6sooCd7Cq3NN3t052UuBcfBlETUQ6CXwxJKXfdRe6aS3++u00vFNK2/Y+hkNwZcC534StbwWGXO5DVoEbpehXt05W4rF72woRySTwxZBkOJ1k/9eDtC79E8raRu2L2/D2dRrlrPsgLgU++lmfy7c7raQOc3GoHwduu97bVohIJoEvhizX3LkkfvFCmt//JcoC1c9twd/c0fMHnEkw93uw+2Mo+7TP5WcVuTlc1ojuY/RMubetiBYS+GJIy3rgP8Dfgm//QsxmL7Uvbes9oGfcDonD4MP/7nPohezCJDrafNQd6v2mKC6HFZfDKgOoiYgngS+GNFtWJhnf+Q4tSxbhKGzFs7uBpk97Od/eFgdfuB/2r4Xti3tuR+DWhwCHyvruxx+V5WLtnrpTql2IoUYCXwx5KTd9Gef48dQ983OcZybT+M+9ePb10vc+5SuQNhI++nmv4+gnZ8XjiLf268DtggnZFO9vYF/Nqd0iUYihRAJfDHnKYiH7pz/FV12Nt2IxFred2pe3Y7b3cF68xQoX/CdUlUDxaz0vVymyCpM4VNr3gdsFE3IAWLz51G+ELsRQIYEvIkLcxAkkX3899S/+lcTzEvHXt1P31q6eL8oadxVkT4J//RL8PV8wlV3kpu5gC54+hnEYnhrP5Lwk3tkkgS8ilwS+iBgZ3/4/GPHx1D79PyRelE/bhipa11d239gw4PwfQv0+2PFej8vMLkoC4HA/LsC6bFKOdOuIiCaBLyKGNTWV9G/eS8uyZSijDHthEvULd/U8suboBeDOgzVP9LjMrAI3KKRbR8QECXwRUVJvugl7YSFVDz1E6tWFKKtB7cvb0b5uBlmzWGH6LVD6SY9j7NjjrKTmJHC4H2fqHOnWWVwsgS8ikwS+iCjKbifrgfvp2LuXhrffIOWaUXj3N9Pwz73df2Dq18Gw9TpefnZRUr8uwIJAt86mCunWEZFJAl9EHNf555Nw3lyqH3kEW7YiYUY2zcsquh96wZUJ46+CDS+Cp7nb5WUXufG0+qg73HeIS7eOiGQS+CIiZT3wAGZ7O1V/+CPu+QUou5X6t0u7P2tnxh3gaYTiV7tfVmHgwG1/zseXbh0RySTwRURyFBWRevNN1L/2Gt59u0i6JB/Prnrat9ac3Hj4TMieCKuf7Ha4hZTOC7D6ewesSydKt46ITBL4ImKl33svlqQkDv/q18SfnYM1K576d8rQ3hMO4CoV2Muv3AL7Vpy0HGUosgr7fwesSydKt46ITBL4ImJZkpLI+M63aV2zhuYPPyD5iiL8te00LetmrJ2J1wVG01zd/SmaWYVJ1B5swdPW912tpFtHRCoJfBHRkq+7DseYMRz88Y/xHdqKc3waTf8qx99wws1K7PGBMXZKFkHToZOWk13kBt2/O2DBsW6d8lrp1hGRQwJfRDRlsTD8z49iy82l/K67UP7NaFPT8G7ZyY1n3AamD9Y/f9JbWYVJnRdgnVq3zjuyly8iSFACXyk1Xym1XSm1Syn1QDfvK6XUHzvf36SUmhqM9QoBYBs2jBEvvIBrzhwqH/oJythL64YqPHtP2FtPOwPOuBDWPnPS+DqOzguw+nPFLUi3johMAw58pZQFeARYAIwDvqyUGndCswXAqM7HncCfB7peIbqyuBLIe/QRUr/+dRrf+L9os4X6t3aefDHVjDug6QBsf+ekZWQVujlc1tCvC7BAunVE5LEGYRkzgV1a61IApdTLwJXA1i5trgSe14GTpFcqpZKVUjlaa9k9EifRptnzKJjdtdcavw6Me5/y/X9HDc+j/vlXUMY3qHt/M/HnFR5rnDsbEkbA8sch7/zjlpOWbaWkpYODOw+SnBnX53ovzHfye18Li1aU8NVzCvpdrxD94U5LC/oygxH4uUB5l9cVwNn9aJMLSOCL49RUlPPqz/6D1ob6gS0oBS5qryB9CbQu+fyENx+BGuBXxcfNTQOuTHFgPrOb2n6sIg74wJoDS1tpXLq1z/ZC9FebvwX3b+YHfbnBCHzVzbwTd8/60ybQUKk7CXT7kJ+fP7DKRETRWvPRU4/i93mZdf3NqG5/bI7ZUbeTf5V/jFKKSemTsCjLce+vb1jLGVX7UCf2XGoNfk+3P4E+XGgsJ7/RY8193jpXiFNmKh+jGJqBXwEM7/I6DzhwGm0A0Fo/DjwOMH36dPlViiHbli+hfGsxF912L1O+eGmP7dp8bTy8+mHeaH6DKWdP4eHzHmaYa1gIKxUiMgUj8NcAo5RShcB+4EbgphPaLALu6+zfPxtokP570ZWntYUlf32KrKJRTLp4Xo/tdtbt5AdLfkBpQym3T7yde6fci82whbBSISLXgANfa+1TSt0HvA9YgKe11luUUnd3vv8YsBi4FNgFtAK3DnS9Irp89tqLtDTUc9UPHsQwuu9SWbhrIT9f+XNcNhePXfIYs4bNCnGVQkS2YOzho7VeTCDUu857rMu0Br4ZjHWJ6FO1t4zP3/sHky6aR/bI0d22KW8s5yef/YRpWdN4+LyHSY9LD3GVQkQ+udJWhJU2TT586s84E1zM+fLXe2z35OYnsRpWHpr7kIS9EKdJAl+E1ZZPP+bA9q3MvfkW4lyJ3bbZ37yfRbsWce3oa8mIzwhxhUJEDwl8ETbtzc18+sIz5Iwey4TzL+6x3VPFT6GU4tbxcuhHiIGQwBdhs+zl52lvauLi2+5FGd3/KB5qOcTfd/2dq0ddTVZCVogrFCK6SOCLsKjcU8rGD99lyvzLyCwo6rHdU8VPAXDbhNtCVZoQUUsCX4RF8cfvY7XZmXXdzT22qWyt5M2db3LlGVeS48oJYXVCRCcJfBFypt/PjpXLKZo6A2eCq8d2z2x+Br/2c/vE20NYnRDRSwJfhFz5lmJaG+oZO/u8HttUt1Xz2o7XuOKMK8hLzAthdUJELwl8EXLbPluCPS6OwinTe2zz3Jbn8Jpe7ph4RwgrEyK6SeCLkPJ5vexc/RkjZ5yL1W7vtk1tey2vbH+FSwsvJd8tI6YKESwS+CKk9m5aj6elhbGzeu7OeX7L87T72rljkuzdCxFMEvgipLYt/xSnK5H8iVO6fb+6rZqXtr3E/IL5FCX1fLqmEOLUSeCLkPF62tm9dhWjz56NxXryuH1aax5c/iB+7eeeKfeEoUIhopsEvgiZ0vVr8XraGdNDd84r219h2f5lfG/69yhMKuy2jRDi9Engi5DZtnwJCSmp5I0bf9J7pfWl/Hbtb5mdO5sbx9wYhuqEiH4S+CIkPK0tlG1Yy5hz5px0gxOv38sDSx8g3hrPL2b/AqV6v5etEOL0BOUGKEL0Zdealfi93m67cx7Z8AgltSX8/oLfy1j3Qgwi2cMXIbH9s09xZ2SSM2rMcfPXHlrL05uf5ppR13BR/kVhqk6I2CCBLwZda2MDe4s3MGbWecd11zR1NPGjZT8iLzGPH874YRgrFCI2SJeOGHS7Vq/A9PtPutjqV6t+RWVrJc8teI54W3yYqhMidsgevhh025YvIWVYHhkjjp1q+dqO13i79G3umnQXkzMmh7E6IWKHBL4YVM21NZSXbGbsrLlHu3PeLXuXn6/4OXNy58jwCUKEkAS+GFTbVywFrY+enbOkfAk/WvojpmVN43df+B1WQ3oVhQgVCXwxaLzt7az5x5sMG30mabnDWX1wNd/95LuMTR3Lny78E06rM9wlChFTJPDFoFn7zt9pqavlvJtvZVPVJu77+D7y3fn8+eI/47L3fKcrIcTgkL+nxaBoqa9jzaI3GTnjXJozLdzz/h2kx6Xz+CWPk+xMDnd5QsQk2cMXg2LF6y/i93ZQcMVF3PXBXTitTp744hNkxGeEuzQhYpYEvgi6mv3lbProfRxTC7l9zbfQaJ744hPkunLDXZoQMU0CXwTd+889is9i8rT7X5ydczavXv6q3MxEiCFA+vBF0PhNP8+89zsaNhZTMq6Nn1z0Cy4vulxGvxRiiJDAF0Gxs24nP/3sJwxfWEVKQjy/+vbz5CRLF44QQ4kEvjhtXtPLJ+Wf8Mq2V1h1aBXjqtLJaEhg3j3fkrAXYgiSwBenrLK1kjd2vMHrO16nsq2SnIQc/s+k+zCfXEHciETGnXdBuEsUQnRDAl/0SWvNnsY9rD64muUHlvNpxaf4tZ/ZubN5cMyDzM2dy+eLF7Gkupp5d337pDtaCSGGBgl8cRKtNQdaDrDm0BpWHVzF6oOrqWyrBCA7IZuvnPkVrh9zPfnufAAqtm1h2cvPUzhlGgWTzgpn6UKIXgwo8JVSqcArQAGwB7hea113QpvhwPNANmACj2ut/zCQ9Yrg8Pq9HGo5RGlDKbsbdlNaX0ppQ+DR4m0BINWZyszsmczMmcnZ2WczPHH4cWfd1OwvZ+FvfoE7PZMF930vXJsihOiHge7hPwB8pLV+SCn1QOfr+09o4wO+p7Ver5RKBNYppT7QWm8d4LpFF17TS7uvnRZvC40djTR6GmnqaKLJ20Sjp5E6Tx1VrVVUtlVS1VpFVWsVdZ7jvptJj0vnjKQzuKLoCs5IPoOpWVMZlTyqx9MqW+rrePPXP8WwWLj6P/6buER3KDZVCHGaBhr4VwJf6Jx+DviEEwJfa30QONg53aSUKgFygUEL/Fe3v4rX9J7SZ7TWgWd0t6+7a6fRaK2P+0zXeVprTMzAszbRBJ5PfPi1H1Ob+Ewffu0/+uw3/XhNL17TS4e/47hpj99Du6+ddl87bb42fNrX6/YZyiDdmU5GfAbDXMOYnDGZjPgMsuOzKUwqpDCpkCRHUr//f3W0t/H3h/+b1sZ6bvjJQyRnZff7s0KI8Bho4Gd1Bjpa64NKqczeGiulCoCzgFW9tLkTuBMgPz//tIr67drf0uZrO63PDgaFQimFgYGhjn8opbAoS+BhWLAqKxYj8NpqWLEZNmwWG3bDTrw1HpvFhs2w4bQ6cVqcxFnjiLPG4bQ6cVgcuGwu3A43ifZEEu2JuG3Hpi1BOphq+v28/buHqCwr5aofPkj2GaOCslwhxODqM/CVUh8S6H8/0X+eyoqUUi7gDeA7WuvGntpprR8HHgeYPn267qldb/55zT/7qqVf7ytOeD5h/pF5RwL9yH8ojoZ7tF1lqrXmwycfoWzDOi654z6Kps4Id0lCiH7qM/C11hf39J5S6rBSKqdz7z4HqOyhnY1A2L+gtX7ztKvtJxl+d3BorVnx+ksUf/xPzrn6BiZdPD/cJQkhTsFAB09bBHy9c/rrwMITG6jALu5TQInW+n8GuD4RJm3NTbz9u4dY8fqLjDvvQmZd/5VwlySEOEUD7cN/CHhVKXUbsA+4DkApNQx4Umt9KTAb+CpQrJTa0Pm5H2mtFw9w3SJE9m3eyLuP/A+tDQ3MvekWpl/xpajrqhIiFgwo8LXWNcBF3cw/AFzaOb0MkHSIQD6vl+Wv/JW1b/+dlJxcbvrBg2QVjQx3WUKI0yRX2opu1VSU886ffkPVnlImX7KA8796GzaH3HRciEgmgS+OU7O/nPWLF7JlyUfY4+K56ocPcsa0s8NdlhAiCCTwBVpr9hVvZN3ityj7fC0Wm41xcy9g9g1fJSE5JdzlCSGCRAI/hnW0tbJj5XLWLV5I9b49xCclM+u6m5l8yQLik5LDXZ4QIsgk8GOINk0q95SyZ+N69mxaz4HtJZh+P+n5Bcy7+9uMnX0+Vrs93GUKIQaJBH4Ua29ppqZ8H9Xle9i/vYS9mz6ntaEegIyCIqZd/iWKpkwn98zxcpqlEDFAAj+Caa3paGulqaaa5ppqGmuqqTu4n+ryvVSX76W5pvpo27hENyMmnUXB5KkUTJ4qffNCxCAJ/DAy/X78Xi8+bwdejwevpx2fx4O3vR2vJ/Bob2mmvbm587kJT3Mz7S1NNNfW0lRbg7f9+EHiLFYrqXn5DB83kfThI0jPH0H68BEkpmXIXrwQMS4qA//9x/6I3+cFffxQx0ccfa27DH6sdedrDfpIG9052wy8d+RhmoGPmH5M00SbgXlam2jTxPSbmKYf0+/H9PuOvfb58Hu9gYfPF1huP1msVpyuRBwJLpwJLtKHj6BgyjQSU9NwpabhSksnMTWdxLR0DIvcYlAIcbKoDPyDO7fh83YAXUa27LJzG9jTPTK/y9iXSh0bEVOpY+8ZgVEvlTJQxrERMZVhwTAMDIsFZbWiDANlGEfnGRZr4NkwMKyBaYvNhsXa+bBZsVhtWG02rA4nNqcTm8OJzeEIPDudOBNcOF0urHaH7KELIQYkKgP/lv/3aLhLEEKIIWego2UKIYSIEBL4QggRIyTwhRAiRkjgCyFEjJDAF0KIGCGBL4QQMUICXwghYoQEvhBCxAh14rADQ4lSqgrYG+46TlE6UN1nq+gi2xwbZJsjwwitdUZ3bwzpwI9ESqm1Wuvp4a4jlGSbY4Nsc+STLh0hhIgREvhCCBEjJPCD7/FwFxAGss2xQbY5wkkfvhBCxAjZwxdCiBghgS+EEDFCAl8IIWKEBH6IKaUSlFLrlFKXh7uWUFBKXaWUekIptVAp9cVw1zNYOv9dn+vc1pvDXU8oxMq/bVeR/vsrgd9PSqmnlVKVSqnNJ8yfr5TarpTapZR6oB+Luh94dXCqDK5gbLPW+i2t9R3ALcANg1hu0J3i9l8NvN65rf8W8mKD5FS2OZL/bY84jZ/xiPn97Y4Efv89C8zvOkMpZQEeARYA44AvK6XGKaUmKqXePuGRqZS6GNgKHA518afpWQa4zV0++uPOz0WSZ+nn9gN5QHlnM38Iawy2Z+n/Nh8Rif+2RzxL/3/GI+339yRReRPzwaC1/lQpVXDC7JnALq11KYBS6mXgSq31r4GT/uRTSl0AJBD4IWpTSi3WWpuDW/npC9I2K+Ah4F2t9fpBLjmoTmX7gQoCob+BCN6ROpVtVkqVEKH/tkec4r+xiwj6/e2OBP7A5HJsrw4Cv/Rn99RYa/2fAEqpW4DqSPth6XRK2wx8C7gYSFJKjdRaPzaYxYVAT9v/R+B/lVKXAf8IR2GDqKdtjrZ/2yO63V6t9X0Q2b+/EvgDo7qZ1+eVbFrrZ4NfSsic0jZrrf9IIAyjRbfbr7VuAW4NdTEh0tM2R9u/7RG9/oxH8u9vxP7pOURUAMO7vM4DDoSpllCJxW3uKha3P9a2OWq3VwJ/YNYAo5RShUopO3AjsCjMNQ22WNzmrmJx+2Ntm6N2eyXw+0kp9RKwAhijlKpQSt2mtfYB9wHvAyXAq1rrLeGsM5hicZu7isXtj7VtjrntlcHThBAiNsgevhBCxAgJfCGEiBES+EIIESMk8IUQIkZI4AshRIyQwBdCiBghgS+EEDFCAl8IIWKEBL4QQsSI/w+6QcN1jACu9gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-34.59703199 -30.79543532  19.31018182 -19.44809959]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[43.92269956 20.29212653 25.94887054 31.22240214]]\n",
      "30.346524692219862\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[-0.78768, -1.51760513, 0.74416271, -0.62288928]])\n",
    "y = np.array([[-34.59703199, -30.79543532, 19.31018182, -19.44809959]])\n",
    "\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression().fit(X, y)\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)\n",
    "\n",
    "print(y/X)\n",
    "print(np.mean(y/X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Quizz\n",
    "\n",
    "Quizz de salaud, destiné à piéger plus qu'à valider l'assimilation des connaissances essentielles.\n",
    "\n",
    "Q1\n",
    "\n",
    "Par exemple, la première question porte sur des caractéristiques non explicitées dans la synthèse du cours :\n",
    "\n",
    "Normalité du bruit : je ne me souviens pas avoir entendu parler du bruit.\n",
    "\n",
    "Les observation sont 'iid' : je ne me souviens pas avoir entendu parler de cet iid.\n",
    "https://www.youtube.com/watch?v=hZ5FOYIkFtw\n",
    "\n",
    "* Independent\n",
    "* Indentically\n",
    "* Distributed\n",
    "\n",
    "observations\n",
    "\n",
    "-> restrictions on dependance, heterogeneity, \n",
    "\n",
    "Q3 - Il suffit d'appliquer la formule $\\beta = (X^\\top X)^{-1}X^\\top y$\n",
    "\n",
    "La source de ce dont il fallait se souvenir est le [3.2 Programmez votre proemière régression linéaire du cours Initiez-vous au Machine Learning](https://openclassrooms.com/fr/courses/4011851-initiez-vous-au-machine-learning/4121986-programmez-votre-premiere-regression-lineaire) :\n",
    "* $\\hat{y} = x^\\top\\theta$, avec $x^\\top = (x_1, x_2, \\cdots, x_n)$ et $\\hat{y}^\\top = (\\hat{y}_1, \\hat{y}_2, \\cdots, \\hat{y}_n)$\n",
    "* ... pas limpide\n",
    "* mais un renvoi sur une démonstration de la solution de de la minimisation : $\\beta = \\hat{\\theta}= (X^\\top X)^{-1}X^\\top y$ : https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression\n",
    "\n",
    "-> C'est de là que je dois repartir pour approfondir sur le plan mathémtique, mais il me faudrait une vraie ressource de référence qui couvre tout de A à Z, pour pouvoir me programmer un chemin d'apprentissage.\n",
    "\n",
    "\n",
    "ok, mais si on attend ce niveau de maîtrise du formel, le cours devrait donner des liens vers des ressources de révision d'algèbre linéaire ciblées, et ce n'est pas le cas.\n",
    "\n",
    "Q5 - c'est vraiment une question piège.. j'ai hésité : c'est donc la recherche sur grille (qui se charge d'observer l'erreur en fonction de lambda pour trouver son minimum)\n",
    "\n",
    "Q7 - réponses multiples, mais une seule à sélectionner (pour la première fois) : j'ai pris le risque et ne suis pas tombé dans le panneau.\n",
    "\n",
    "Q9 - faute de frappe de ma part, sinon j'aurais validé le quizz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ((4, 1)) : [[-0.78768   ]\n",
      " [-1.51760513]\n",
      " [ 0.74416271]\n",
      " [-0.62288928]]\n",
      "X^T ((1, 4)) : [[-0.78768    -1.51760513  0.74416271 -0.62288928]]\n",
      "X^T.X : [[3.86533431]]\n",
      "(X^T.X)^-1 : [[0.25870983]]\n",
      "(X^T.X)^-1.X^T : [[-0.20378056 -0.39261937  0.19252221 -0.16114758]]\n",
      "(X^T.X)^-1.X^T.Y : [[25.99274029]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(X)\\nprint(X**2)\\nprint(np.sum(X**2))\\nX = X.reshape(4, 1)\\nY = Y.reshape(1, 4)\\nprint(X)\\nprint(X.shape)\\nprint(Y.shape)\\nprint(X.dot(Y))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commencer par recalculer Q3 à la main sur papier et ensuite à l'aide de numpy\n",
    "import numpy as np\n",
    "X = np.array([-0.78768, -1.51760513, 0.74416271, -0.62288928]).reshape(4, 1)\n",
    "Y = np.array([-34.59703199, -30.79543532, 19.31018182, -19.44809959]).reshape(4, 1)\n",
    "print(f'X ({X.shape}) :', X)\n",
    "print(f'X^T ({X.reshape(1, 4).shape}) :', X.reshape(1, 4))\n",
    "print('X^T.X :', X.reshape(1, 4).dot(X))\n",
    "print('(X^T.X)^-1 :', np.linalg.inv(X.reshape(1, 4).dot(X)))\n",
    "print('(X^T.X)^-1.X^T :', np.linalg.inv(X.reshape(1, 4).dot(X)).dot(X.reshape(1, 4)))\n",
    "print('(X^T.X)^-1.X^T.Y :', np.linalg.inv(X.reshape(1, 4).dot(X)).dot(X.reshape(1, 4)).dot(Y))\n",
    "\n",
    "\n",
    "\"\"\"print(X)\n",
    "print(X**2)\n",
    "print(np.sum(X**2))\n",
    "X = X.reshape(4, 1)\n",
    "Y = Y.reshape(1, 4)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X.dot(Y))\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 [Prédisez linéairement la probabilité de l’appartenance d’un point à une classe](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire/4507831-predisez-lineairement-la-probabilite-de-l-appartenance-d-un-point-a-une-classe)\n",
    "\n",
    "Classification binaire : être ou ne pas être.\n",
    "\n",
    "Les explications ne sont pas super intuitives, donc je reformule à ma manière :\n",
    "\n",
    "Objectif : adapter les méthode de régression à la classification binaire.\n",
    "\n",
    "Appartenir vs. ne pas appartenir à la classe peut se représenter à l'aide de l'ensemble {0, 1}\n",
    "\n",
    "Déjà avec deux variables voit mal un modèle linéaire fonctionner pour prédire $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 = 0 | 1$\n",
    "\n",
    "D'autre part, une fonction linéaire a pour image un ensemble continu compris entre $-\\infty$ et $+\\infty$.\n",
    "\n",
    "L'idée principale est non pas de prédire de manière discrète l'appartenance ou non à la classe, mais de prédire la probabilité d'appartenance $P(Y=1|x)$.\n",
    "\n",
    "En outre, une probabilité n'a pas un comportement linéaire.\n",
    "\n",
    "Pour interfacer les deux mondes : la fonction logistique (la fonction de seuil du neurone) :\n",
    "\n",
    "$\\text{Logistic}(u) = \\left(\\frac{1}{1 + e^{-u}}\\right)$\n",
    "\n",
    "\n",
    "Transforme une image liénaire en une image comprise entre 0 et 1 qui a le comportement d'une probabilité.\n",
    "\n",
    "$P(Y=1|x) = \\text{Logistic} \\left( \\displaystyle\\sum_{j=1}^p \\beta_j x_j + \\beta_0 \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20330263a00>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "u = np.linspace(-10, 10, 100)\n",
    "y = 1 / (1 + np.exp(-u))\n",
    "plt.plot(u, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgré son nom, la régression logistique sert à résoudre des problèmes de classification.\n",
    "\n",
    "Comme pour la régression linaire, il va s'agir de maximiser la vraisemblance.\n",
    "\n",
    "Là, elle dit souvenez-vous, mais j'ai le sentiment de ne pas me souvenir : quand, quelle partie de cours ?\n",
    "\n",
    "vraisemblance :\n",
    "* $p\\left(\\mathcal{D}|\\beta\\right)$, avec $\\mathcal{D}=\\{x^i, y^i\\}_{i=1, \\cdots, n}$\n",
    "* (condition iid) $p\\left(\\mathcal{D}|\\beta\\right) = \\displaystyle\\prod_{i=1}^n p\\left(x^i, y^i|\\beta\\right)$\n",
    "* $= \\displaystyle\\prod_{i=1}^n p\\left(y^i|x^i, \\beta\\right)p\\left(x^i\\right)$\n",
    "\n",
    "$p\\left(x^i\\right)$ indépendant de $\\beta$, il s'agit donc de maximiser :\n",
    "\n",
    "$\\displaystyle\\max_{\\beta \\in \\mathbb{R}^{p+1}} \\prod_{i=1}^n p\\left(y^i|x^i, \\beta\\right)$\n",
    "\n",
    "Passage à une somme grâce au log :\n",
    "\n",
    "$\\displaystyle\\max_{\\beta \\in \\mathbb{R}^{p+1}} \\sum_{i=1}^n \\log{p\\left(y^i|x^i, \\beta\\right)}$\n",
    "\n",
    "Là, je surnage..\n",
    "\n",
    "Dans notre cas :\n",
    "\n",
    "$\\displaystyle\\max_{\\beta \\in \\mathbb{R}^{p+1}} \\sum_{i=1}^n y^i \\log{\\left(p(Y=1|x^i)\\right)} + (1-y^i)\\log{\\left(1 - p(Y=0|x^i)\\right)}$\n",
    "\n",
    "Il me faut un cours qui explique mieux !\n",
    "\n",
    "Reste à remplacer les deux probabilités par leur expression logistique :\n",
    "\n",
    "$\\displaystyle\\max_{\\beta \\in \\mathbb{R}^{p+1}} \\sum_{i=1}^n y^i \\log{\\left(\\frac{1}{1 + e^{-(\\beta^\\top x^i)}} \\right)} + (1-y^i)\\log{\\left(\\frac{1}{1 + e^{-(\\beta^\\top x^i)}}\\right)}$\n",
    "\n",
    "Pas de solution explicite.\n",
    "\n",
    "Mais expression concave -> on peut utiliser la méthode du gradient pour trouver une bonne approximation.\n",
    "\n",
    "Les techniques de régularisation qui permettent d'obtenir des modèles parcimonieux et d'éviter le surapprentissage s'appliquent également à la régression logistique.\n",
    "\n",
    "Au chapitre suivant, autre technique pour créer un classificateur linéaire avec le SVM.\n",
    "\n",
    "https://fr.wikipedia.org/wiki/Fonction_logistique_(Verhulst)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_function : permet d'approfondir\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 [Maximisez la marge de séparation entre vos classes](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire/4507841-maximisez-la-marge-de-separation-entre-vos-classes)\n",
    "\n",
    "\n",
    "Vu comment séparer deux classes à l'aide d'une méthode linéaire avec la régression logistique.\n",
    "\n",
    "Autres méthodes pour déterminer le meilleur hyperplan qui sépare deux classes.\n",
    "\n",
    "L'une d'entre elles : SVM (*Support Vector Machines*).\n",
    "\n",
    "On démarre avec le cas **linéairement séparable** : en 2D, cela signifie qu'il existe une droite qui sépare les points des deux classes. Par ext., en nD, il existe un hyperplan.\n",
    "\n",
    "NB > une ne veut pas dire unique : il en existe même une infinité. En revanche, elles ne donnent évidemment pas les mêmes prédictions.\n",
    "\n",
    "Quelle est la droite (l'hyperplan) idéal parmi toutes les possibilités ?\n",
    "\n",
    "\n",
    "Pour une droite (un hyperplan) donnée, on définit une zone (un tube) dont le rayon est la distance (perpendiculaire) au point le plus proche. On appelle cette zone, **la marge**.\n",
    "\n",
    "L'idée du SVM, est de choisir parmi l'ensemble des droites possibles celle dont la marge est la plus grande.\n",
    "\n",
    "Chercher la droite à plus grande marge justifie l'expression parfois employée en français pour le SVM, *Séparatrice à Vaste Marge*.\n",
    "\n",
    "Notons que si la marge est en contact avec un ou plusieurs plus proches de l'une des deux classes, mais pas de l'autre, il suffit de la déplacer sur une position parallèle qui la rapproche de l'autre classe de telle sorte que la marge soit plus large et en contact avec un point de cette autre classe. La droite est donc exactement à mi chemin entre les deux frontières de sa marge (les parois du tube), lesquelles sont toutes deux en contact avec un point de chacune des deux classes.\n",
    "\n",
    "Les points de contact qui définissent la droite sont appelés **vecteur de support**, ce qui donne son nom à la méthode.\n",
    "\n",
    "Formalisation :\n",
    "* un jeu de données avec $n$ points et $p$ variables : $X \\in \\mathbb{R}^{n \\times p}$\n",
    "* un ensemble d'étiquettes : $y \\in \\{-1, 1\\}^n$\n",
    "\n",
    "\n",
    "On cherche l'hyperplan séparateur qui a la plus grande marge.\n",
    "\n",
    "L'équation de cet hyperplan est $\\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b = 0$, où $\\left<., .\\right>$ est le **produit scalaire** des deux vecteurs de support $\\boldsymbol{w}$ et $\\boldsymbol{x}$.\n",
    "\n",
    "Là, elle ne dit pas explicitement qui sont $\\boldsymbol{w}$ et $\\boldsymbol{x}$, et je suppose que ce sont les deux points de contact.\n",
    "\n",
    "Les deux parois sont parallèles à l'hyperplan séprateur et donc d'équation $\\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b = cste$\n",
    "\n",
    "En outre, l'hyperplan est à mi-distance de ces deux parois, ce qui entraîne que les deux $cste$ sont opposées.\n",
    "\n",
    "On fixe par convention ces deux constantes à -1 et 1.\n",
    "\n",
    "Les points appartenant aux deux classes sont resp. les points tq :\n",
    "* $\\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b \\gt 1$\n",
    "* $\\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b \\lt -1$\n",
    "\n",
    "<mark>A réviser</mark> :\n",
    "* produit scalaire\n",
    "* équation d'un hyperplan\n",
    "\n",
    "Ces équations étant posées, on peut déterminer le diamètre $\\gamma$ de la marge.\n",
    "\n",
    "Son rayon $\\gamma/2$ est la distance entre un point B de la droite et sa projection A sur l'une des deux parois du tube.\n",
    "\n",
    "$\\gamma = 2||A - B|| = \\frac{2}{||\\boldsymbol{w}||}$\n",
    "\n",
    "<mark>**NB**</mark> > là, c'est le coup du chapeau magique : j'ai besoin de comprendre pourquoi, mais les explications ne me le permettent pas.\n",
    "\n",
    "Nous cherchons donc $\\displaystyle\\max_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\frac{2}{||\\boldsymbol{w}||}$\n",
    "\n",
    "La fonction de décision avec ce modèle : $f(\\boldsymbol{x}) = \\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b$\n",
    "\n",
    "Suivant le signe de la fonction, la prédiction est dite **positive** ou **négative**.\n",
    "\n",
    "Retour au jeu d'entraînement :\n",
    "* prédiction positive : $f(\\boldsymbol{x}) \\ge 1 \\Rightarrow y = 1$\n",
    "* prédiction négative : $f(\\boldsymbol{x}) \\le -1 \\Rightarrow y = -1$\n",
    "\n",
    "On peut réunir les deux cas en une seule formulation : $yf(\\boldsymbol{x}) \\ge 1$\n",
    "\n",
    "En résumé, nous cherchons $\\displaystyle\\max_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\frac{2}{||\\boldsymbol{w}||}$ sous la contrainte $y\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}\\right> + b\\right) \\ge 1$\n",
    "\n",
    "Pour des raisons pratiques, on cherche $\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\frac{1}{2}||\\boldsymbol{w}||^2$, ce qui est équivalent.\n",
    "\n",
    "Résumé du problème d'optimisation :\n",
    "* $X \\in \\mathbb{R}^{n \\times p}$\n",
    "* $y \\in \\{-1, 1\\}^n$\n",
    "* $\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\frac{1}{2}||\\boldsymbol{w}||^2$ tq $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\ge 1, \\forall i \\in \\{1, \\cdots, n\\}$\n",
    "\n",
    "Par les **multiplicateurs de Lagrange**, ce problème à $n$ contraintes est équivalent à celui-ci :\n",
    "\n",
    "<mark>A \"réviser\"</mark> :\n",
    "* multiplicateurs de Lagrange\n",
    "\n",
    "\n",
    "$\\displaystyle\\max_{\\alpha \\in \\mathbb{R}^n_+} \\left( \\displaystyle\\min_{\\substack{\\boldsymbol{w} \\in \\mathbb{R}^p\\\\b \\in \\mathbb{R}}} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2  - \\displaystyle\\sum_{i=1}^n \\alpha_i \\left( y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) - 1 \\right) \\right) \\right)$ (A)\n",
    "\n",
    "<mark>La suite est hardcore et cela ne fait pas partie des notions de niveau license (de mon époque)</mark>\n",
    "\n",
    "On a introduit un nouveau terme réel $\\alpha_i$ pour chacun des points du jeu d'entraînement.\n",
    "\n",
    "L'équivalence entre les deux lignes est vraie sous les conditions de **Karush-Kuhn-Tucker** (*KKT*) : soit $\\alpha_i$, soit l'autre terme sous la somme, $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) - 1$ est égal à 0.\n",
    "\n",
    "<mark>A nouveau un saut de raisonnement non vraiment justifié et totalement incompréhensible sans les bases nécessaires :</mark>\n",
    "\n",
    "En posant $L_p = \\frac{1}{2}||\\boldsymbol{w}||^2  - \\displaystyle\\sum_{i=1}^n \\alpha_i \\left( y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) - 1 \\right)$\n",
    "\n",
    "Résoudre la condition KKT revient à déterminer $\\boldsymbol{w}$ tq $\\nabla_{\\boldsymbol{w}} L_p = 0$ et de même $\\nabla_b L_p = 0$\n",
    "\n",
    "On obtient les équations suivantes :\n",
    "* $\\nabla_{\\boldsymbol{w}} L_p = 0 \\Rightarrow \\boldsymbol{w} = \\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} \\boldsymbol{x}^{(i)}$\n",
    "* $\\nabla_b L_p = 0 \\Rightarrow \\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} = 0$\n",
    "\n",
    "Ce qui permet de reformuler (A) de la manière suivante :\n",
    "\n",
    "$\\displaystyle\\max_{\\alpha \\in \\mathbb{R}^n_+} \\left( -\\frac{1}{2} \\displaystyle\\sum_{i=1}^n \\displaystyle\\sum_{j=1}^n \\alpha_i \\alpha_j y^{(i)} y^{(j)}\\left<\\boldsymbol{x}^{(i)}, \\boldsymbol{x}^{(j)}\\right> + \\displaystyle\\sum_{i=1}^n \\alpha_i \\right)$ tq $\\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} = 0$\n",
    "\n",
    "\n",
    "Nous disposons de deux formulations équivalentes du problème de maximisation de la marge.\n",
    "* $\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\frac{1}{2}||\\boldsymbol{w}||^2$ tq $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\ge 1, \\forall i \\in \\{1, \\cdots, n\\}$\n",
    "* $\\displaystyle\\max_{\\alpha \\in \\mathbb{R}^n_+} \\left( -\\frac{1}{2} \\displaystyle\\sum_{i=1}^n \\displaystyle\\sum_{j=1}^n \\alpha_i \\alpha_j y^{(i)} y^{(j)}\\left<\\boldsymbol{x}^{(i)}, \\boldsymbol{x}^{(j)}\\right> + \\displaystyle\\sum_{i=1}^n \\alpha_i \\right)$ tq $\\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} = 0$\n",
    "\n",
    "La première formulation s'appelle le **primal**, et la seconde, le **dual**.\n",
    "\n",
    "NB > le primal est un problème d'optimisation en $p$ dimensions tandis que le dual est un problème d'optimisation en $n$ dimensions.\n",
    "\n",
    "Cela permet de choisir l'une ou l'autre des deux méthodes pour des raisons de performance :\n",
    "* on choisit le primal avec un problème en faible dimension,\n",
    "* et le dual avec un problème qui comporte peu d'instances.\n",
    "\n",
    "<mark>Là, elle me largue à nouveau :</mark>\n",
    "\n",
    "Les conditions KKT : $\\alpha_i = 0$ ou $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) - 1 = 0$\n",
    "\n",
    "permettent de mieux comprendre les vecteurs de support :\n",
    "\n",
    "Soit $\\alpha_i = 0$ et alors $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\gt 1$, ce qui correspond à des points qui ne sont pas sur la frontière de la marge.\n",
    "\n",
    "Soit $\\alpha_i \\gt 0$ et alors $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) = 1$, ce qui correspond à une observation située exactement sur la frontière.\n",
    "\n",
    "En d'autres termes, les points pour lesquels $\\alpha_i \\gt 0$ sont les vecteurs de support.\n",
    "\n",
    "Si on revient à $\\nabla_{\\boldsymbol{w}} L_p = 0 \\Rightarrow \\boldsymbol{w} = \\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} \\boldsymbol{x}^{(i)}$, on peut voir que $\\boldsymbol{w}$ ne dépend que des points pour lesquels $\\alpha_i \\ne 0$, c'est-à-dire des vecteurs de support.\n",
    "\n",
    "\n",
    "Cela peut également se comprendre d'un point de vue géométrique : $\\boldsymbol{w} = \\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} \\boldsymbol{x}^{(i)}$ exprime le fait que déplacer un point éloigné de l'hyperplan n'influence pas sa position, tandis que déplacer l'un des points vecteur de support, modifie la solution.\n",
    "\n",
    "Cela conclut la présentation du principe de la SVM.\n",
    "\n",
    "\n",
    "Reste à traiter le cas où les points ne sont pas séparables.\n",
    "\n",
    "<mark>Là, je trouve le saut sur l'erreur un peu rapide. J'aimerais une explication un peu plus formelle et moins intuitive de la notion de séparabilité</mark>\n",
    "\n",
    "On cherche à minimiser  $\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2 + \\text{err} \\right)$, ce qui rapelle les méthodes de régularisation de la régression linéaire. Traditionnement, avec la SVM, ce terme est dénoté par $C$.\n",
    "\n",
    "Comment mesurer cette erreur : perte Hinge (*Hinge loss*) : on compare à 1 le produit de l'étiquette par sa valeur prédite $yf(\\boldsymbol{x})$. Rappel : on cherche $yf(\\boldsymbol{x}) \\ge 1$:\n",
    "* Si c'est le cas, la perte est nulle.\n",
    "* Sinon, elle est d'autant plus grande que $yf(\\boldsymbol{x}) \\lt 1$\n",
    "\n",
    "$l_{\\text{hinge}}(y, f(\\boldsymbol{x}))$\n",
    "\n",
    "Le problème à résoudre devient :\n",
    "\n",
    "$\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2 + C\\displaystyle\\sum_{i=1}^n l_{\\text{hinge}}(y^{(i)}, f(\\boldsymbol{x}^{(i)})) \\right)$ tq $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\ge 1, \\forall i \\in \\{1, \\cdots, n\\}$\n",
    "\n",
    "Cette formulation s'appelle le **SVM à marge souple** (*soft-margin SVM*)\n",
    "\n",
    "La perte Hinge est difficile à minimiser, et on la remplace par un terme réel $\\xi$ :\n",
    "\n",
    "$\\displaystyle\\min_{\\boldsymbol{w} \\in \\mathbb{R}^p} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2 + C\\displaystyle\\sum_{i=1}^n \\xi_i \\right)$ tq $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\ge 1 - \\xi_i, \\forall i \\in \\{1, \\cdots, n\\}$\n",
    "\n",
    "$\\xi_i$ est une variable d'ajustement et correspond à la distance entre 1 et $y^{(i)}f(\\boldsymbol{x}^{(i)})$.\n",
    "\n",
    "Comme pour le cas linéairement séparable, ce primal possède un dual qui ne diffère que par la contrainte que $\\alpha_i \\le C$ :\n",
    "\n",
    "$\\displaystyle\\max_{\\alpha \\in \\mathbb{R}^n_+} \\left( -\\frac{1}{2} \\displaystyle\\sum_{i=1}^n \\displaystyle\\sum_{j=1}^n \\alpha_i \\alpha_j y^{(i)} y^{(j)}\\left<\\boldsymbol{x}^{(i)}, \\boldsymbol{x}^{(j)}\\right> + \\displaystyle\\sum_{i=1}^n \\alpha_i \\right)$ tq $\\displaystyle\\sum_{i=1}^n \\alpha_i y^{(i)} = 0$ et $0 \\le \\alpha_i \\le C$\n",
    "\n",
    "Il y a à présent 3 cas possibles pour le coefficient $\\alpha_i$ associé à l'observation $\\boldsymbol{x}^{(i)}$ :\n",
    "* $\\alpha_i = 0$ : $\\boldsymbol{x}^{(i)}$ ne contribue pas à la frontière de décision.\n",
    "* $\\alpha_i = C$ : $\\boldsymbol{x}^{(i)}$ est un point mal classifié.\n",
    "* $0 \\lt \\alpha_i \\lt C$ : $\\boldsymbol{x}^{(i)}$ est un vecteur de support.\n",
    "\n",
    "Bilan comparatif avec la régression logistique qui est l'autre classificateur binaire liénaire :\n",
    "* Dans les deux cas, séparation des données avec un hyperplan\n",
    "* Perte hinge vs. perte logistique \n",
    "* SVM n'utilise que les points proches de l'hyperplan, alors que la régression logistique utilise tous les points du jeu de données. Cf. la médiane vs. la moyenne, la SVM est moins sensible aux outliers dont données aberrantes.\n",
    "* La régression logistique retourne directement la probabilité qu'un point appartienne à l'une des deux classes, alors que la SVM retourne un score plus difficile à interpréter en termes de probabilité.\n",
    "\n",
    "Prochain chapitre : résoudre des problèmes de classification multi-classes.\n",
    "\n",
    "<mark>Lectures Wikipedia complémentaires</mark> :\n",
    "* [SVM.en](https://en.wikipedia.org/wiki/Support-vector_machine) et [SVM.fr](https://fr.wikipedia.org/wiki/Machine_%C3%A0_vecteurs_de_support)\n",
    "* [dot product](https://en.wikipedia.org/wiki/Dot_product) et [produit scalaire](https://fr.wikipedia.org/wiki/Produit_scalaire)\n",
    "* [quadratic programming](https://en.wikipedia.org/wiki/Quadratic_programming) et [optimisation quadratique](https://fr.wikipedia.org/wiki/Optimisation_quadratique)\n",
    "* [Karush-Kuhn-Tucker conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions) et [Conditions de Karush-Kuhn-Tucker](https://fr.wikipedia.org/wiki/Conditions_de_Karush-Kuhn-Tucker)\n",
    "* [Lagrange multiplier](https://en.wikipedia.org/wiki/Lagrange_multiplier) et [Multiplicateur de Lagrange](https://fr.wikipedia.org/wiki/Multiplicateur_de_Lagrange)\n",
    "* perte hinge (charnière)\n",
    "* [hyperplane](https://en.wikipedia.org/wiki/Hyperplane) et [hyperplan](https://fr.wikipedia.org/wiki/Hyperplan)\n",
    "* [linear classifier](https://en.wikipedia.org/wiki/Linear_classifier) et [classifieur liénaire](https://fr.wikipedia.org/wiki/Classifieur_lin%C3%A9aire)\n",
    "* [Optimisation linéaire](https://fr.wikipedia.org/wiki/Optimisation_lin%C3%A9aire)\n",
    "\n",
    "\n",
    "NB > dans la catégorie des classifieurs linéaires, il y aura aussi le perceptron, le classifieur bayesien, la LDA.\n",
    "\n",
    "NB > pour le cas non séparable, elle a parlé de marge souple, mais totalement zappé l'astuce du noyau (kernel trick).\n",
    "\n",
    "\n",
    "* **[Cours du MIT sur le SVM (49 ')](https://www.youtube.com/watch?v=_PwhiWxHK8o)**\n",
    "\n",
    "\n",
    "<mark>Il faudra revenir sur ce chapitre après avoir pratiqué dans le cadre du projet et d'autres exercices</mark>\n",
    "\n",
    "<mark>Je pense que c'est un chapitre pour ségreguer entre ceux qui décrochent et ceux qui ne décrochent pas</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 [Classifiez vos données en plus de deux classes](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire/4507846-classifiez-vos-donnees-en-plus-de-deux-classes)\n",
    "\n",
    "Chapitre précédent : classifications binaires avec séparateurs linéaires.\n",
    "\n",
    "Comment étendre à des problèmes de classification multiclasses.\n",
    "\n",
    "* $X \\in \\mathbb{R}^{n \\times p}$\n",
    "* $y \\in \\{0, 1, 2 \\cdots, K - 1\\}^n$\n",
    "\n",
    "**Première méthode** : Un contre les autres (*One-vs-rest* (**OVR**)) ou Un contre tous (*One-vs-all* (**OVA**))\n",
    "\n",
    "On exprime le problème $K$ fois en termes de classification binaire : la classe $i$ vs toutes les autres classes.\n",
    "\n",
    "Soit : $k$ classifieurs binaires $f_0, f_1, \\cdots, f_{K - 1}$.\n",
    "\n",
    "Complexité :\n",
    "* Entraînement : soit $\\mathcal{C}_n$ la complexité d'entraînement d'un classifieur binaire, alors la complexité est $\\mathcal{O}(K\\mathcal{C}_n)$ \n",
    "* Prédiction : $\\mathcal{O}(K\\mathcal{C}_{\\text{pred}})$\n",
    "\n",
    "Seconde méthode : Un contre un (*One-vs-one* (**OVO**))\n",
    "\n",
    "Spération binaire de claque couple de classes, en ignorant les points des autres classes.\n",
    "\n",
    "Cela fait donc $\\frac{1}{2}n(n-1)$ classifieurs binaires $f_{kl}, 0 \\le k \\lt l \\le K - 1$.\n",
    "\n",
    "En effet $f_{kl} = -f_{lk}$\n",
    "\n",
    "Prédiction finale : vote de la majorité\n",
    "\n",
    "La classe est celle pour laquelle le plus de classifieurs binaires s'accordent à désigner comme la bonne.\n",
    "\n",
    "$f(\\boldsymbol{x}) = \\arg \\displaystyle\\max_k \\displaystyle\\sum_l f_{kl} (\\boldsymbol{x})$\n",
    "\n",
    "Complexité : Elle devient quadratique mais la complexité d'entraînement est diminuée puisque chaque classifieur binaire n'est plus entraîné que sur $\\frac{n}{K}$ points : $\\mathcal{O}(K^2\\mathcal{C}_{\\frac{n}{K}})$\n",
    "\n",
    "Peut-être intéressant si $n$ est grand et que l'algorithme utilisé a une complexité polynomiale en le nombre d'observations. <mark>Là franchement elle abuse : ce n'est pas assez précis tout en faisant référence à des notions de complexité que de nombreux étudiants ne connaîtront pas</mark>\n",
    "\n",
    "Prédiction : $\\mathcal{O}(K^2\\mathcal{C}_{\\text{pred}})$\n",
    "\n",
    "Ces deux méthodes (algorithmes) s'appliquent indépendamment des classifieurs utilisés, qui ne sont d'ailleurs pas nécessairement linénaires.\n",
    "\n",
    "Cas particulier des SVM (à marge souple) :\n",
    "\n",
    "$\\displaystyle\\min_{\\substack{\\boldsymbol{w} \\in \\mathbb{R}^p \\\\ b \\in \\mathbb{R} \\\\ \\boldsymbol{\\xi} \\in \\mathbb{R}^n_+}} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2 + C\\displaystyle\\sum_{i=1}^n \\xi_i \\right)$ tq $y^{(i)}\\left(\\left<\\boldsymbol{w}, \\boldsymbol{x}^{(i)}\\right> + b\\right) \\ge 1 - \\xi_i, \\forall i \\in \\{1, \\cdots, n\\}$\n",
    "\n",
    "$f(\\boldsymbol{x}) = \\left<\\boldsymbol{w}, \\, \\boldsymbol{x} \\right> + b$\n",
    "\n",
    "Construction d'un SVM multiclasse cf. paradigme OVA :\n",
    "\n",
    "construction de $K$ SVMs dépendant d'un poids $\\boldsymbol{w}_k$ et d'un scalaire $b_k$ :\n",
    "$f_k(\\boldsymbol{x}) = \\left<\\boldsymbol{w}_k, \\, \\boldsymbol{x} \\right> + b_k$\n",
    "\n",
    "Mais plutôt que de construire ces $K$ SVMs indépendamment les unes des autres, on peut les construire simultanément :\n",
    "\n",
    "<mark>Là, ce n'est même pas la peine, pour saisir avec ses explications, il faut sortir de Normal Sup</mark>\n",
    "\n",
    "$\\displaystyle\\min_{\\substack{\\boldsymbol{w} \\in \\mathbb{R}^{K \\times p} \\\\ b \\in \\mathbb{R}^K \\\\ \\boldsymbol{\\xi} \\in \\mathbb{R}^n_+}} \\left( \\frac{1}{2}||\\boldsymbol{w}||^2 + C\\displaystyle\\sum_{i=1}^n \\xi_i \\right)$\n",
    "tq\n",
    "$y^{(i)}\n",
    "    \\left(\\left<\\boldsymbol{w}_{y^{(i)}}, \\boldsymbol{x}^{(i)}\\right> + b_{y^{(i)}}\\right) \\ge\n",
    "    \\left(\\left<\\boldsymbol{w}_k, \\boldsymbol{x}^{(i)}\\right> + b_k\\right) +\n",
    "    \\left(1 - \\xi_i\\right),\n",
    "    \\forall i \\in \\{1, \\cdots, n\\}, \\forall k \\ne y^{(i)}$\n",
    "\n",
    "\n",
    "* $\\left(\\left<\\boldsymbol{w}_{y^{(i)}}, \\boldsymbol{x}^{(i)}\\right> + b_{y^{(i)}}\\right)$ : prédiction pour la vraie classe\n",
    "* $\\left(\\left<\\boldsymbol{w}_k, \\boldsymbol{x}^{(i)}\\right> + b_k\\right)$ : prédiction pour une autre classe\n",
    "* $\\left(1 - \\xi_i\\right)$ : terme d'erreur\n",
    "\n",
    "$f(\\boldsymbol{x}) = \\arg \\displaystyle\\max_k f_k (\\boldsymbol{x})$\n",
    "\n",
    "\n",
    "Il existe également des méthodes intrinsèquement multiclasses (prochain cours).\n",
    "\n",
    "Tous les problèmes ne se résolvent pas avec de la classification liénaire --> classifieurs non linéaires.\n",
    "\n",
    "<mark>Il faudra revenir sur ce chapitre, même s'il est beaucoup moins pointu que le précédent</mark>\n",
    "\n",
    "Le chapitre suivant est un énorme TP + une invitation à suivre les chapitres 20 à 27 de Machine Learnia : ça tombe bien, j'en suis exactement là.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 [TP - Entraînez une régression logistique et une SVM linéaire](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire/4507851-tp-entrainez-une-regression-logistique-et-une-svm-lineaire)\n",
    "\n",
    "\n",
    "TP basé sur le dataset Kaggle [Mushroom Classification](https://www.kaggle.com/datasets/uciml/mushroom-classification)\n",
    "\n",
    "Objectifs pédagogiques :\n",
    "1. Comprendre et analyser les données\n",
    "2. Préparer les données et entraîner un classifieur naïf\n",
    "3. Entraîner une régression logistique et une SVM\n",
    "4. Améliorer nos modèles\n",
    "\n",
    "But : savoir si des champignons sont commestibles ou non\n",
    "\n",
    "Epistémologie du ML :\n",
    "* Supervisé\n",
    "    - Régression\n",
    "    - Classification\n",
    "        - Binaire\n",
    "        - Multiple\n",
    "* Non supervisé\n",
    "* Semi supervisé\n",
    "* Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et inspection du dataframe\n",
    "\n",
    "8 124 x 23, a priori, juste des codes alphabétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0        p         x           s         n       t    p               f   \n",
       "1        e         x           s         y       t    a               f   \n",
       "2        e         b           s         w       t    l               f   \n",
       "3        p         x           y         w       t    p               f   \n",
       "4        e         x           s         g       f    n               f   \n",
       "...    ...       ...         ...       ...     ...  ...             ...   \n",
       "8119     e         k           s         n       f    n               a   \n",
       "8120     e         x           s         n       f    n               a   \n",
       "8121     e         f           s         n       f    n               a   \n",
       "8122     p         k           y         n       f    y               f   \n",
       "8123     e         x           s         n       f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0               c         n          k  ...                        s   \n",
       "1               c         b          k  ...                        s   \n",
       "2               c         b          n  ...                        s   \n",
       "3               c         n          n  ...                        s   \n",
       "4               w         b          k  ...                        s   \n",
       "...           ...       ...        ...  ...                      ...   \n",
       "8119            c         b          y  ...                        s   \n",
       "8120            c         b          y  ...                        s   \n",
       "8121            c         b          n  ...                        s   \n",
       "8122            c         n          b  ...                        k   \n",
       "8123            c         b          y  ...                        s   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                         w                      w         p          w   \n",
       "1                         w                      w         p          w   \n",
       "2                         w                      w         p          w   \n",
       "3                         w                      w         p          w   \n",
       "4                         w                      w         p          w   \n",
       "...                     ...                    ...       ...        ...   \n",
       "8119                      o                      o         p          o   \n",
       "8120                      o                      o         p          n   \n",
       "8121                      o                      o         p          o   \n",
       "8122                      w                      w         p          w   \n",
       "8123                      o                      o         p          o   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat  \n",
       "0              o         p                 k          s       u  \n",
       "1              o         p                 n          n       g  \n",
       "2              o         p                 n          n       m  \n",
       "3              o         p                 k          s       u  \n",
       "4              o         e                 n          a       g  \n",
       "...          ...       ...               ...        ...     ...  \n",
       "8119           o         p                 b          c       l  \n",
       "8120           o         p                 b          v       l  \n",
       "8121           o         p                 b          c       l  \n",
       "8122           o         e                 w          v       l  \n",
       "8123           o         p                 o          c       l  \n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('mushrooms.csv')\n",
    "display(data)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe plein, pas de NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()  # df plein, aucun NA, tout objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fréquences des modalités sont comprises entre 21 % et 100 % (constante `veil-type`).\n",
    "\n",
    "Pour 14 variables, 1 seule classe (dénotée par une modalité) domine de plus de 50 % toutes les autres réunies.\n",
    "\n",
    "Le nombre de classes (modalités) pour une variable donné est compris entre 1 (`veil-type`) et 12 (``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>veil-type</th>\n",
       "      <td>8124</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>8124</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>w</td>\n",
       "      <td>7924</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-attachment</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>7914</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-number</th>\n",
       "      <td>8124</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>7488</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-spacing</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>6812</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-size</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>5612</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>5176</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>4936</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruises</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>4748</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-shape</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>4608</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>4464</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>4384</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>4208</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>8124</td>\n",
       "      <td>6</td>\n",
       "      <td>v</td>\n",
       "      <td>4040</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-type</th>\n",
       "      <td>8124</td>\n",
       "      <td>5</td>\n",
       "      <td>p</td>\n",
       "      <td>3968</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-root</th>\n",
       "      <td>8124</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>3776</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-shape</th>\n",
       "      <td>8124</td>\n",
       "      <td>6</td>\n",
       "      <td>x</td>\n",
       "      <td>3656</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>n</td>\n",
       "      <td>3528</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-surface</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>y</td>\n",
       "      <td>3244</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitat</th>\n",
       "      <td>8124</td>\n",
       "      <td>7</td>\n",
       "      <td>d</td>\n",
       "      <td>3148</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore-print-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>2388</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>10</td>\n",
       "      <td>n</td>\n",
       "      <td>2284</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>12</td>\n",
       "      <td>b</td>\n",
       "      <td>1728</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique top  freq    %\n",
       "veil-type                 8124      1   p  8124  100\n",
       "veil-color                8124      4   w  7924   98\n",
       "gill-attachment           8124      2   f  7914   97\n",
       "ring-number               8124      3   o  7488   92\n",
       "gill-spacing              8124      2   c  6812   84\n",
       "gill-size                 8124      2   b  5612   69\n",
       "stalk-surface-above-ring  8124      4   s  5176   64\n",
       "stalk-surface-below-ring  8124      4   s  4936   61\n",
       "bruises                   8124      2   f  4748   58\n",
       "stalk-shape               8124      2   t  4608   57\n",
       "stalk-color-above-ring    8124      9   w  4464   55\n",
       "stalk-color-below-ring    8124      9   w  4384   54\n",
       "class                     8124      2   e  4208   52\n",
       "population                8124      6   v  4040   50\n",
       "ring-type                 8124      5   p  3968   49\n",
       "stalk-root                8124      5   b  3776   46\n",
       "cap-shape                 8124      6   x  3656   45\n",
       "odor                      8124      9   n  3528   43\n",
       "cap-surface               8124      4   y  3244   40\n",
       "habitat                   8124      7   d  3148   39\n",
       "spore-print-color         8124      9   w  2388   29\n",
       "cap-color                 8124     10   n  2284   28\n",
       "gill-color                8124     12   b  1728   21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "freqs = data.describe(include='all').T.sort_values(by='freq', ascending=False)\n",
    "freqs['%'] = round(100 * (freqs.freq.astype(np.int32) / 8124)).round(0).astype(np.int32)\n",
    "display(freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profils des distributions fréquentielles des modalités\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu</th>\n",
       "      <th>a_0</th>\n",
       "      <th>n_0</th>\n",
       "      <th>f_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>n_1</th>\n",
       "      <th>f_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>n_2</th>\n",
       "      <th>f_2</th>\n",
       "      <th>...</th>\n",
       "      <th>f_8</th>\n",
       "      <th>a_9</th>\n",
       "      <th>n_9</th>\n",
       "      <th>f_9</th>\n",
       "      <th>a_10</th>\n",
       "      <th>n_10</th>\n",
       "      <th>f_10</th>\n",
       "      <th>a_11</th>\n",
       "      <th>n_11</th>\n",
       "      <th>f_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>-0.430608</td>\n",
       "      <td>e</td>\n",
       "      <td>4208.0</td>\n",
       "      <td>0.517971442639094</td>\n",
       "      <td>p</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>0.48202855736090594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-shape</th>\n",
       "      <td>1.277899</td>\n",
       "      <td>x</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>0.4500246184145741</td>\n",
       "      <td>f</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>0.3879862136878385</td>\n",
       "      <td>k</td>\n",
       "      <td>828.0</td>\n",
       "      <td>0.1019202363367799</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-surface</th>\n",
       "      <td>-0.004316</td>\n",
       "      <td>y</td>\n",
       "      <td>3244.0</td>\n",
       "      <td>0.3993106843919252</td>\n",
       "      <td>s</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>0.31462333825701627</td>\n",
       "      <td>f</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>0.28557360905957657</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-color</th>\n",
       "      <td>1.943082</td>\n",
       "      <td>n</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>0.2811422944362383</td>\n",
       "      <td>g</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>0.22648941408173315</td>\n",
       "      <td>e</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.18463810930576072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0019694731659281144</td>\n",
       "      <td>r</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0019694731659281144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruises</th>\n",
       "      <td>-0.211036</td>\n",
       "      <td>f</td>\n",
       "      <td>4748.0</td>\n",
       "      <td>0.5844411619891678</td>\n",
       "      <td>t</td>\n",
       "      <td>3376.0</td>\n",
       "      <td>0.4155588380108321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor</th>\n",
       "      <td>2.697279</td>\n",
       "      <td>n</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>0.4342688330871492</td>\n",
       "      <td>f</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>0.2658788774002954</td>\n",
       "      <td>y</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.07090103397341212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004431314623338257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-attachment</th>\n",
       "      <td>0.473465</td>\n",
       "      <td>f</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>0.9741506646971935</td>\n",
       "      <td>a</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0258493353028065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-spacing</th>\n",
       "      <td>0.307399</td>\n",
       "      <td>c</td>\n",
       "      <td>6812.0</td>\n",
       "      <td>0.8385032003938946</td>\n",
       "      <td>w</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>0.16149679960610536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-size</th>\n",
       "      <td>0.052388</td>\n",
       "      <td>b</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>0.690792712949286</td>\n",
       "      <td>n</td>\n",
       "      <td>2512.0</td>\n",
       "      <td>0.30920728705071393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-color</th>\n",
       "      <td>1.798611</td>\n",
       "      <td>b</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>0.21270310192023634</td>\n",
       "      <td>p</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>0.18365337272279667</td>\n",
       "      <td>w</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>0.1479566715903496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011816838995568686</td>\n",
       "      <td>y</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.010585918266863614</td>\n",
       "      <td>o</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.007877892663712457</td>\n",
       "      <td>r</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0029542097488921715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-shape</th>\n",
       "      <td>-0.263021</td>\n",
       "      <td>t</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>0.5672082717872969</td>\n",
       "      <td>e</td>\n",
       "      <td>3516.0</td>\n",
       "      <td>0.4327917282127031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-root</th>\n",
       "      <td>0.848517</td>\n",
       "      <td>b</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>0.464795667159035</td>\n",
       "      <td>?</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0.3052683407188577</td>\n",
       "      <td>e</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.137863121614968</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <td>0.930448</td>\n",
       "      <td>s</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.637124569177745</td>\n",
       "      <td>k</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>0.2919743968488429</td>\n",
       "      <td>f</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.06794682422451995</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <td>0.854133</td>\n",
       "      <td>s</td>\n",
       "      <td>4936.0</td>\n",
       "      <td>0.6075824716888233</td>\n",
       "      <td>k</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>0.28360413589364847</td>\n",
       "      <td>f</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.07385524372230429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <td>3.180108</td>\n",
       "      <td>w</td>\n",
       "      <td>4464.0</td>\n",
       "      <td>0.5494830132939439</td>\n",
       "      <td>p</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>0.23042836041358936</td>\n",
       "      <td>g</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.07090103397341212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009847365829640572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <td>3.146898</td>\n",
       "      <td>w</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>0.5396356474643033</td>\n",
       "      <td>p</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>0.23042836041358936</td>\n",
       "      <td>g</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.07090103397341212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0029542097488921715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil-type</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>p</td>\n",
       "      <td>8124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil-color</th>\n",
       "      <td>1.474760</td>\n",
       "      <td>w</td>\n",
       "      <td>7924.0</td>\n",
       "      <td>0.9753815854258986</td>\n",
       "      <td>n</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.011816838995568686</td>\n",
       "      <td>o</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.011816838995568686</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-number</th>\n",
       "      <td>0.915064</td>\n",
       "      <td>o</td>\n",
       "      <td>7488.0</td>\n",
       "      <td>0.9217134416543574</td>\n",
       "      <td>t</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.07385524372230429</td>\n",
       "      <td>n</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.004431314623338257</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-type</th>\n",
       "      <td>0.952621</td>\n",
       "      <td>p</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.48842934515017233</td>\n",
       "      <td>e</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>0.3417035942885278</td>\n",
       "      <td>l</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>0.15952732644017725</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore-print-color</th>\n",
       "      <td>1.597990</td>\n",
       "      <td>w</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.29394387001477107</td>\n",
       "      <td>n</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>0.24224519940915806</td>\n",
       "      <td>k</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>0.23042836041358936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005908419497784343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>1.489109</td>\n",
       "      <td>v</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>0.49729197439684886</td>\n",
       "      <td>y</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>0.21073362875430823</td>\n",
       "      <td>s</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.1536189069423929</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitat</th>\n",
       "      <td>1.419314</td>\n",
       "      <td>d</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>0.38749384539635645</td>\n",
       "      <td>g</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>0.26440177252584934</td>\n",
       "      <td>p</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>0.14081733136386015</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mu a_0     n_0                  f_0  a_1  \\\n",
       "class                    -0.430608   e  4208.0    0.517971442639094    p   \n",
       "cap-shape                 1.277899   x  3656.0   0.4500246184145741    f   \n",
       "cap-surface              -0.004316   y  3244.0   0.3993106843919252    s   \n",
       "cap-color                 1.943082   n  2284.0   0.2811422944362383    g   \n",
       "bruises                  -0.211036   f  4748.0   0.5844411619891678    t   \n",
       "odor                      2.697279   n  3528.0   0.4342688330871492    f   \n",
       "gill-attachment           0.473465   f  7914.0   0.9741506646971935    a   \n",
       "gill-spacing              0.307399   c  6812.0   0.8385032003938946    w   \n",
       "gill-size                 0.052388   b  5612.0    0.690792712949286    n   \n",
       "gill-color                1.798611   b  1728.0  0.21270310192023634    p   \n",
       "stalk-shape              -0.263021   t  4608.0   0.5672082717872969    e   \n",
       "stalk-root                0.848517   b  3776.0    0.464795667159035    ?   \n",
       "stalk-surface-above-ring  0.930448   s  5176.0    0.637124569177745    k   \n",
       "stalk-surface-below-ring  0.854133   s  4936.0   0.6075824716888233    k   \n",
       "stalk-color-above-ring    3.180108   w  4464.0   0.5494830132939439    p   \n",
       "stalk-color-below-ring    3.146898   w  4384.0   0.5396356474643033    p   \n",
       "veil-type                 0.000000   p  8124.0                  1.0  NaN   \n",
       "veil-color                1.474760   w  7924.0   0.9753815854258986    n   \n",
       "ring-number               0.915064   o  7488.0   0.9217134416543574    t   \n",
       "ring-type                 0.952621   p  3968.0  0.48842934515017233    e   \n",
       "spore-print-color         1.597990   w  2388.0  0.29394387001477107    n   \n",
       "population                1.489109   v  4040.0  0.49729197439684886    y   \n",
       "habitat                   1.419314   d  3148.0  0.38749384539635645    g   \n",
       "\n",
       "                             n_1                   f_1  a_2     n_2  \\\n",
       "class                     3916.0   0.48202855736090594  NaN     NaN   \n",
       "cap-shape                 3152.0    0.3879862136878385    k   828.0   \n",
       "cap-surface               2556.0   0.31462333825701627    f  2320.0   \n",
       "cap-color                 1840.0   0.22648941408173315    e  1500.0   \n",
       "bruises                   3376.0    0.4155588380108321  NaN     NaN   \n",
       "odor                      2160.0    0.2658788774002954    y   576.0   \n",
       "gill-attachment            210.0    0.0258493353028065  NaN     NaN   \n",
       "gill-spacing              1312.0   0.16149679960610536  NaN     NaN   \n",
       "gill-size                 2512.0   0.30920728705071393  NaN     NaN   \n",
       "gill-color                1492.0   0.18365337272279667    w  1202.0   \n",
       "stalk-shape               3516.0    0.4327917282127031  NaN     NaN   \n",
       "stalk-root                2480.0    0.3052683407188577    e  1120.0   \n",
       "stalk-surface-above-ring  2372.0    0.2919743968488429    f   552.0   \n",
       "stalk-surface-below-ring  2304.0   0.28360413589364847    f   600.0   \n",
       "stalk-color-above-ring    1872.0   0.23042836041358936    g   576.0   \n",
       "stalk-color-below-ring    1872.0   0.23042836041358936    g   576.0   \n",
       "veil-type                    NaN                   NaN  NaN     NaN   \n",
       "veil-color                  96.0  0.011816838995568686    o    96.0   \n",
       "ring-number                600.0   0.07385524372230429    n    36.0   \n",
       "ring-type                 2776.0    0.3417035942885278    l  1296.0   \n",
       "spore-print-color         1968.0   0.24224519940915806    k  1872.0   \n",
       "population                1712.0   0.21073362875430823    s  1248.0   \n",
       "habitat                   2148.0   0.26440177252584934    p  1144.0   \n",
       "\n",
       "                                           f_2  ...                    f_8  \\\n",
       "class                                      NaN  ...                    NaN   \n",
       "cap-shape                   0.1019202363367799  ...                    NaN   \n",
       "cap-surface                0.28557360905957657  ...                    NaN   \n",
       "cap-color                  0.18463810930576072  ...  0.0019694731659281144   \n",
       "bruises                                    NaN  ...                    NaN   \n",
       "odor                       0.07090103397341212  ...   0.004431314623338257   \n",
       "gill-attachment                            NaN  ...                    NaN   \n",
       "gill-spacing                               NaN  ...                    NaN   \n",
       "gill-size                                  NaN  ...                    NaN   \n",
       "gill-color                  0.1479566715903496  ...   0.011816838995568686   \n",
       "stalk-shape                                NaN  ...                    NaN   \n",
       "stalk-root                   0.137863121614968  ...                    NaN   \n",
       "stalk-surface-above-ring   0.06794682422451995  ...                    NaN   \n",
       "stalk-surface-below-ring   0.07385524372230429  ...                    NaN   \n",
       "stalk-color-above-ring     0.07090103397341212  ...  0.0009847365829640572   \n",
       "stalk-color-below-ring     0.07090103397341212  ...  0.0029542097488921715   \n",
       "veil-type                                  NaN  ...                    NaN   \n",
       "veil-color                0.011816838995568686  ...                    NaN   \n",
       "ring-number               0.004431314623338257  ...                    NaN   \n",
       "ring-type                  0.15952732644017725  ...                    NaN   \n",
       "spore-print-color          0.23042836041358936  ...   0.005908419497784343   \n",
       "population                  0.1536189069423929  ...                    NaN   \n",
       "habitat                    0.14081733136386015  ...                    NaN   \n",
       "\n",
       "                          a_9   n_9                    f_9 a_10  n_10  \\\n",
       "class                     NaN   NaN                    NaN  NaN   NaN   \n",
       "cap-shape                 NaN   NaN                    NaN  NaN   NaN   \n",
       "cap-surface               NaN   NaN                    NaN  NaN   NaN   \n",
       "cap-color                   r  16.0  0.0019694731659281144  NaN   NaN   \n",
       "bruises                   NaN   NaN                    NaN  NaN   NaN   \n",
       "odor                      NaN   NaN                    NaN  NaN   NaN   \n",
       "gill-attachment           NaN   NaN                    NaN  NaN   NaN   \n",
       "gill-spacing              NaN   NaN                    NaN  NaN   NaN   \n",
       "gill-size                 NaN   NaN                    NaN  NaN   NaN   \n",
       "gill-color                  y  86.0   0.010585918266863614    o  64.0   \n",
       "stalk-shape               NaN   NaN                    NaN  NaN   NaN   \n",
       "stalk-root                NaN   NaN                    NaN  NaN   NaN   \n",
       "stalk-surface-above-ring  NaN   NaN                    NaN  NaN   NaN   \n",
       "stalk-surface-below-ring  NaN   NaN                    NaN  NaN   NaN   \n",
       "stalk-color-above-ring    NaN   NaN                    NaN  NaN   NaN   \n",
       "stalk-color-below-ring    NaN   NaN                    NaN  NaN   NaN   \n",
       "veil-type                 NaN   NaN                    NaN  NaN   NaN   \n",
       "veil-color                NaN   NaN                    NaN  NaN   NaN   \n",
       "ring-number               NaN   NaN                    NaN  NaN   NaN   \n",
       "ring-type                 NaN   NaN                    NaN  NaN   NaN   \n",
       "spore-print-color         NaN   NaN                    NaN  NaN   NaN   \n",
       "population                NaN   NaN                    NaN  NaN   NaN   \n",
       "habitat                   NaN   NaN                    NaN  NaN   NaN   \n",
       "\n",
       "                                          f_10 a_11  n_11  \\\n",
       "class                                      NaN  NaN   NaN   \n",
       "cap-shape                                  NaN  NaN   NaN   \n",
       "cap-surface                                NaN  NaN   NaN   \n",
       "cap-color                                  NaN  NaN   NaN   \n",
       "bruises                                    NaN  NaN   NaN   \n",
       "odor                                       NaN  NaN   NaN   \n",
       "gill-attachment                            NaN  NaN   NaN   \n",
       "gill-spacing                               NaN  NaN   NaN   \n",
       "gill-size                                  NaN  NaN   NaN   \n",
       "gill-color                0.007877892663712457    r  24.0   \n",
       "stalk-shape                                NaN  NaN   NaN   \n",
       "stalk-root                                 NaN  NaN   NaN   \n",
       "stalk-surface-above-ring                   NaN  NaN   NaN   \n",
       "stalk-surface-below-ring                   NaN  NaN   NaN   \n",
       "stalk-color-above-ring                     NaN  NaN   NaN   \n",
       "stalk-color-below-ring                     NaN  NaN   NaN   \n",
       "veil-type                                  NaN  NaN   NaN   \n",
       "veil-color                                 NaN  NaN   NaN   \n",
       "ring-number                                NaN  NaN   NaN   \n",
       "ring-type                                  NaN  NaN   NaN   \n",
       "spore-print-color                          NaN  NaN   NaN   \n",
       "population                                 NaN  NaN   NaN   \n",
       "habitat                                    NaN  NaN   NaN   \n",
       "\n",
       "                                           f_11  \n",
       "class                                       NaN  \n",
       "cap-shape                                   NaN  \n",
       "cap-surface                                 NaN  \n",
       "cap-color                                   NaN  \n",
       "bruises                                     NaN  \n",
       "odor                                        NaN  \n",
       "gill-attachment                             NaN  \n",
       "gill-spacing                                NaN  \n",
       "gill-size                                   NaN  \n",
       "gill-color                0.0029542097488921715  \n",
       "stalk-shape                                 NaN  \n",
       "stalk-root                                  NaN  \n",
       "stalk-surface-above-ring                    NaN  \n",
       "stalk-surface-below-ring                    NaN  \n",
       "stalk-color-above-ring                      NaN  \n",
       "stalk-color-below-ring                      NaN  \n",
       "veil-type                                   NaN  \n",
       "veil-color                                  NaN  \n",
       "ring-number                                 NaN  \n",
       "ring-type                                   NaN  \n",
       "spore-print-color                           NaN  \n",
       "population                                  NaN  \n",
       "habitat                                     NaN  \n",
       "\n",
       "[23 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def super_freqs(data):\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "    rows = []\n",
    "    q = []  # alphabets sizes\n",
    "    q_max = 0\n",
    "    for label, values in data.items():\n",
    "        vc = pd.DataFrame(values.value_counts())\n",
    "        q += [vc.size]\n",
    "        if vc.size > q_max:\n",
    "            q_max = vc.size\n",
    "        vc['%'] = vc[vc.columns[0]] / n\n",
    "        row = np.array([[m, v[0], v[1]] for m, v in vc.T.items()]).ravel()\n",
    "        #display(vc.T)\n",
    "        rows += [row]\n",
    "\n",
    "    display(q_max)\n",
    "    columns = np.array([[f'a_{k}', f'n_{k}', f'f_{k}'] for k in range(q_max)]).ravel()\n",
    "    df = pd.DataFrame(index=data.columns, columns=columns)\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, e in enumerate(row):\n",
    "            df.iloc[i, j] = row[j]\n",
    "\n",
    "    # calcul de mu\n",
    "    n_0 = df.n_0.astype(float).astype(np.int32).values\n",
    "    q = np.array(q)\n",
    "    mu = (1/2) * (q - 1) - (n - n_0) / n_0\n",
    "    df.insert(0, 'mu', mu)\n",
    "    display(df)\n",
    "\n",
    "\n",
    "# le next step serait une grille de petits barplots, avec l'identité et le rappel de mu\n",
    "# TODO : mais ce sera plus tard, je dois me refocus sur les objectifs - ici, faire ce TP\n",
    "\n",
    "super_freqs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vidéo 2/5 EDA (Exploratory Data Analysis)\n",
    "\n",
    "4 objectifs :\n",
    "1. Charger nos données (et vérifier libs)\n",
    "2. Comprendre la structure de nos données\n",
    "3. Evaluer la qualité globale de nos données\n",
    "4. Effectuer un premier cleaning de nos données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Pandas\n",
    "* Numpy\n",
    "* Scikit-learn\n",
    "* Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_list = ('pandas', 'numpy', 'matplotlib', 'scikit-learn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.4.2\n",
      "numpy 1.21.5\n",
      "matplotlib 3.5.1\n",
      "scikit-learn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "#! python3 -v\n",
    "#txt = !python3 -m pip freeze\n",
    "# les magic-commands ne fonctionnent visiblement pas avec VS Code\n",
    "# alternative avec importlib\n",
    "from importlib.metadata import version\n",
    "for p in package_list:\n",
    "    print(p, version(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.makedirs('data/source')\n",
    "os.makedirs('data/cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned', 'source']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0        p         x           s         n       t    p               f   \n",
       "1        e         x           s         y       t    a               f   \n",
       "2        e         b           s         w       t    l               f   \n",
       "3        p         x           y         w       t    p               f   \n",
       "4        e         x           s         g       f    n               f   \n",
       "...    ...       ...         ...       ...     ...  ...             ...   \n",
       "8119     e         k           s         n       f    n               a   \n",
       "8120     e         x           s         n       f    n               a   \n",
       "8121     e         f           s         n       f    n               a   \n",
       "8122     p         k           y         n       f    y               f   \n",
       "8123     e         x           s         n       f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0               c         n          k  ...                        s   \n",
       "1               c         b          k  ...                        s   \n",
       "2               c         b          n  ...                        s   \n",
       "3               c         n          n  ...                        s   \n",
       "4               w         b          k  ...                        s   \n",
       "...           ...       ...        ...  ...                      ...   \n",
       "8119            c         b          y  ...                        s   \n",
       "8120            c         b          y  ...                        s   \n",
       "8121            c         b          n  ...                        s   \n",
       "8122            c         n          b  ...                        k   \n",
       "8123            c         b          y  ...                        s   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                         w                      w         p          w   \n",
       "1                         w                      w         p          w   \n",
       "2                         w                      w         p          w   \n",
       "3                         w                      w         p          w   \n",
       "4                         w                      w         p          w   \n",
       "...                     ...                    ...       ...        ...   \n",
       "8119                      o                      o         p          o   \n",
       "8120                      o                      o         p          n   \n",
       "8121                      o                      o         p          o   \n",
       "8122                      w                      w         p          w   \n",
       "8123                      o                      o         p          o   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat  \n",
       "0              o         p                 k          s       u  \n",
       "1              o         p                 n          n       g  \n",
       "2              o         p                 n          n       m  \n",
       "3              o         p                 k          s       u  \n",
       "4              o         e                 n          a       g  \n",
       "...          ...       ...               ...        ...     ...  \n",
       "8119           o         p                 b          c       l  \n",
       "8120           o         p                 b          v       l  \n",
       "8121           o         p                 b          c       l  \n",
       "8122           o         e                 w          v       l  \n",
       "8123           o         p                 o          c       l  \n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './data/source'\n",
    "filename = 'mushrooms.csv'\n",
    "data = pd.read_csv(os.path.join(path, filename))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "object    23\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class                        2\n",
       "cap-shape                    6\n",
       "cap-surface                  4\n",
       "cap-color                   10\n",
       "bruises                      2\n",
       "odor                         9\n",
       "gill-attachment              2\n",
       "gill-spacing                 2\n",
       "gill-size                    2\n",
       "gill-color                  12\n",
       "stalk-shape                  2\n",
       "stalk-root                   5\n",
       "stalk-surface-above-ring     4\n",
       "stalk-surface-below-ring     4\n",
       "stalk-color-above-ring       9\n",
       "stalk-color-below-ring       9\n",
       "veil-type                    1\n",
       "veil-color                   4\n",
       "ring-number                  3\n",
       "ring-type                    5\n",
       "spore-print-color            9\n",
       "population                   6\n",
       "habitat                      7\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.info())\n",
    "display(data.dtypes.value_counts())\n",
    "display(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       0\n",
       "cap-shape                   0\n",
       "cap-surface                 0\n",
       "cap-color                   0\n",
       "bruises                     0\n",
       "odor                        0\n",
       "gill-attachment             0\n",
       "gill-spacing                0\n",
       "gill-size                   0\n",
       "gill-color                  0\n",
       "stalk-shape                 0\n",
       "stalk-root                  0\n",
       "stalk-surface-above-ring    0\n",
       "stalk-surface-below-ring    0\n",
       "stalk-color-above-ring      0\n",
       "stalk-color-below-ring      0\n",
       "veil-type                   0\n",
       "veil-color                  0\n",
       "ring-number                 0\n",
       "ring-type                   0\n",
       "spore-print-color           0\n",
       "population                  0\n",
       "habitat                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.isna().sum())\n",
    "display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
       "0         1          5            2          4        1     6   \n",
       "1         0          5            2          9        1     0   \n",
       "2         0          0            2          8        1     3   \n",
       "3         1          5            3          8        1     6   \n",
       "4         0          5            2          3        0     5   \n",
       "...     ...        ...          ...        ...      ...   ...   \n",
       "8119      0          3            2          4        0     5   \n",
       "8120      0          5            2          4        0     5   \n",
       "8121      0          2            2          4        0     5   \n",
       "8122      1          3            3          4        0     8   \n",
       "8123      0          5            2          4        0     5   \n",
       "\n",
       "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
       "0                   1             0          1           4  ...   \n",
       "1                   1             0          0           4  ...   \n",
       "2                   1             0          0           5  ...   \n",
       "3                   1             0          1           5  ...   \n",
       "4                   1             1          0           4  ...   \n",
       "...               ...           ...        ...         ...  ...   \n",
       "8119                0             0          0          11  ...   \n",
       "8120                0             0          0          11  ...   \n",
       "8121                0             0          0           5  ...   \n",
       "8122                1             0          1           0  ...   \n",
       "8123                0             0          0          11  ...   \n",
       "\n",
       "      stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                            2                       7   \n",
       "1                            2                       7   \n",
       "2                            2                       7   \n",
       "3                            2                       7   \n",
       "4                            2                       7   \n",
       "...                        ...                     ...   \n",
       "8119                         2                       5   \n",
       "8120                         2                       5   \n",
       "8121                         2                       5   \n",
       "8122                         1                       7   \n",
       "8123                         2                       5   \n",
       "\n",
       "      stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "0                          7          0           2            1          4   \n",
       "1                          7          0           2            1          4   \n",
       "2                          7          0           2            1          4   \n",
       "3                          7          0           2            1          4   \n",
       "4                          7          0           2            1          0   \n",
       "...                      ...        ...         ...          ...        ...   \n",
       "8119                       5          0           1            1          4   \n",
       "8120                       5          0           0            1          4   \n",
       "8121                       5          0           1            1          4   \n",
       "8122                       7          0           2            1          0   \n",
       "8123                       5          0           1            1          4   \n",
       "\n",
       "      spore-print-color  population  habitat  \n",
       "0                     2           3        5  \n",
       "1                     3           2        1  \n",
       "2                     3           2        3  \n",
       "3                     2           3        5  \n",
       "4                     3           0        1  \n",
       "...                 ...         ...      ...  \n",
       "8119                  0           1        2  \n",
       "8120                  0           4        2  \n",
       "8121                  0           1        2  \n",
       "8122                  7           4        2  \n",
       "8123                  4           1        2  \n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# N'avoir que des données numériques\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data[col] = labelencoder.fit_transform(data[col])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
       "0          1          5            2          4        1     6   \n",
       "1          0          5            2          9        1     0   \n",
       "2          0          0            2          8        1     3   \n",
       "3          1          5            3          8        1     6   \n",
       "4          0          5            2          3        0     5   \n",
       "...      ...        ...          ...        ...      ...   ...   \n",
       "8119       0          3            2          4        0     5   \n",
       "8120       0          5            2          4        0     5   \n",
       "8121       0          2            2          4        0     5   \n",
       "8122       1          3            3          4        0     8   \n",
       "8123       0          5            2          4        0     5   \n",
       "\n",
       "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
       "0                   1             0          1           4  ...   \n",
       "1                   1             0          0           4  ...   \n",
       "2                   1             0          0           5  ...   \n",
       "3                   1             0          1           5  ...   \n",
       "4                   1             1          0           4  ...   \n",
       "...               ...           ...        ...         ...  ...   \n",
       "8119                0             0          0          11  ...   \n",
       "8120                0             0          0          11  ...   \n",
       "8121                0             0          0           5  ...   \n",
       "8122                1             0          1           0  ...   \n",
       "8123                0             0          0          11  ...   \n",
       "\n",
       "      stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                            2                       7   \n",
       "1                            2                       7   \n",
       "2                            2                       7   \n",
       "3                            2                       7   \n",
       "4                            2                       7   \n",
       "...                        ...                     ...   \n",
       "8119                         2                       5   \n",
       "8120                         2                       5   \n",
       "8121                         2                       5   \n",
       "8122                         1                       7   \n",
       "8123                         2                       5   \n",
       "\n",
       "      stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "0                          7          0           2            1          4   \n",
       "1                          7          0           2            1          4   \n",
       "2                          7          0           2            1          4   \n",
       "3                          7          0           2            1          4   \n",
       "4                          7          0           2            1          0   \n",
       "...                      ...        ...         ...          ...        ...   \n",
       "8119                       5          0           1            1          4   \n",
       "8120                       5          0           0            1          4   \n",
       "8121                       5          0           1            1          4   \n",
       "8122                       7          0           2            1          0   \n",
       "8123                       5          0           1            1          4   \n",
       "\n",
       "      spore-print-color  population  habitat  \n",
       "0                     2           3        5  \n",
       "1                     3           2        1  \n",
       "2                     3           2        3  \n",
       "3                     2           3        5  \n",
       "4                     3           0        1  \n",
       "...                 ...         ...      ...  \n",
       "8119                  0           1        2  \n",
       "8120                  0           4        2  \n",
       "8121                  0           1        2  \n",
       "8122                  7           4        2  \n",
       "8123                  4           1        2  \n",
       "\n",
       "[8124 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# renommage de 'class' en 'target'\n",
    "data = data.rename(columns={'class': 'target'})\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                       2\n",
       "cap-shape                    6\n",
       "cap-surface                  4\n",
       "cap-color                   10\n",
       "bruises                      2\n",
       "odor                         9\n",
       "gill-attachment              2\n",
       "gill-spacing                 2\n",
       "gill-size                    2\n",
       "gill-color                  12\n",
       "stalk-shape                  2\n",
       "stalk-root                   5\n",
       "stalk-surface-above-ring     4\n",
       "stalk-surface-below-ring     4\n",
       "stalk-color-above-ring       9\n",
       "stalk-color-below-ring       9\n",
       "veil-color                   4\n",
       "ring-number                  3\n",
       "ring-type                    5\n",
       "spore-print-color            9\n",
       "population                   6\n",
       "habitat                      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppression des variables constantes\n",
    "tmp = data.nunique()\n",
    "cols = tmp[tmp == 1].index\n",
    "data = data.drop(columns=cols)\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export des données nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join('data/cleaned', filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vidéo 3/5 - Préparation des données et dummy classifier\n",
    "\n",
    "Objectifs :\n",
    "1. Séparer X et y\n",
    "2. Partition jeux d'entraînement et de test\n",
    "3. Entraîner le classifieur naïf\n",
    "4. Analyse des 1ers résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
       "0          1          5            2          4        1     6   \n",
       "1          0          5            2          9        1     0   \n",
       "2          0          0            2          8        1     3   \n",
       "3          1          5            3          8        1     6   \n",
       "4          0          5            2          3        0     5   \n",
       "...      ...        ...          ...        ...      ...   ...   \n",
       "8119       0          3            2          4        0     5   \n",
       "8120       0          5            2          4        0     5   \n",
       "8121       0          2            2          4        0     5   \n",
       "8122       1          3            3          4        0     8   \n",
       "8123       0          5            2          4        0     5   \n",
       "\n",
       "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
       "0                   1             0          1           4  ...   \n",
       "1                   1             0          0           4  ...   \n",
       "2                   1             0          0           5  ...   \n",
       "3                   1             0          1           5  ...   \n",
       "4                   1             1          0           4  ...   \n",
       "...               ...           ...        ...         ...  ...   \n",
       "8119                0             0          0          11  ...   \n",
       "8120                0             0          0          11  ...   \n",
       "8121                0             0          0           5  ...   \n",
       "8122                1             0          1           0  ...   \n",
       "8123                0             0          0          11  ...   \n",
       "\n",
       "      stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
       "0                            2                         2   \n",
       "1                            2                         2   \n",
       "2                            2                         2   \n",
       "3                            2                         2   \n",
       "4                            2                         2   \n",
       "...                        ...                       ...   \n",
       "8119                         2                         2   \n",
       "8120                         2                         2   \n",
       "8121                         2                         2   \n",
       "8122                         2                         1   \n",
       "8123                         2                         2   \n",
       "\n",
       "      stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
       "0                          7                       7           2            1   \n",
       "1                          7                       7           2            1   \n",
       "2                          7                       7           2            1   \n",
       "3                          7                       7           2            1   \n",
       "4                          7                       7           2            1   \n",
       "...                      ...                     ...         ...          ...   \n",
       "8119                       5                       5           1            1   \n",
       "8120                       5                       5           0            1   \n",
       "8121                       5                       5           1            1   \n",
       "8122                       7                       7           2            1   \n",
       "8123                       5                       5           1            1   \n",
       "\n",
       "      ring-type  spore-print-color  population  habitat  \n",
       "0             4                  2           3        5  \n",
       "1             4                  3           2        1  \n",
       "2             4                  3           2        3  \n",
       "3             4                  2           3        5  \n",
       "4             0                  3           0        1  \n",
       "...         ...                ...         ...      ...  \n",
       "8119          4                  0           1        2  \n",
       "8120          4                  0           4        2  \n",
       "8121          4                  0           1        2  \n",
       "8122          0                  7           4        2  \n",
       "8123          4                  4           1        2  \n",
       "\n",
       "[8124 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_data = pd.read_csv(os.path.join('data/cleaned', filename))\n",
    "display(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0             5            2          4        1     6                1   \n",
       "1             5            2          9        1     0                1   \n",
       "2             0            2          8        1     3                1   \n",
       "3             5            3          8        1     6                1   \n",
       "4             5            2          3        0     5                1   \n",
       "...         ...          ...        ...      ...   ...              ...   \n",
       "8119          3            2          4        0     5                0   \n",
       "8120          5            2          4        0     5                0   \n",
       "8121          2            2          4        0     5                0   \n",
       "8122          3            3          4        0     8                1   \n",
       "8123          5            2          4        0     5                0   \n",
       "\n",
       "      gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "0                0          1           4            0  ...   \n",
       "1                0          0           4            0  ...   \n",
       "2                0          0           5            0  ...   \n",
       "3                0          1           5            0  ...   \n",
       "4                1          0           4            1  ...   \n",
       "...            ...        ...         ...          ...  ...   \n",
       "8119             0          0          11            0  ...   \n",
       "8120             0          0          11            0  ...   \n",
       "8121             0          0           5            0  ...   \n",
       "8122             0          1           0            1  ...   \n",
       "8123             0          0          11            0  ...   \n",
       "\n",
       "      stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
       "0                            2                         2   \n",
       "1                            2                         2   \n",
       "2                            2                         2   \n",
       "3                            2                         2   \n",
       "4                            2                         2   \n",
       "...                        ...                       ...   \n",
       "8119                         2                         2   \n",
       "8120                         2                         2   \n",
       "8121                         2                         2   \n",
       "8122                         2                         1   \n",
       "8123                         2                         2   \n",
       "\n",
       "      stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
       "0                          7                       7           2            1   \n",
       "1                          7                       7           2            1   \n",
       "2                          7                       7           2            1   \n",
       "3                          7                       7           2            1   \n",
       "4                          7                       7           2            1   \n",
       "...                      ...                     ...         ...          ...   \n",
       "8119                       5                       5           1            1   \n",
       "8120                       5                       5           0            1   \n",
       "8121                       5                       5           1            1   \n",
       "8122                       7                       7           2            1   \n",
       "8123                       5                       5           1            1   \n",
       "\n",
       "      ring-type  spore-print-color  population  habitat  \n",
       "0             4                  2           3        5  \n",
       "1             4                  3           2        1  \n",
       "2             4                  3           2        3  \n",
       "3             4                  2           3        5  \n",
       "4             0                  3           0        1  \n",
       "...         ...                ...         ...      ...  \n",
       "8119          4                  0           1        2  \n",
       "8120          4                  0           4        2  \n",
       "8121          4                  0           1        2  \n",
       "8122          0                  7           4        2  \n",
       "8123          4                  4           1        2  \n",
       "\n",
       "[8124 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "8119    0\n",
       "8120    0\n",
       "8121    0\n",
       "8122    1\n",
       "8123    0\n",
       "Name: target, Length: 8124, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# séparation X, y\n",
    "X = _data.drop(columns='target')\n",
    "y = _data.target\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition train / test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifieur naïf\n",
    "estimator = DummyClassifier(strategy='most_frequent')\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2438\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.515587\n",
       "1    0.484413\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.519, score test 0.5156\n"
     ]
    }
   ],
   "source": [
    "tr_score = estimator.score(X_train, y_train).round(4)\n",
    "ts_score = estimator.score(X_test, y_test).round(4)\n",
    "print(f'score train : {tr_score}, score test {ts_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.519, score test 0.5156\n"
     ]
    }
   ],
   "source": [
    "def score(estimator):\n",
    "    \"\"\"compute and print train score and test score\"\"\"\n",
    "    tr_score = estimator.score(X_train, y_train).round(4)\n",
    "    ts_score = estimator.score(X_test, y_test).round(4)\n",
    "    print(f'score train : {tr_score}, score test {ts_score}')\n",
    "\n",
    "score(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.519\n",
       "1    0.481\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5156\n",
       "1    0.4844\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1257,    0],\n",
       "       [1181,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>1181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1257       0\n",
       "test_1    1181       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = pd.DataFrame(mat)\n",
    "mat.columns = [f'pred_{i}' for i in mat.columns]\n",
    "mat.index = [f'test_{i}' for i in mat.index]\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>1181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1257       0\n",
       "test_1    1181       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion(y_test, y_pred):\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    mat = pd.DataFrame(mat)\n",
    "    mat.columns = [f'pred_{i}' for i in mat.columns]\n",
    "    mat.index = [f'test_{i}' for i in mat.index]\n",
    "    return mat\n",
    "\n",
    "display(confusion(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "print(false_positive_rate)\n",
    "print(true_positive_rate)\n",
    "print(thresholds)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vidéo 4/5 - Entraîner une régression logistique et une SVM\n",
    "\n",
    "1. Entraîner une régression logistique\n",
    "2. Entraîner une SVM\n",
    "\n",
    "Temps important sur l'analyse des résultats et leur compréhension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver='liblinear')\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [0.09, 0.91],\n",
       "       [0.  , 1.  ],\n",
       "       ...,\n",
       "       [0.09, 0.91],\n",
       "       [1.  , 0.  ],\n",
       "       [0.95, 0.05]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = estimator.predict_proba(X_test).round(2)\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.9485, score test 0.9491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1201</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>68</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1201      56\n",
       "test_1      68    1113"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(estimator)\n",
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489355797205421"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.9469, score test 0.9463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1202</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>76</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1202      55\n",
       "test_1      76    1105"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(estimator)\n",
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459463919914693"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vidéo 5/5 - Trouver les meilleurs hyperparamètres\n",
    "\n",
    "1. Utiliser une GridSearch\n",
    "2. Analyser ses résultats\n",
    "3. Ré-entraîner les modèles avec les meilleurs paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 165 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "880 fits failed out of a total of 1650.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.0115735         nan        nan        nan 0.0115528  0.06925466\n",
      " 0.04329193 0.04329193 0.00867495 0.00432712        nan        nan\n",
      "        nan        nan        nan 0.0115735         nan        nan\n",
      "        nan 0.01010352 0.06925466 0.04329193 0.04329193 0.02451346\n",
      " 0.02888199        nan        nan        nan        nan        nan\n",
      " 0.0115735         nan        nan        nan 0.01010352 0.06925466\n",
      " 0.04329193 0.04329193 0.0389648  0.04329193        nan        nan\n",
      "        nan        nan        nan 0.00287785        nan        nan\n",
      "        nan 0.01153209 0.09093168 0.04329193 0.04329193 0.04329193\n",
      " 0.04329193        nan        nan        nan        nan        nan\n",
      " 0.00722567        nan        nan        nan 0.01153209 0.17024845\n",
      " 0.06782609 0.06782609 0.06782609 0.06782609        nan        nan\n",
      "        nan        nan        nan 0.12559006        nan        nan\n",
      "        nan 0.12269151 0.29300207 0.24240166 0.24240166 0.24240166\n",
      " 0.24240166        nan        nan        nan        nan        nan\n",
      " 0.7489648         nan        nan        nan 0.70418219 0.62913043\n",
      " 0.63490683 0.63490683 0.63490683 0.63345756        nan        nan\n",
      "        nan        nan        nan 0.85995859        nan        nan\n",
      "        nan 0.89180124 0.89900621 0.90333333 0.90333333 0.89902692\n",
      " 0.89035197        nan        nan        nan        nan        nan\n",
      " 0.87583851        nan        nan        nan 0.90768116 0.9336853\n",
      " 0.92645963 0.92645963 0.91490683 0.90623188        nan        nan\n",
      "        nan        nan        nan 0.89035197        nan        nan\n",
      "        nan 0.90768116 0.93801242 0.93223602 0.92356108 0.91490683\n",
      " 0.90623188        nan        nan        nan        nan        nan\n",
      " 0.93795031        nan        nan        nan 0.90623188 0.93801242\n",
      " 0.93658385 0.91927536 0.91345756 0.90768116        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.01154438        nan        nan        nan 0.01186515 0.09138731\n",
      " 0.06524931 0.06524957 0.01443002 0.01443002        nan        nan\n",
      "        nan        nan        nan 0.01154438        nan        nan\n",
      "        nan 0.01186515 0.09154757 0.06524931 0.06524931 0.04248313\n",
      " 0.04937518        nan        nan        nan        nan        nan\n",
      " 0.01154438        nan        nan        nan 0.01218515 0.09266936\n",
      " 0.06524931 0.06524931 0.05931571 0.06524931        nan        nan\n",
      "        nan        nan        nan 0.01443002        nan        nan\n",
      "        nan 0.01170386 0.11816325 0.06524931 0.06524931 0.06476828\n",
      " 0.06524931        nan        nan        nan        nan        nan\n",
      " 0.01443002        nan        nan        nan 0.01346771 0.21677033\n",
      " 0.08737987 0.08737987 0.08737987 0.08737987        nan        nan\n",
      "        nan        nan        nan 0.12826815        nan        nan\n",
      "        nan 0.13003174 0.37276927 0.30639559 0.30655585 0.30623534\n",
      " 0.30655585        nan        nan        nan        nan        nan\n",
      " 0.92175757        nan        nan        nan 0.87462007 0.76735374\n",
      " 0.77408965 0.77408965 0.77408965 0.77360862        nan        nan\n",
      "        nan        nan        nan 1.                nan        nan\n",
      "        nan 0.99887769 0.99791615 0.99935872 0.99935872 0.9990382\n",
      " 0.99679281        nan        nan        nan        nan        nan\n",
      " 1.                nan        nan        nan 0.99983974 1.\n",
      " 1.         1.         1.         0.99983974        nan        nan\n",
      "        nan        nan        nan 1.                nan        nan\n",
      "        nan 1.         1.         1.         1.         1.\n",
      " 1.                nan        nan        nan        nan        nan\n",
      " 1.                nan        nan        nan 0.99983974 1.\n",
      " 1.         1.         1.         1.                nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             return_train_score=True, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             return_train_score=True, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag',\n",
       "                                    'saga']},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'C': np.logspace(-5, 5, 11),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator,\n",
    "    params,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10000.0, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.19569111e-03, 3.19848061e-03, 3.60959053e-02, 1.86599112e-01,\n",
       "        7.85979986e-02, 7.90007591e-02, 4.09829617e-03, 2.70049572e-03,\n",
       "        1.87502646e-01, 2.40495729e-01, 1.69798112e-01, 9.02992964e-02,\n",
       "        3.09736729e-03, 3.69877815e-03, 4.62499714e-01, 3.03899574e-01,\n",
       "        1.94601512e-01, 1.92498899e-01, 3.09958458e-03, 3.09908390e-03,\n",
       "        9.93726072e+00, 3.53499341e-01, 1.92598438e-01, 2.38300014e-01,\n",
       "        5.79912663e-03, 2.90131569e-03, 1.12374640e+01, 5.69902372e-01,\n",
       "        1.30600429e-01, 2.93400240e-01, 2.79929638e-03, 3.00014019e-03,\n",
       "        1.29628010e+01, 7.28902316e-01, 1.73698187e-01, 4.11497712e-01,\n",
       "        7.50052929e-03, 4.70120907e-03, 1.05174036e+01, 7.65599728e-01,\n",
       "        1.50299978e-01, 4.83299851e-01]),\n",
       " 'std_fit_time': array([4.04513528e-04, 8.73145771e-04, 4.45935694e-03, 4.16353223e-02,\n",
       "        2.21901750e-02, 1.83996222e-02, 1.13617012e-03, 6.40491596e-04,\n",
       "        5.92329950e-02, 6.82915186e-02, 4.34502255e-02, 1.37277389e-02,\n",
       "        9.42266313e-04, 1.73627680e-03, 1.97413093e-01, 8.87495282e-02,\n",
       "        6.38541002e-02, 6.53975949e-02, 5.38567371e-04, 6.98265405e-04,\n",
       "        1.25256868e+00, 6.86593388e-02, 5.39858659e-02, 5.09795777e-02,\n",
       "        4.77016534e-03, 7.02410292e-04, 3.24830708e+00, 1.64532257e-01,\n",
       "        3.29277114e-03, 7.73013151e-02, 7.49355446e-04, 8.94042951e-04,\n",
       "        2.20514761e+00, 1.53367634e-01, 3.68368122e-02, 1.25193443e-01,\n",
       "        7.88844178e-03, 3.79488182e-03, 1.48630124e+00, 7.84711276e-02,\n",
       "        2.89075143e-02, 1.05766468e-01]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.02510087, 0.00429747, 0.00410388,\n",
       "        0.00419793, 0.        , 0.        , 0.01320035, 0.00450561,\n",
       "        0.00440278, 0.0035017 , 0.        , 0.        , 0.00399902,\n",
       "        0.00460117, 0.00759835, 0.00400014, 0.        , 0.        ,\n",
       "        0.00440047, 0.00660162, 0.00489888, 0.00380051, 0.        ,\n",
       "        0.        , 0.00600023, 0.0035022 , 0.00329947, 0.00380013,\n",
       "        0.        , 0.        , 0.00369825, 0.00900071, 0.00490205,\n",
       "        0.00340078, 0.        , 0.        , 0.00250428, 0.00399957,\n",
       "        0.00400126, 0.00360096]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.02462953, 0.00167655, 0.00082983,\n",
       "        0.00097924, 0.        , 0.        , 0.02763631, 0.00120594,\n",
       "        0.00201204, 0.00067053, 0.        , 0.        , 0.00089186,\n",
       "        0.00168602, 0.00920562, 0.00126631, 0.        , 0.        ,\n",
       "        0.0016243 , 0.00697366, 0.00541184, 0.00098133, 0.        ,\n",
       "        0.        , 0.00667829, 0.00050104, 0.00063932, 0.00146919,\n",
       "        0.        , 0.        , 0.00045883, 0.01033418, 0.00273626,\n",
       "        0.00049107, 0.        , 0.        , 0.00080428, 0.00044698,\n",
       "        0.0010965 , 0.00111332]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0, 10.0,\n",
       "                    10.0, 10.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                    1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}],\n",
       " 'split0_test_score': array([       nan,        nan, 0.75571178, 0.87346221, 0.87346221,\n",
       "        0.86115993,        nan,        nan, 0.90509666, 0.90333919,\n",
       "        0.90333919, 0.90158172,        nan,        nan, 0.94376098,\n",
       "        0.93497364, 0.93497364, 0.93321617,        nan,        nan,\n",
       "        0.95782074, 0.94551845, 0.94727592, 0.94551845,        nan,\n",
       "               nan, 0.97012302, 0.96309315, 0.96485062, 0.9543058 ,\n",
       "               nan,        nan, 0.97012302, 0.97012302, 0.96309315,\n",
       "        0.97012302,        nan,        nan, 0.97012302, 0.97188049,\n",
       "        0.96836555, 0.97188049]),\n",
       " 'split1_test_score': array([       nan,        nan, 0.78910369, 0.89982425, 0.89982425,\n",
       "        0.89103691,        nan,        nan, 0.92091388, 0.91036907,\n",
       "        0.91036907, 0.91915641,        nan,        nan, 0.95782074,\n",
       "        0.95079086, 0.95254833, 0.95079086,        nan,        nan,\n",
       "        0.97012302, 0.96485062, 0.96485062, 0.96309315,        nan,\n",
       "               nan, 0.9771529 , 0.97188049, 0.96660808, 0.97012302,\n",
       "               nan,        nan, 0.9771529 , 0.9771529 , 0.96836555,\n",
       "        0.9771529 ,        nan,        nan, 0.9771529 , 0.9771529 ,\n",
       "        0.97012302, 0.9771529 ]),\n",
       " 'split2_test_score': array([       nan,        nan, 0.75922671, 0.86467487, 0.86467487,\n",
       "        0.85764499,        nan,        nan, 0.89982425, 0.90509666,\n",
       "        0.90509666, 0.91036907,        nan,        nan, 0.94727592,\n",
       "        0.94024605, 0.94024605, 0.93673111,        nan,        nan,\n",
       "        0.95782074, 0.94903339, 0.9543058 , 0.95254833,        nan,\n",
       "               nan, 0.97012302, 0.96133568, 0.95606327, 0.95782074,\n",
       "               nan,        nan, 0.97012302, 0.97012302, 0.95782074,\n",
       "        0.97012302,        nan,        nan, 0.97012302, 0.97012302,\n",
       "        0.95606327, 0.97012302]),\n",
       " 'split3_test_score': array([       nan,        nan, 0.76977153, 0.87873462, 0.87873462,\n",
       "        0.86643234,        nan,        nan, 0.89982425, 0.90685413,\n",
       "        0.90685413, 0.91036907,        nan,        nan, 0.93497364,\n",
       "        0.9314587 , 0.93497364, 0.9314587 ,        nan,        nan,\n",
       "        0.94024605, 0.93673111, 0.93673111, 0.93497364,        nan,\n",
       "               nan, 0.94024605, 0.94200351, 0.94024605, 0.93673111,\n",
       "               nan,        nan, 0.94200351, 0.94200351, 0.93673111,\n",
       "        0.94200351,        nan,        nan, 0.94200351, 0.94376098,\n",
       "        0.94200351, 0.94376098]),\n",
       " 'split4_test_score': array([       nan,        nan, 0.79086116, 0.88049209, 0.88049209,\n",
       "        0.86467487,        nan,        nan, 0.88049209, 0.90333919,\n",
       "        0.90333919, 0.89982425,        nan,        nan, 0.93673111,\n",
       "        0.92618629, 0.92442882, 0.92970123,        nan,        nan,\n",
       "        0.94024605, 0.93848858, 0.93848858, 0.93848858,        nan,\n",
       "               nan, 0.94727592, 0.94024605, 0.94376098, 0.94024605,\n",
       "               nan,        nan, 0.94551845, 0.94727592, 0.94200351,\n",
       "        0.94727592,        nan,        nan, 0.94551845, 0.94727592,\n",
       "        0.94727592, 0.94551845]),\n",
       " 'split5_test_score': array([       nan,        nan, 0.78383128, 0.89279438, 0.89279438,\n",
       "        0.88224956,        nan,        nan, 0.91564148, 0.91564148,\n",
       "        0.91564148, 0.91564148,        nan,        nan, 0.95606327,\n",
       "        0.94024605, 0.94200351, 0.94024605,        nan,        nan,\n",
       "        0.95606327, 0.9543058 , 0.9543058 , 0.9543058 ,        nan,\n",
       "               nan, 0.96309315, 0.95782074, 0.95254833, 0.95606327,\n",
       "               nan,        nan, 0.96309315, 0.96309315, 0.95782074,\n",
       "        0.96133568,        nan,        nan, 0.96133568, 0.96309315,\n",
       "        0.95254833, 0.96309315]),\n",
       " 'split6_test_score': array([       nan,        nan, 0.76408451, 0.875     , 0.875     ,\n",
       "        0.87852113,        nan,        nan, 0.90492958, 0.90140845,\n",
       "        0.90140845, 0.9084507 ,        nan,        nan, 0.93485915,\n",
       "        0.93133803, 0.93133803, 0.93133803,        nan,        nan,\n",
       "        0.93661972, 0.93661972, 0.93309859, 0.93661972,        nan,\n",
       "               nan, 0.94190141, 0.93661972, 0.93485915, 0.93485915,\n",
       "               nan,        nan, 0.94190141, 0.94190141, 0.93661972,\n",
       "        0.94014085,        nan,        nan, 0.94190141, 0.94014085,\n",
       "        0.93485915, 0.94190141]),\n",
       " 'split7_test_score': array([       nan,        nan, 0.76584507, 0.87147887, 0.87147887,\n",
       "        0.85739437,        nan,        nan, 0.90492958, 0.91021127,\n",
       "        0.91021127, 0.90492958,        nan,        nan, 0.95070423,\n",
       "        0.93661972, 0.93661972, 0.93485915,        nan,        nan,\n",
       "        0.96126761, 0.95422535, 0.95246479, 0.95422535,        nan,\n",
       "               nan, 0.9665493 , 0.96302817, 0.96302817, 0.95950704,\n",
       "               nan,        nan, 0.97007042, 0.97007042, 0.96302817,\n",
       "        0.96830986,        nan,        nan, 0.97007042, 0.97007042,\n",
       "        0.95950704, 0.97007042]),\n",
       " 'split8_test_score': array([       nan,        nan, 0.79225352, 0.89084507, 0.89084507,\n",
       "        0.88204225,        nan,        nan, 0.91021127, 0.92429577,\n",
       "        0.92429577, 0.92429577,        nan,        nan, 0.94014085,\n",
       "        0.93485915, 0.93133803, 0.93133803,        nan,        nan,\n",
       "        0.94894366, 0.94190141, 0.94190141, 0.94190141,        nan,\n",
       "               nan, 0.94894366, 0.9471831 , 0.95070423, 0.94894366,\n",
       "               nan,        nan, 0.95422535, 0.95070423, 0.95070423,\n",
       "        0.94894366,        nan,        nan, 0.95422535, 0.95246479,\n",
       "        0.95246479, 0.95422535]),\n",
       " 'split9_test_score': array([       nan,        nan, 0.74295775, 0.86443662, 0.86443662,\n",
       "        0.8556338 ,        nan,        nan, 0.90140845, 0.90316901,\n",
       "        0.90316901, 0.90316901,        nan,        nan, 0.94894366,\n",
       "        0.93309859, 0.93133803, 0.93133803,        nan,        nan,\n",
       "        0.95246479, 0.9471831 , 0.94542254, 0.94542254,        nan,\n",
       "               nan, 0.9665493 , 0.95422535, 0.95422535, 0.95070423,\n",
       "               nan,        nan, 0.96478873, 0.9665493 , 0.95950704,\n",
       "        0.96478873,        nan,        nan, 0.9665493 , 0.96830986,\n",
       "        0.95598592, 0.96830986]),\n",
       " 'mean_test_score': array([       nan,        nan, 0.7713647 , 0.8791743 , 0.8791743 ,\n",
       "        0.86967901,        nan,        nan, 0.90432715, 0.90837242,\n",
       "        0.90837242, 0.90977871,        nan,        nan, 0.94512735,\n",
       "        0.93598171, 0.93598078, 0.93510174,        nan,        nan,\n",
       "        0.95216156, 0.94688575, 0.94688451, 0.9467097 ,        nan,\n",
       "               nan, 0.95919577, 0.9537436 , 0.95268942, 0.95093041,\n",
       "               nan,        nan, 0.9599    , 0.95989969, 0.9535694 ,\n",
       "        0.95901972,        nan,        nan, 0.95990031, 0.96042724,\n",
       "        0.95391965, 0.9606036 ]),\n",
       " 'std_test_score': array([       nan,        nan, 0.01603698, 0.01134358, 0.01134358,\n",
       "        0.0120265 ,        nan,        nan, 0.01027743, 0.00673079,\n",
       "        0.00673079, 0.00754323,        nan,        nan, 0.00797973,\n",
       "        0.00636119, 0.00727667, 0.00603171,        nan,        nan,\n",
       "        0.01010329, 0.00861451, 0.00924569, 0.00866036,        nan,\n",
       "               nan, 0.01260945, 0.01110558, 0.01009301, 0.0105128 ,\n",
       "               nan,        nan, 0.01235913, 0.01246071, 0.01087795,\n",
       "        0.01259261,        nan,        nan, 0.0124083 , 0.01262072,\n",
       "        0.01031867, 0.01244412]),\n",
       " 'rank_test_score': array([42, 31, 28, 25, 25, 27, 32, 35, 24, 22, 22, 21, 33, 40, 17, 18, 19,\n",
       "        20, 39, 38, 12, 14, 15, 16, 37, 36,  6,  9, 11, 13, 34, 41,  4,  5,\n",
       "        10,  7, 30, 29,  3,  2,  8,  1]),\n",
       " 'split0_train_score': array([       nan,        nan, 0.77310924, 0.88098495, 0.88098495,\n",
       "        0.87062732,        nan,        nan, 0.90541333, 0.90912644,\n",
       "        0.90912644, 0.91362126,        nan,        nan, 0.94723471,\n",
       "        0.93609537, 0.93648622, 0.93570451,        nan,        nan,\n",
       "        0.95896033, 0.95094782, 0.95075239, 0.95114325,        nan,\n",
       "               nan, 0.96970881, 0.9609146 , 0.96013289, 0.95681063,\n",
       "               nan,        nan, 0.96951339, 0.96931796, 0.96267344,\n",
       "        0.96931796,        nan,        nan, 0.96951339, 0.97049052,\n",
       "        0.95915576, 0.97029509]),\n",
       " 'split1_train_score': array([       nan,        nan, 0.76939613, 0.87805355, 0.87805355,\n",
       "        0.86769592,        nan,        nan, 0.90170021, 0.90971272,\n",
       "        0.90971272, 0.90932187,        nan,        nan, 0.94528044,\n",
       "        0.93453195, 0.93511823, 0.93355482,        nan,        nan,\n",
       "        0.95641978, 0.94664843, 0.94821184, 0.94762556,        nan,\n",
       "               nan, 0.9630643 , 0.95798319, 0.95524722, 0.95309752,\n",
       "               nan,        nan, 0.96267344, 0.96325972, 0.95681063,\n",
       "        0.96345515,        nan,        nan, 0.96345515, 0.96345515,\n",
       "        0.95485636, 0.96267344]),\n",
       " 'split2_train_score': array([       nan,        nan, 0.77271839, 0.88039867, 0.88039867,\n",
       "        0.87140903,        nan,        nan, 0.90365449, 0.90873559,\n",
       "        0.90873559, 0.91127614,        nan,        nan, 0.94528044,\n",
       "        0.93589994, 0.93668165, 0.93433653,        nan,        nan,\n",
       "        0.95544264, 0.94957983, 0.95094782, 0.95036154,        nan,\n",
       "               nan, 0.96169631, 0.9566152 , 0.9536838 , 0.95329295,\n",
       "               nan,        nan, 0.96169631, 0.96189173, 0.95427008,\n",
       "        0.96150088,        nan,        nan, 0.96169631, 0.96189173,\n",
       "        0.95407465, 0.96189173]),\n",
       " 'split3_train_score': array([       nan,        nan, 0.77154583, 0.88078953, 0.88078953,\n",
       "        0.86984561,        nan,        nan, 0.90560876, 0.90912644,\n",
       "        0.90912644, 0.90932187,        nan,        nan, 0.94567129,\n",
       "        0.93863592, 0.93746336, 0.93589994,        nan,        nan,\n",
       "        0.95446551, 0.94957983, 0.94977526, 0.94997069,        nan,\n",
       "               nan, 0.95700606, 0.9536838 , 0.95309752, 0.95231581,\n",
       "               nan,        nan, 0.95974204, 0.95896033, 0.9536838 ,\n",
       "        0.95817862,        nan,        nan, 0.95896033, 0.96052374,\n",
       "        0.95387923, 0.96032832]),\n",
       " 'split4_train_score': array([       nan,        nan, 0.7692007 , 0.87863983, 0.87863983,\n",
       "        0.86984561,        nan,        nan, 0.90775845, 0.91127614,\n",
       "        0.91127614, 0.91381669,        nan,        nan, 0.94840727,\n",
       "        0.93941763, 0.93902677, 0.93824507,        nan,        nan,\n",
       "        0.95446551, 0.95055697, 0.95075239, 0.95036154,        nan,\n",
       "               nan, 0.96365058, 0.95563807, 0.95602892, 0.95427008,\n",
       "               nan,        nan, 0.96482314, 0.963846  , 0.95915576,\n",
       "        0.96345515,        nan,        nan, 0.96482314, 0.96540942,\n",
       "        0.96032832, 0.96540942]),\n",
       " 'split5_train_score': array([       nan,        nan, 0.76998241, 0.8805941 , 0.8805941 ,\n",
       "        0.87082275,        nan,        nan, 0.90424077, 0.90814931,\n",
       "        0.90814931, 0.91303498,        nan,        nan, 0.94586672,\n",
       "        0.93609537, 0.93609537, 0.9341411 ,        nan,        nan,\n",
       "        0.95348837, 0.9486027 , 0.94957983, 0.9486027 ,        nan,\n",
       "               nan, 0.95778777, 0.95231581, 0.95251124, 0.9515341 ,\n",
       "               nan,        nan, 0.95798319, 0.95798319, 0.95563807,\n",
       "        0.95759234,        nan,        nan, 0.95759234, 0.95935118,\n",
       "        0.9558335 , 0.95915576]),\n",
       " 'split6_train_score': array([       nan,        nan, 0.77217663, 0.88100821, 0.88100821,\n",
       "        0.86772177,        nan,        nan, 0.90601798, 0.90875342,\n",
       "        0.90875342, 0.90992575,        nan,        nan, 0.94665885,\n",
       "        0.93962485, 0.93806174, 0.93728019,        nan,        nan,\n",
       "        0.9527159 , 0.94958968, 0.94880813, 0.94998046,        nan,\n",
       "               nan, 0.95427902, 0.95212974, 0.95154357, 0.95134818,\n",
       "               nan,        nan, 0.95564674, 0.95584213, 0.95193435,\n",
       "        0.95584213,        nan,        nan, 0.95564674, 0.95564674,\n",
       "        0.95291129, 0.95584213]),\n",
       " 'split7_train_score': array([       nan,        nan, 0.77198124, 0.88139898, 0.88139898,\n",
       "        0.87162954,        nan,        nan, 0.90289175, 0.90933959,\n",
       "        0.90933959, 0.91070731,        nan,        nan, 0.94275107,\n",
       "        0.93415397, 0.93454474, 0.93259086,        nan,        nan,\n",
       "        0.95388824, 0.94607268, 0.94704963, 0.94685424,        nan,\n",
       "               nan, 0.95818679, 0.95408363, 0.95252052, 0.94998046,\n",
       "               nan,        nan, 0.96053146, 0.96033607, 0.95310668,\n",
       "        0.95935912,        nan,        nan, 0.9597499 , 0.96053146,\n",
       "        0.95349746, 0.96053146]),\n",
       " 'split8_train_score': array([       nan,        nan, 0.76905041, 0.88022665, 0.88022665,\n",
       "        0.87006643,        nan,        nan, 0.90425948, 0.90894881,\n",
       "        0.90894881, 0.9109027 ,        nan,        nan, 0.94744041,\n",
       "        0.93786635, 0.93786635, 0.9370848 ,        nan,        nan,\n",
       "        0.95466979, 0.94919891, 0.94998046, 0.94919891,        nan,\n",
       "               nan, 0.95935912, 0.95369285, 0.9562329 , 0.95095741,\n",
       "               nan,        nan, 0.96092224, 0.96053146, 0.95564674,\n",
       "        0.95955451,        nan,        nan, 0.96092224, 0.96170379,\n",
       "        0.95662368, 0.96111762]),\n",
       " 'split9_train_score': array([       nan,        nan, 0.7745213 , 0.8812036 , 0.8812036 ,\n",
       "        0.87143415,        nan,        nan, 0.9038687 , 0.9091442 ,\n",
       "        0.9091442 , 0.91070731,        nan,        nan, 0.94294646,\n",
       "        0.93474013, 0.93630324, 0.93454474,        nan,        nan,\n",
       "        0.9527159 , 0.94665885, 0.94880813, 0.94724502,        nan,\n",
       "               nan, 0.96072685, 0.95252052, 0.95232513, 0.95017585,\n",
       "               nan,        nan, 0.95994529, 0.96092224, 0.95603751,\n",
       "        0.96033607,        nan,        nan, 0.96072685, 0.96092224,\n",
       "        0.95486518, 0.96092224]),\n",
       " 'mean_train_score': array([       nan,        nan, 0.77136823, 0.88032981, 0.88032981,\n",
       "        0.87010981,        nan,        nan, 0.90454139, 0.90923126,\n",
       "        0.90923126, 0.91126359,        nan,        nan, 0.94575377,\n",
       "        0.93670615, 0.93676477, 0.93533825,        nan,        nan,\n",
       "        0.9547232 , 0.94874357, 0.94946659, 0.94913439,        nan,\n",
       "               nan, 0.96054656, 0.95495774, 0.95433237, 0.9523783 ,\n",
       "               nan,        nan, 0.96134772, 0.96128908, 0.95589571,\n",
       "        0.96085919,        nan,        nan, 0.96130864, 0.9619926 ,\n",
       "        0.95560254, 0.96181672]),\n",
       " 'std_train_score': array([       nan,        nan, 0.00178148, 0.00105499, 0.00105499,\n",
       "        0.00134902,        nan,        nan, 0.00163193, 0.00078607,\n",
       "        0.00078607, 0.00159042,        nan,        nan, 0.00173962,\n",
       "        0.00193502, 0.00129944, 0.00171802,        nan,        nan,\n",
       "        0.00178228, 0.00162352, 0.00118979, 0.00140694,        nan,\n",
       "               nan, 0.0040949 , 0.00269726, 0.00247638, 0.00197422,\n",
       "               nan,        nan, 0.00360346, 0.0035055 , 0.00297586,\n",
       "        0.00364274,        nan,        nan, 0.00372461, 0.00372568,\n",
       "        0.00232666, 0.00365325])}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = grid.cv_results_\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.755712</td>\n",
       "      <td>0.789104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772718</td>\n",
       "      <td>0.771546</td>\n",
       "      <td>0.769201</td>\n",
       "      <td>0.769982</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>0.771981</td>\n",
       "      <td>0.769050</td>\n",
       "      <td>0.774521</td>\n",
       "      <td>0.771368</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.873462</td>\n",
       "      <td>0.899824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880399</td>\n",
       "      <td>0.880790</td>\n",
       "      <td>0.878640</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>0.881008</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.880227</td>\n",
       "      <td>0.881204</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078598</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.873462</td>\n",
       "      <td>0.899824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880399</td>\n",
       "      <td>0.880790</td>\n",
       "      <td>0.878640</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>0.881008</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.880227</td>\n",
       "      <td>0.881204</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.861160</td>\n",
       "      <td>0.891037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871409</td>\n",
       "      <td>0.869846</td>\n",
       "      <td>0.869846</td>\n",
       "      <td>0.870823</td>\n",
       "      <td>0.867722</td>\n",
       "      <td>0.871630</td>\n",
       "      <td>0.870066</td>\n",
       "      <td>0.871434</td>\n",
       "      <td>0.870110</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.187503</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.905097</td>\n",
       "      <td>0.920914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903654</td>\n",
       "      <td>0.905609</td>\n",
       "      <td>0.907758</td>\n",
       "      <td>0.904241</td>\n",
       "      <td>0.906018</td>\n",
       "      <td>0.902892</td>\n",
       "      <td>0.904259</td>\n",
       "      <td>0.903869</td>\n",
       "      <td>0.904541</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.240496</td>\n",
       "      <td>0.068292</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.910369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908736</td>\n",
       "      <td>0.909126</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>0.908149</td>\n",
       "      <td>0.908753</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.908949</td>\n",
       "      <td>0.909144</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169798</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.910369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908736</td>\n",
       "      <td>0.909126</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>0.908149</td>\n",
       "      <td>0.908753</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.908949</td>\n",
       "      <td>0.909144</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.090299</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.901582</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>0.909322</td>\n",
       "      <td>0.913817</td>\n",
       "      <td>0.913035</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.910707</td>\n",
       "      <td>0.910903</td>\n",
       "      <td>0.910707</td>\n",
       "      <td>0.911264</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.197413</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.943761</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945280</td>\n",
       "      <td>0.945671</td>\n",
       "      <td>0.948407</td>\n",
       "      <td>0.945867</td>\n",
       "      <td>0.946659</td>\n",
       "      <td>0.942751</td>\n",
       "      <td>0.947440</td>\n",
       "      <td>0.942946</td>\n",
       "      <td>0.945754</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.088750</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.934974</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.938636</td>\n",
       "      <td>0.939418</td>\n",
       "      <td>0.936095</td>\n",
       "      <td>0.939625</td>\n",
       "      <td>0.934154</td>\n",
       "      <td>0.937866</td>\n",
       "      <td>0.934740</td>\n",
       "      <td>0.936706</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.194602</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.934974</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936682</td>\n",
       "      <td>0.937463</td>\n",
       "      <td>0.939027</td>\n",
       "      <td>0.936095</td>\n",
       "      <td>0.938062</td>\n",
       "      <td>0.934545</td>\n",
       "      <td>0.937866</td>\n",
       "      <td>0.936303</td>\n",
       "      <td>0.936765</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.192499</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934337</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.938245</td>\n",
       "      <td>0.934141</td>\n",
       "      <td>0.937280</td>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.937085</td>\n",
       "      <td>0.934545</td>\n",
       "      <td>0.935338</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.937261</td>\n",
       "      <td>1.252569</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955443</td>\n",
       "      <td>0.954466</td>\n",
       "      <td>0.954466</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>0.953888</td>\n",
       "      <td>0.954670</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>0.954723</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.353499</td>\n",
       "      <td>0.068659</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.945518</td>\n",
       "      <td>0.964851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.950557</td>\n",
       "      <td>0.948603</td>\n",
       "      <td>0.949590</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.949199</td>\n",
       "      <td>0.946659</td>\n",
       "      <td>0.948744</td>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.192598</td>\n",
       "      <td>0.053986</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.947276</td>\n",
       "      <td>0.964851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950948</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.950752</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>0.947050</td>\n",
       "      <td>0.949980</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>0.949467</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.945518</td>\n",
       "      <td>0.963093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950362</td>\n",
       "      <td>0.949971</td>\n",
       "      <td>0.950362</td>\n",
       "      <td>0.948603</td>\n",
       "      <td>0.949980</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.949199</td>\n",
       "      <td>0.947245</td>\n",
       "      <td>0.949134</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.237464</td>\n",
       "      <td>3.248307</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961696</td>\n",
       "      <td>0.957006</td>\n",
       "      <td>0.963651</td>\n",
       "      <td>0.957788</td>\n",
       "      <td>0.954279</td>\n",
       "      <td>0.958187</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.960727</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.004095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.569902</td>\n",
       "      <td>0.164532</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.963093</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956615</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.955638</td>\n",
       "      <td>0.952316</td>\n",
       "      <td>0.952130</td>\n",
       "      <td>0.954084</td>\n",
       "      <td>0.953693</td>\n",
       "      <td>0.952521</td>\n",
       "      <td>0.954958</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.964851</td>\n",
       "      <td>0.966608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.953098</td>\n",
       "      <td>0.956029</td>\n",
       "      <td>0.952511</td>\n",
       "      <td>0.951544</td>\n",
       "      <td>0.952521</td>\n",
       "      <td>0.956233</td>\n",
       "      <td>0.952325</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.954306</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953293</td>\n",
       "      <td>0.952316</td>\n",
       "      <td>0.954270</td>\n",
       "      <td>0.951534</td>\n",
       "      <td>0.951348</td>\n",
       "      <td>0.949980</td>\n",
       "      <td>0.950957</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.952378</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.962801</td>\n",
       "      <td>2.205148</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961696</td>\n",
       "      <td>0.959742</td>\n",
       "      <td>0.964823</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.955647</td>\n",
       "      <td>0.960531</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.959945</td>\n",
       "      <td>0.961348</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.153368</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961892</td>\n",
       "      <td>0.958960</td>\n",
       "      <td>0.963846</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>0.960531</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>0.003506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.173698</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.963093</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954270</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.959156</td>\n",
       "      <td>0.955638</td>\n",
       "      <td>0.951934</td>\n",
       "      <td>0.953107</td>\n",
       "      <td>0.955647</td>\n",
       "      <td>0.956038</td>\n",
       "      <td>0.955896</td>\n",
       "      <td>0.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.411498</td>\n",
       "      <td>0.125193</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961501</td>\n",
       "      <td>0.958179</td>\n",
       "      <td>0.963455</td>\n",
       "      <td>0.957592</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.959555</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.517404</td>\n",
       "      <td>1.486301</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961696</td>\n",
       "      <td>0.958960</td>\n",
       "      <td>0.964823</td>\n",
       "      <td>0.957592</td>\n",
       "      <td>0.955647</td>\n",
       "      <td>0.959750</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.960727</td>\n",
       "      <td>0.961309</td>\n",
       "      <td>0.003725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.078471</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961892</td>\n",
       "      <td>0.960524</td>\n",
       "      <td>0.965409</td>\n",
       "      <td>0.959351</td>\n",
       "      <td>0.955647</td>\n",
       "      <td>0.960531</td>\n",
       "      <td>0.961704</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.961993</td>\n",
       "      <td>0.003726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954075</td>\n",
       "      <td>0.953879</td>\n",
       "      <td>0.960328</td>\n",
       "      <td>0.955833</td>\n",
       "      <td>0.952911</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.956624</td>\n",
       "      <td>0.954865</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.105766</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>0.977153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961892</td>\n",
       "      <td>0.960328</td>\n",
       "      <td>0.965409</td>\n",
       "      <td>0.959156</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>0.960531</td>\n",
       "      <td>0.961118</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.961817</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.003196      0.000405         0.000000        0.000000   0.001   \n",
       "1        0.003198      0.000873         0.000000        0.000000   0.001   \n",
       "2        0.036096      0.004459         0.025101        0.024630   0.001   \n",
       "3        0.186599      0.041635         0.004297        0.001677   0.001   \n",
       "4        0.078598      0.022190         0.004104        0.000830   0.001   \n",
       "5        0.079001      0.018400         0.004198        0.000979   0.001   \n",
       "6        0.004098      0.001136         0.000000        0.000000    0.01   \n",
       "7        0.002700      0.000640         0.000000        0.000000    0.01   \n",
       "8        0.187503      0.059233         0.013200        0.027636    0.01   \n",
       "9        0.240496      0.068292         0.004506        0.001206    0.01   \n",
       "10       0.169798      0.043450         0.004403        0.002012    0.01   \n",
       "11       0.090299      0.013728         0.003502        0.000671    0.01   \n",
       "12       0.003097      0.000942         0.000000        0.000000     0.1   \n",
       "13       0.003699      0.001736         0.000000        0.000000     0.1   \n",
       "14       0.462500      0.197413         0.003999        0.000892     0.1   \n",
       "15       0.303900      0.088750         0.004601        0.001686     0.1   \n",
       "16       0.194602      0.063854         0.007598        0.009206     0.1   \n",
       "17       0.192499      0.065398         0.004000        0.001266     0.1   \n",
       "18       0.003100      0.000539         0.000000        0.000000     1.0   \n",
       "19       0.003099      0.000698         0.000000        0.000000     1.0   \n",
       "20       9.937261      1.252569         0.004400        0.001624     1.0   \n",
       "21       0.353499      0.068659         0.006602        0.006974     1.0   \n",
       "22       0.192598      0.053986         0.004899        0.005412     1.0   \n",
       "23       0.238300      0.050980         0.003801        0.000981     1.0   \n",
       "24       0.005799      0.004770         0.000000        0.000000    10.0   \n",
       "25       0.002901      0.000702         0.000000        0.000000    10.0   \n",
       "26      11.237464      3.248307         0.006000        0.006678    10.0   \n",
       "27       0.569902      0.164532         0.003502        0.000501    10.0   \n",
       "28       0.130600      0.003293         0.003299        0.000639    10.0   \n",
       "29       0.293400      0.077301         0.003800        0.001469    10.0   \n",
       "30       0.002799      0.000749         0.000000        0.000000   100.0   \n",
       "31       0.003000      0.000894         0.000000        0.000000   100.0   \n",
       "32      12.962801      2.205148         0.003698        0.000459   100.0   \n",
       "33       0.728902      0.153368         0.009001        0.010334   100.0   \n",
       "34       0.173698      0.036837         0.004902        0.002736   100.0   \n",
       "35       0.411498      0.125193         0.003401        0.000491   100.0   \n",
       "36       0.007501      0.007888         0.000000        0.000000  1000.0   \n",
       "37       0.004701      0.003795         0.000000        0.000000  1000.0   \n",
       "38      10.517404      1.486301         0.002504        0.000804  1000.0   \n",
       "39       0.765600      0.078471         0.004000        0.000447  1000.0   \n",
       "40       0.150300      0.028908         0.004001        0.001097  1000.0   \n",
       "41       0.483300      0.105766         0.003601        0.001113  1000.0   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0             l1    newton-cg   \n",
       "1             l1        lbfgs   \n",
       "2             l1    liblinear   \n",
       "3             l2    newton-cg   \n",
       "4             l2        lbfgs   \n",
       "5             l2    liblinear   \n",
       "6             l1    newton-cg   \n",
       "7             l1        lbfgs   \n",
       "8             l1    liblinear   \n",
       "9             l2    newton-cg   \n",
       "10            l2        lbfgs   \n",
       "11            l2    liblinear   \n",
       "12            l1    newton-cg   \n",
       "13            l1        lbfgs   \n",
       "14            l1    liblinear   \n",
       "15            l2    newton-cg   \n",
       "16            l2        lbfgs   \n",
       "17            l2    liblinear   \n",
       "18            l1    newton-cg   \n",
       "19            l1        lbfgs   \n",
       "20            l1    liblinear   \n",
       "21            l2    newton-cg   \n",
       "22            l2        lbfgs   \n",
       "23            l2    liblinear   \n",
       "24            l1    newton-cg   \n",
       "25            l1        lbfgs   \n",
       "26            l1    liblinear   \n",
       "27            l2    newton-cg   \n",
       "28            l2        lbfgs   \n",
       "29            l2    liblinear   \n",
       "30            l1    newton-cg   \n",
       "31            l1        lbfgs   \n",
       "32            l1    liblinear   \n",
       "33            l2    newton-cg   \n",
       "34            l2        lbfgs   \n",
       "35            l2    liblinear   \n",
       "36            l1    newton-cg   \n",
       "37            l1        lbfgs   \n",
       "38            l1    liblinear   \n",
       "39            l2    newton-cg   \n",
       "40            l2        lbfgs   \n",
       "41            l2    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.001, 'penalty': 'l1', 'solver': 'newto...                NaN   \n",
       "1    {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "2   {'C': 0.001, 'penalty': 'l1', 'solver': 'libli...           0.755712   \n",
       "3   {'C': 0.001, 'penalty': 'l2', 'solver': 'newto...           0.873462   \n",
       "4    {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}           0.873462   \n",
       "5   {'C': 0.001, 'penalty': 'l2', 'solver': 'libli...           0.861160   \n",
       "6   {'C': 0.01, 'penalty': 'l1', 'solver': 'newton...                NaN   \n",
       "7     {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "8   {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...           0.905097   \n",
       "9   {'C': 0.01, 'penalty': 'l2', 'solver': 'newton...           0.903339   \n",
       "10    {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}           0.903339   \n",
       "11  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...           0.901582   \n",
       "12  {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...                NaN   \n",
       "13     {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "14  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...           0.943761   \n",
       "15  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...           0.934974   \n",
       "16     {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.934974   \n",
       "17  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.933216   \n",
       "18  {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...                NaN   \n",
       "19     {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "20  {'C': 1.0, 'penalty': 'l1', 'solver': 'libline...           0.957821   \n",
       "21  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...           0.945518   \n",
       "22     {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}           0.947276   \n",
       "23  {'C': 1.0, 'penalty': 'l2', 'solver': 'libline...           0.945518   \n",
       "24  {'C': 10.0, 'penalty': 'l1', 'solver': 'newton...                NaN   \n",
       "25    {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "26  {'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...           0.970123   \n",
       "27  {'C': 10.0, 'penalty': 'l2', 'solver': 'newton...           0.963093   \n",
       "28    {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}           0.964851   \n",
       "29  {'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...           0.954306   \n",
       "30  {'C': 100.0, 'penalty': 'l1', 'solver': 'newto...                NaN   \n",
       "31   {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "32  {'C': 100.0, 'penalty': 'l1', 'solver': 'libli...           0.970123   \n",
       "33  {'C': 100.0, 'penalty': 'l2', 'solver': 'newto...           0.970123   \n",
       "34   {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}           0.963093   \n",
       "35  {'C': 100.0, 'penalty': 'l2', 'solver': 'libli...           0.970123   \n",
       "36  {'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...                NaN   \n",
       "37  {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "38  {'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...           0.970123   \n",
       "39  {'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...           0.971880   \n",
       "40  {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}           0.968366   \n",
       "41  {'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...           0.971880   \n",
       "\n",
       "    split1_test_score  ...  split2_train_score  split3_train_score  \\\n",
       "0                 NaN  ...                 NaN                 NaN   \n",
       "1                 NaN  ...                 NaN                 NaN   \n",
       "2            0.789104  ...            0.772718            0.771546   \n",
       "3            0.899824  ...            0.880399            0.880790   \n",
       "4            0.899824  ...            0.880399            0.880790   \n",
       "5            0.891037  ...            0.871409            0.869846   \n",
       "6                 NaN  ...                 NaN                 NaN   \n",
       "7                 NaN  ...                 NaN                 NaN   \n",
       "8            0.920914  ...            0.903654            0.905609   \n",
       "9            0.910369  ...            0.908736            0.909126   \n",
       "10           0.910369  ...            0.908736            0.909126   \n",
       "11           0.919156  ...            0.911276            0.909322   \n",
       "12                NaN  ...                 NaN                 NaN   \n",
       "13                NaN  ...                 NaN                 NaN   \n",
       "14           0.957821  ...            0.945280            0.945671   \n",
       "15           0.950791  ...            0.935900            0.938636   \n",
       "16           0.952548  ...            0.936682            0.937463   \n",
       "17           0.950791  ...            0.934337            0.935900   \n",
       "18                NaN  ...                 NaN                 NaN   \n",
       "19                NaN  ...                 NaN                 NaN   \n",
       "20           0.970123  ...            0.955443            0.954466   \n",
       "21           0.964851  ...            0.949580            0.949580   \n",
       "22           0.964851  ...            0.950948            0.949775   \n",
       "23           0.963093  ...            0.950362            0.949971   \n",
       "24                NaN  ...                 NaN                 NaN   \n",
       "25                NaN  ...                 NaN                 NaN   \n",
       "26           0.977153  ...            0.961696            0.957006   \n",
       "27           0.971880  ...            0.956615            0.953684   \n",
       "28           0.966608  ...            0.953684            0.953098   \n",
       "29           0.970123  ...            0.953293            0.952316   \n",
       "30                NaN  ...                 NaN                 NaN   \n",
       "31                NaN  ...                 NaN                 NaN   \n",
       "32           0.977153  ...            0.961696            0.959742   \n",
       "33           0.977153  ...            0.961892            0.958960   \n",
       "34           0.968366  ...            0.954270            0.953684   \n",
       "35           0.977153  ...            0.961501            0.958179   \n",
       "36                NaN  ...                 NaN                 NaN   \n",
       "37                NaN  ...                 NaN                 NaN   \n",
       "38           0.977153  ...            0.961696            0.958960   \n",
       "39           0.977153  ...            0.961892            0.960524   \n",
       "40           0.970123  ...            0.954075            0.953879   \n",
       "41           0.977153  ...            0.961892            0.960328   \n",
       "\n",
       "    split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0                  NaN                 NaN                 NaN   \n",
       "1                  NaN                 NaN                 NaN   \n",
       "2             0.769201            0.769982            0.772177   \n",
       "3             0.878640            0.880594            0.881008   \n",
       "4             0.878640            0.880594            0.881008   \n",
       "5             0.869846            0.870823            0.867722   \n",
       "6                  NaN                 NaN                 NaN   \n",
       "7                  NaN                 NaN                 NaN   \n",
       "8             0.907758            0.904241            0.906018   \n",
       "9             0.911276            0.908149            0.908753   \n",
       "10            0.911276            0.908149            0.908753   \n",
       "11            0.913817            0.913035            0.909926   \n",
       "12                 NaN                 NaN                 NaN   \n",
       "13                 NaN                 NaN                 NaN   \n",
       "14            0.948407            0.945867            0.946659   \n",
       "15            0.939418            0.936095            0.939625   \n",
       "16            0.939027            0.936095            0.938062   \n",
       "17            0.938245            0.934141            0.937280   \n",
       "18                 NaN                 NaN                 NaN   \n",
       "19                 NaN                 NaN                 NaN   \n",
       "20            0.954466            0.953488            0.952716   \n",
       "21            0.950557            0.948603            0.949590   \n",
       "22            0.950752            0.949580            0.948808   \n",
       "23            0.950362            0.948603            0.949980   \n",
       "24                 NaN                 NaN                 NaN   \n",
       "25                 NaN                 NaN                 NaN   \n",
       "26            0.963651            0.957788            0.954279   \n",
       "27            0.955638            0.952316            0.952130   \n",
       "28            0.956029            0.952511            0.951544   \n",
       "29            0.954270            0.951534            0.951348   \n",
       "30                 NaN                 NaN                 NaN   \n",
       "31                 NaN                 NaN                 NaN   \n",
       "32            0.964823            0.957983            0.955647   \n",
       "33            0.963846            0.957983            0.955842   \n",
       "34            0.959156            0.955638            0.951934   \n",
       "35            0.963455            0.957592            0.955842   \n",
       "36                 NaN                 NaN                 NaN   \n",
       "37                 NaN                 NaN                 NaN   \n",
       "38            0.964823            0.957592            0.955647   \n",
       "39            0.965409            0.959351            0.955647   \n",
       "40            0.960328            0.955833            0.952911   \n",
       "41            0.965409            0.959156            0.955842   \n",
       "\n",
       "    split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0                  NaN                 NaN                 NaN   \n",
       "1                  NaN                 NaN                 NaN   \n",
       "2             0.771981            0.769050            0.774521   \n",
       "3             0.881399            0.880227            0.881204   \n",
       "4             0.881399            0.880227            0.881204   \n",
       "5             0.871630            0.870066            0.871434   \n",
       "6                  NaN                 NaN                 NaN   \n",
       "7                  NaN                 NaN                 NaN   \n",
       "8             0.902892            0.904259            0.903869   \n",
       "9             0.909340            0.908949            0.909144   \n",
       "10            0.909340            0.908949            0.909144   \n",
       "11            0.910707            0.910903            0.910707   \n",
       "12                 NaN                 NaN                 NaN   \n",
       "13                 NaN                 NaN                 NaN   \n",
       "14            0.942751            0.947440            0.942946   \n",
       "15            0.934154            0.937866            0.934740   \n",
       "16            0.934545            0.937866            0.936303   \n",
       "17            0.932591            0.937085            0.934545   \n",
       "18                 NaN                 NaN                 NaN   \n",
       "19                 NaN                 NaN                 NaN   \n",
       "20            0.953888            0.954670            0.952716   \n",
       "21            0.946073            0.949199            0.946659   \n",
       "22            0.947050            0.949980            0.948808   \n",
       "23            0.946854            0.949199            0.947245   \n",
       "24                 NaN                 NaN                 NaN   \n",
       "25                 NaN                 NaN                 NaN   \n",
       "26            0.958187            0.959359            0.960727   \n",
       "27            0.954084            0.953693            0.952521   \n",
       "28            0.952521            0.956233            0.952325   \n",
       "29            0.949980            0.950957            0.950176   \n",
       "30                 NaN                 NaN                 NaN   \n",
       "31                 NaN                 NaN                 NaN   \n",
       "32            0.960531            0.960922            0.959945   \n",
       "33            0.960336            0.960531            0.960922   \n",
       "34            0.953107            0.955647            0.956038   \n",
       "35            0.959359            0.959555            0.960336   \n",
       "36                 NaN                 NaN                 NaN   \n",
       "37                 NaN                 NaN                 NaN   \n",
       "38            0.959750            0.960922            0.960727   \n",
       "39            0.960531            0.961704            0.960922   \n",
       "40            0.953497            0.956624            0.954865   \n",
       "41            0.960531            0.961118            0.960922   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0                NaN              NaN  \n",
       "1                NaN              NaN  \n",
       "2           0.771368         0.001781  \n",
       "3           0.880330         0.001055  \n",
       "4           0.880330         0.001055  \n",
       "5           0.870110         0.001349  \n",
       "6                NaN              NaN  \n",
       "7                NaN              NaN  \n",
       "8           0.904541         0.001632  \n",
       "9           0.909231         0.000786  \n",
       "10          0.909231         0.000786  \n",
       "11          0.911264         0.001590  \n",
       "12               NaN              NaN  \n",
       "13               NaN              NaN  \n",
       "14          0.945754         0.001740  \n",
       "15          0.936706         0.001935  \n",
       "16          0.936765         0.001299  \n",
       "17          0.935338         0.001718  \n",
       "18               NaN              NaN  \n",
       "19               NaN              NaN  \n",
       "20          0.954723         0.001782  \n",
       "21          0.948744         0.001624  \n",
       "22          0.949467         0.001190  \n",
       "23          0.949134         0.001407  \n",
       "24               NaN              NaN  \n",
       "25               NaN              NaN  \n",
       "26          0.960547         0.004095  \n",
       "27          0.954958         0.002697  \n",
       "28          0.954332         0.002476  \n",
       "29          0.952378         0.001974  \n",
       "30               NaN              NaN  \n",
       "31               NaN              NaN  \n",
       "32          0.961348         0.003603  \n",
       "33          0.961289         0.003506  \n",
       "34          0.955896         0.002976  \n",
       "35          0.960859         0.003643  \n",
       "36               NaN              NaN  \n",
       "37               NaN              NaN  \n",
       "38          0.961309         0.003725  \n",
       "39          0.961993         0.003726  \n",
       "40          0.955603         0.002327  \n",
       "41          0.961817         0.003653  \n",
       "\n",
       "[42 rows x 33 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.105766</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...</td>\n",
       "      <td>0.960604</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961817</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.078471</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...</td>\n",
       "      <td>0.960427</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961993</td>\n",
       "      <td>0.003726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.517404</td>\n",
       "      <td>1.486301</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961309</td>\n",
       "      <td>0.003725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.962801</td>\n",
       "      <td>2.205148</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961348</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.153368</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>5</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>0.003506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.237464</td>\n",
       "      <td>3.248307</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>6</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.004095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.411498</td>\n",
       "      <td>0.125193</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.959020</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>7</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.953920</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>8</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.569902</td>\n",
       "      <td>0.164532</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.953744</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>9</td>\n",
       "      <td>0.954958</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.173698</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.953569</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955896</td>\n",
       "      <td>0.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.952689</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>11</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.937261</td>\n",
       "      <td>1.252569</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.952162</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954723</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.950930</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>13</td>\n",
       "      <td>0.952378</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.353499</td>\n",
       "      <td>0.068659</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.946886</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>14</td>\n",
       "      <td>0.948744</td>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.192598</td>\n",
       "      <td>0.053986</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.946885</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>15</td>\n",
       "      <td>0.949467</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.946710</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>16</td>\n",
       "      <td>0.949134</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.197413</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.945127</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>17</td>\n",
       "      <td>0.945754</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.088750</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>18</td>\n",
       "      <td>0.936706</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.194602</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.935981</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>19</td>\n",
       "      <td>0.936765</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.192499</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.935102</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>20</td>\n",
       "      <td>0.935338</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.090299</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.909779</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>21</td>\n",
       "      <td>0.911264</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.240496</td>\n",
       "      <td>0.068292</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>22</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169798</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>22</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.187503</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.904327</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>24</td>\n",
       "      <td>0.904541</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.879174</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>25</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078598</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.879174</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>25</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>27</td>\n",
       "      <td>0.870110</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.771365</td>\n",
       "      <td>0.016037</td>\n",
       "      <td>28</td>\n",
       "      <td>0.771368</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "41       0.483300      0.105766         0.003601        0.001113  1000.0   \n",
       "39       0.765600      0.078471         0.004000        0.000447  1000.0   \n",
       "38      10.517404      1.486301         0.002504        0.000804  1000.0   \n",
       "32      12.962801      2.205148         0.003698        0.000459   100.0   \n",
       "33       0.728902      0.153368         0.009001        0.010334   100.0   \n",
       "26      11.237464      3.248307         0.006000        0.006678    10.0   \n",
       "35       0.411498      0.125193         0.003401        0.000491   100.0   \n",
       "40       0.150300      0.028908         0.004001        0.001097  1000.0   \n",
       "27       0.569902      0.164532         0.003502        0.000501    10.0   \n",
       "34       0.173698      0.036837         0.004902        0.002736   100.0   \n",
       "28       0.130600      0.003293         0.003299        0.000639    10.0   \n",
       "20       9.937261      1.252569         0.004400        0.001624     1.0   \n",
       "29       0.293400      0.077301         0.003800        0.001469    10.0   \n",
       "21       0.353499      0.068659         0.006602        0.006974     1.0   \n",
       "22       0.192598      0.053986         0.004899        0.005412     1.0   \n",
       "23       0.238300      0.050980         0.003801        0.000981     1.0   \n",
       "14       0.462500      0.197413         0.003999        0.000892     0.1   \n",
       "15       0.303900      0.088750         0.004601        0.001686     0.1   \n",
       "16       0.194602      0.063854         0.007598        0.009206     0.1   \n",
       "17       0.192499      0.065398         0.004000        0.001266     0.1   \n",
       "11       0.090299      0.013728         0.003502        0.000671    0.01   \n",
       "9        0.240496      0.068292         0.004506        0.001206    0.01   \n",
       "10       0.169798      0.043450         0.004403        0.002012    0.01   \n",
       "8        0.187503      0.059233         0.013200        0.027636    0.01   \n",
       "3        0.186599      0.041635         0.004297        0.001677   0.001   \n",
       "4        0.078598      0.022190         0.004104        0.000830   0.001   \n",
       "5        0.079001      0.018400         0.004198        0.000979   0.001   \n",
       "2        0.036096      0.004459         0.025101        0.024630   0.001   \n",
       "37       0.004701      0.003795         0.000000        0.000000  1000.0   \n",
       "36       0.007501      0.007888         0.000000        0.000000  1000.0   \n",
       "1        0.003198      0.000873         0.000000        0.000000   0.001   \n",
       "6        0.004098      0.001136         0.000000        0.000000    0.01   \n",
       "12       0.003097      0.000942         0.000000        0.000000     0.1   \n",
       "30       0.002799      0.000749         0.000000        0.000000   100.0   \n",
       "7        0.002700      0.000640         0.000000        0.000000    0.01   \n",
       "25       0.002901      0.000702         0.000000        0.000000    10.0   \n",
       "24       0.005799      0.004770         0.000000        0.000000    10.0   \n",
       "19       0.003099      0.000698         0.000000        0.000000     1.0   \n",
       "18       0.003100      0.000539         0.000000        0.000000     1.0   \n",
       "13       0.003699      0.001736         0.000000        0.000000     0.1   \n",
       "31       0.003000      0.000894         0.000000        0.000000   100.0   \n",
       "0        0.003196      0.000405         0.000000        0.000000   0.001   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "41            l2    liblinear   \n",
       "39            l2    newton-cg   \n",
       "38            l1    liblinear   \n",
       "32            l1    liblinear   \n",
       "33            l2    newton-cg   \n",
       "26            l1    liblinear   \n",
       "35            l2    liblinear   \n",
       "40            l2        lbfgs   \n",
       "27            l2    newton-cg   \n",
       "34            l2        lbfgs   \n",
       "28            l2        lbfgs   \n",
       "20            l1    liblinear   \n",
       "29            l2    liblinear   \n",
       "21            l2    newton-cg   \n",
       "22            l2        lbfgs   \n",
       "23            l2    liblinear   \n",
       "14            l1    liblinear   \n",
       "15            l2    newton-cg   \n",
       "16            l2        lbfgs   \n",
       "17            l2    liblinear   \n",
       "11            l2    liblinear   \n",
       "9             l2    newton-cg   \n",
       "10            l2        lbfgs   \n",
       "8             l1    liblinear   \n",
       "3             l2    newton-cg   \n",
       "4             l2        lbfgs   \n",
       "5             l2    liblinear   \n",
       "2             l1    liblinear   \n",
       "37            l1        lbfgs   \n",
       "36            l1    newton-cg   \n",
       "1             l1        lbfgs   \n",
       "6             l1    newton-cg   \n",
       "12            l1    newton-cg   \n",
       "30            l1    newton-cg   \n",
       "7             l1        lbfgs   \n",
       "25            l1        lbfgs   \n",
       "24            l1    newton-cg   \n",
       "19            l1        lbfgs   \n",
       "18            l1    newton-cg   \n",
       "13            l1        lbfgs   \n",
       "31            l1        lbfgs   \n",
       "0             l1    newton-cg   \n",
       "\n",
       "                                               params  mean_test_score  \\\n",
       "41  {'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...         0.960604   \n",
       "39  {'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...         0.960427   \n",
       "38  {'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...         0.959900   \n",
       "32  {'C': 100.0, 'penalty': 'l1', 'solver': 'libli...         0.959900   \n",
       "33  {'C': 100.0, 'penalty': 'l2', 'solver': 'newto...         0.959900   \n",
       "26  {'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...         0.959196   \n",
       "35  {'C': 100.0, 'penalty': 'l2', 'solver': 'libli...         0.959020   \n",
       "40  {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.953920   \n",
       "27  {'C': 10.0, 'penalty': 'l2', 'solver': 'newton...         0.953744   \n",
       "34   {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.953569   \n",
       "28    {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.952689   \n",
       "20  {'C': 1.0, 'penalty': 'l1', 'solver': 'libline...         0.952162   \n",
       "29  {'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...         0.950930   \n",
       "21  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...         0.946886   \n",
       "22     {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.946885   \n",
       "23  {'C': 1.0, 'penalty': 'l2', 'solver': 'libline...         0.946710   \n",
       "14  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...         0.945127   \n",
       "15  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...         0.935982   \n",
       "16     {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}         0.935981   \n",
       "17  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...         0.935102   \n",
       "11  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...         0.909779   \n",
       "9   {'C': 0.01, 'penalty': 'l2', 'solver': 'newton...         0.908372   \n",
       "10    {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}         0.908372   \n",
       "8   {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...         0.904327   \n",
       "3   {'C': 0.001, 'penalty': 'l2', 'solver': 'newto...         0.879174   \n",
       "4    {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}         0.879174   \n",
       "5   {'C': 0.001, 'penalty': 'l2', 'solver': 'libli...         0.869679   \n",
       "2   {'C': 0.001, 'penalty': 'l1', 'solver': 'libli...         0.771365   \n",
       "37  {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "36  {'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...              NaN   \n",
       "1    {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "6   {'C': 0.01, 'penalty': 'l1', 'solver': 'newton...              NaN   \n",
       "12  {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...              NaN   \n",
       "30  {'C': 100.0, 'penalty': 'l1', 'solver': 'newto...              NaN   \n",
       "7     {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "25    {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "24  {'C': 10.0, 'penalty': 'l1', 'solver': 'newton...              NaN   \n",
       "19     {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "18  {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...              NaN   \n",
       "13     {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "31   {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "0   {'C': 0.001, 'penalty': 'l1', 'solver': 'newto...              NaN   \n",
       "\n",
       "    std_test_score  rank_test_score  mean_train_score  std_train_score  \n",
       "41        0.012444                1          0.961817         0.003653  \n",
       "39        0.012621                2          0.961993         0.003726  \n",
       "38        0.012408                3          0.961309         0.003725  \n",
       "32        0.012359                4          0.961348         0.003603  \n",
       "33        0.012461                5          0.961289         0.003506  \n",
       "26        0.012609                6          0.960547         0.004095  \n",
       "35        0.012593                7          0.960859         0.003643  \n",
       "40        0.010319                8          0.955603         0.002327  \n",
       "27        0.011106                9          0.954958         0.002697  \n",
       "34        0.010878               10          0.955896         0.002976  \n",
       "28        0.010093               11          0.954332         0.002476  \n",
       "20        0.010103               12          0.954723         0.001782  \n",
       "29        0.010513               13          0.952378         0.001974  \n",
       "21        0.008615               14          0.948744         0.001624  \n",
       "22        0.009246               15          0.949467         0.001190  \n",
       "23        0.008660               16          0.949134         0.001407  \n",
       "14        0.007980               17          0.945754         0.001740  \n",
       "15        0.006361               18          0.936706         0.001935  \n",
       "16        0.007277               19          0.936765         0.001299  \n",
       "17        0.006032               20          0.935338         0.001718  \n",
       "11        0.007543               21          0.911264         0.001590  \n",
       "9         0.006731               22          0.909231         0.000786  \n",
       "10        0.006731               22          0.909231         0.000786  \n",
       "8         0.010277               24          0.904541         0.001632  \n",
       "3         0.011344               25          0.880330         0.001055  \n",
       "4         0.011344               25          0.880330         0.001055  \n",
       "5         0.012026               27          0.870110         0.001349  \n",
       "2         0.016037               28          0.771368         0.001781  \n",
       "37             NaN               29               NaN              NaN  \n",
       "36             NaN               30               NaN              NaN  \n",
       "1              NaN               31               NaN              NaN  \n",
       "6              NaN               32               NaN              NaN  \n",
       "12             NaN               33               NaN              NaN  \n",
       "30             NaN               34               NaN              NaN  \n",
       "7              NaN               35               NaN              NaN  \n",
       "25             NaN               36               NaN              NaN  \n",
       "24             NaN               37               NaN              NaN  \n",
       "19             NaN               38               NaN              NaN  \n",
       "18             NaN               39               NaN              NaN  \n",
       "13             NaN               40               NaN              NaN  \n",
       "31             NaN               41               NaN              NaN  \n",
       "0              NaN               42               NaN              NaN  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [i for i in res.columns if 'split' not in i]\n",
    "res = res[cols]\n",
    "res = res.sort_values('rank_test_score')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultize(grid):\n",
    "    \"\"\"make a fancy df from grid.cv_results\"\"\"\n",
    "    res = grid.cv_results_\n",
    "    res = pd.DataFrame(res)\n",
    "    cols = [i for i in res.columns if 'split' not in i]\n",
    "    res = res[cols]\n",
    "    res = res.sort_values('rank_test_score')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.105766</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...</td>\n",
       "      <td>0.960604</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961817</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.078471</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...</td>\n",
       "      <td>0.960427</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961993</td>\n",
       "      <td>0.003726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.517404</td>\n",
       "      <td>1.486301</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961309</td>\n",
       "      <td>0.003725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.962801</td>\n",
       "      <td>2.205148</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961348</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.153368</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>5</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>0.003506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.237464</td>\n",
       "      <td>3.248307</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>6</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.004095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.411498</td>\n",
       "      <td>0.125193</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.959020</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>7</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.953920</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>8</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.569902</td>\n",
       "      <td>0.164532</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.953744</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>9</td>\n",
       "      <td>0.954958</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.173698</td>\n",
       "      <td>0.036837</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.953569</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955896</td>\n",
       "      <td>0.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.952689</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>11</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.937261</td>\n",
       "      <td>1.252569</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.952162</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954723</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.950930</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>13</td>\n",
       "      <td>0.952378</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.353499</td>\n",
       "      <td>0.068659</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.946886</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>14</td>\n",
       "      <td>0.948744</td>\n",
       "      <td>0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.192598</td>\n",
       "      <td>0.053986</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.946885</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>15</td>\n",
       "      <td>0.949467</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.946710</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>16</td>\n",
       "      <td>0.949134</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.197413</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.945127</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>17</td>\n",
       "      <td>0.945754</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.088750</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>18</td>\n",
       "      <td>0.936706</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.194602</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.935981</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>19</td>\n",
       "      <td>0.936765</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.192499</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.935102</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>20</td>\n",
       "      <td>0.935338</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.090299</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.909779</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>21</td>\n",
       "      <td>0.911264</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.240496</td>\n",
       "      <td>0.068292</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'newton...</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>22</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169798</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>22</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.187503</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n",
       "      <td>0.904327</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>24</td>\n",
       "      <td>0.904541</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'newto...</td>\n",
       "      <td>0.879174</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>25</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078598</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.879174</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>25</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>27</td>\n",
       "      <td>0.870110</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'libli...</td>\n",
       "      <td>0.771365</td>\n",
       "      <td>0.016037</td>\n",
       "      <td>28</td>\n",
       "      <td>0.771368</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1', 'solver': 'newton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "41       0.483300      0.105766         0.003601        0.001113  1000.0   \n",
       "39       0.765600      0.078471         0.004000        0.000447  1000.0   \n",
       "38      10.517404      1.486301         0.002504        0.000804  1000.0   \n",
       "32      12.962801      2.205148         0.003698        0.000459   100.0   \n",
       "33       0.728902      0.153368         0.009001        0.010334   100.0   \n",
       "26      11.237464      3.248307         0.006000        0.006678    10.0   \n",
       "35       0.411498      0.125193         0.003401        0.000491   100.0   \n",
       "40       0.150300      0.028908         0.004001        0.001097  1000.0   \n",
       "27       0.569902      0.164532         0.003502        0.000501    10.0   \n",
       "34       0.173698      0.036837         0.004902        0.002736   100.0   \n",
       "28       0.130600      0.003293         0.003299        0.000639    10.0   \n",
       "20       9.937261      1.252569         0.004400        0.001624     1.0   \n",
       "29       0.293400      0.077301         0.003800        0.001469    10.0   \n",
       "21       0.353499      0.068659         0.006602        0.006974     1.0   \n",
       "22       0.192598      0.053986         0.004899        0.005412     1.0   \n",
       "23       0.238300      0.050980         0.003801        0.000981     1.0   \n",
       "14       0.462500      0.197413         0.003999        0.000892     0.1   \n",
       "15       0.303900      0.088750         0.004601        0.001686     0.1   \n",
       "16       0.194602      0.063854         0.007598        0.009206     0.1   \n",
       "17       0.192499      0.065398         0.004000        0.001266     0.1   \n",
       "11       0.090299      0.013728         0.003502        0.000671    0.01   \n",
       "9        0.240496      0.068292         0.004506        0.001206    0.01   \n",
       "10       0.169798      0.043450         0.004403        0.002012    0.01   \n",
       "8        0.187503      0.059233         0.013200        0.027636    0.01   \n",
       "3        0.186599      0.041635         0.004297        0.001677   0.001   \n",
       "4        0.078598      0.022190         0.004104        0.000830   0.001   \n",
       "5        0.079001      0.018400         0.004198        0.000979   0.001   \n",
       "2        0.036096      0.004459         0.025101        0.024630   0.001   \n",
       "37       0.004701      0.003795         0.000000        0.000000  1000.0   \n",
       "36       0.007501      0.007888         0.000000        0.000000  1000.0   \n",
       "1        0.003198      0.000873         0.000000        0.000000   0.001   \n",
       "6        0.004098      0.001136         0.000000        0.000000    0.01   \n",
       "12       0.003097      0.000942         0.000000        0.000000     0.1   \n",
       "30       0.002799      0.000749         0.000000        0.000000   100.0   \n",
       "7        0.002700      0.000640         0.000000        0.000000    0.01   \n",
       "25       0.002901      0.000702         0.000000        0.000000    10.0   \n",
       "24       0.005799      0.004770         0.000000        0.000000    10.0   \n",
       "19       0.003099      0.000698         0.000000        0.000000     1.0   \n",
       "18       0.003100      0.000539         0.000000        0.000000     1.0   \n",
       "13       0.003699      0.001736         0.000000        0.000000     0.1   \n",
       "31       0.003000      0.000894         0.000000        0.000000   100.0   \n",
       "0        0.003196      0.000405         0.000000        0.000000   0.001   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "41            l2    liblinear   \n",
       "39            l2    newton-cg   \n",
       "38            l1    liblinear   \n",
       "32            l1    liblinear   \n",
       "33            l2    newton-cg   \n",
       "26            l1    liblinear   \n",
       "35            l2    liblinear   \n",
       "40            l2        lbfgs   \n",
       "27            l2    newton-cg   \n",
       "34            l2        lbfgs   \n",
       "28            l2        lbfgs   \n",
       "20            l1    liblinear   \n",
       "29            l2    liblinear   \n",
       "21            l2    newton-cg   \n",
       "22            l2        lbfgs   \n",
       "23            l2    liblinear   \n",
       "14            l1    liblinear   \n",
       "15            l2    newton-cg   \n",
       "16            l2        lbfgs   \n",
       "17            l2    liblinear   \n",
       "11            l2    liblinear   \n",
       "9             l2    newton-cg   \n",
       "10            l2        lbfgs   \n",
       "8             l1    liblinear   \n",
       "3             l2    newton-cg   \n",
       "4             l2        lbfgs   \n",
       "5             l2    liblinear   \n",
       "2             l1    liblinear   \n",
       "37            l1        lbfgs   \n",
       "36            l1    newton-cg   \n",
       "1             l1        lbfgs   \n",
       "6             l1    newton-cg   \n",
       "12            l1    newton-cg   \n",
       "30            l1    newton-cg   \n",
       "7             l1        lbfgs   \n",
       "25            l1        lbfgs   \n",
       "24            l1    newton-cg   \n",
       "19            l1        lbfgs   \n",
       "18            l1    newton-cg   \n",
       "13            l1        lbfgs   \n",
       "31            l1        lbfgs   \n",
       "0             l1    newton-cg   \n",
       "\n",
       "                                               params  mean_test_score  \\\n",
       "41  {'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...         0.960604   \n",
       "39  {'C': 1000.0, 'penalty': 'l2', 'solver': 'newt...         0.960427   \n",
       "38  {'C': 1000.0, 'penalty': 'l1', 'solver': 'libl...         0.959900   \n",
       "32  {'C': 100.0, 'penalty': 'l1', 'solver': 'libli...         0.959900   \n",
       "33  {'C': 100.0, 'penalty': 'l2', 'solver': 'newto...         0.959900   \n",
       "26  {'C': 10.0, 'penalty': 'l1', 'solver': 'liblin...         0.959196   \n",
       "35  {'C': 100.0, 'penalty': 'l2', 'solver': 'libli...         0.959020   \n",
       "40  {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.953920   \n",
       "27  {'C': 10.0, 'penalty': 'l2', 'solver': 'newton...         0.953744   \n",
       "34   {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.953569   \n",
       "28    {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.952689   \n",
       "20  {'C': 1.0, 'penalty': 'l1', 'solver': 'libline...         0.952162   \n",
       "29  {'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...         0.950930   \n",
       "21  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-...         0.946886   \n",
       "22     {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}         0.946885   \n",
       "23  {'C': 1.0, 'penalty': 'l2', 'solver': 'libline...         0.946710   \n",
       "14  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...         0.945127   \n",
       "15  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...         0.935982   \n",
       "16     {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}         0.935981   \n",
       "17  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...         0.935102   \n",
       "11  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...         0.909779   \n",
       "9   {'C': 0.01, 'penalty': 'l2', 'solver': 'newton...         0.908372   \n",
       "10    {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}         0.908372   \n",
       "8   {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...         0.904327   \n",
       "3   {'C': 0.001, 'penalty': 'l2', 'solver': 'newto...         0.879174   \n",
       "4    {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}         0.879174   \n",
       "5   {'C': 0.001, 'penalty': 'l2', 'solver': 'libli...         0.869679   \n",
       "2   {'C': 0.001, 'penalty': 'l1', 'solver': 'libli...         0.771365   \n",
       "37  {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "36  {'C': 1000.0, 'penalty': 'l1', 'solver': 'newt...              NaN   \n",
       "1    {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "6   {'C': 0.01, 'penalty': 'l1', 'solver': 'newton...              NaN   \n",
       "12  {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...              NaN   \n",
       "30  {'C': 100.0, 'penalty': 'l1', 'solver': 'newto...              NaN   \n",
       "7     {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "25    {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "24  {'C': 10.0, 'penalty': 'l1', 'solver': 'newton...              NaN   \n",
       "19     {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "18  {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-...              NaN   \n",
       "13     {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "31   {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN   \n",
       "0   {'C': 0.001, 'penalty': 'l1', 'solver': 'newto...              NaN   \n",
       "\n",
       "    std_test_score  rank_test_score  mean_train_score  std_train_score  \n",
       "41        0.012444                1          0.961817         0.003653  \n",
       "39        0.012621                2          0.961993         0.003726  \n",
       "38        0.012408                3          0.961309         0.003725  \n",
       "32        0.012359                4          0.961348         0.003603  \n",
       "33        0.012461                5          0.961289         0.003506  \n",
       "26        0.012609                6          0.960547         0.004095  \n",
       "35        0.012593                7          0.960859         0.003643  \n",
       "40        0.010319                8          0.955603         0.002327  \n",
       "27        0.011106                9          0.954958         0.002697  \n",
       "34        0.010878               10          0.955896         0.002976  \n",
       "28        0.010093               11          0.954332         0.002476  \n",
       "20        0.010103               12          0.954723         0.001782  \n",
       "29        0.010513               13          0.952378         0.001974  \n",
       "21        0.008615               14          0.948744         0.001624  \n",
       "22        0.009246               15          0.949467         0.001190  \n",
       "23        0.008660               16          0.949134         0.001407  \n",
       "14        0.007980               17          0.945754         0.001740  \n",
       "15        0.006361               18          0.936706         0.001935  \n",
       "16        0.007277               19          0.936765         0.001299  \n",
       "17        0.006032               20          0.935338         0.001718  \n",
       "11        0.007543               21          0.911264         0.001590  \n",
       "9         0.006731               22          0.909231         0.000786  \n",
       "10        0.006731               22          0.909231         0.000786  \n",
       "8         0.010277               24          0.904541         0.001632  \n",
       "3         0.011344               25          0.880330         0.001055  \n",
       "4         0.011344               25          0.880330         0.001055  \n",
       "5         0.012026               27          0.870110         0.001349  \n",
       "2         0.016037               28          0.771368         0.001781  \n",
       "37             NaN               29               NaN              NaN  \n",
       "36             NaN               30               NaN              NaN  \n",
       "1              NaN               31               NaN              NaN  \n",
       "6              NaN               32               NaN              NaN  \n",
       "12             NaN               33               NaN              NaN  \n",
       "30             NaN               34               NaN              NaN  \n",
       "7              NaN               35               NaN              NaN  \n",
       "25             NaN               36               NaN              NaN  \n",
       "24             NaN               37               NaN              NaN  \n",
       "19             NaN               38               NaN              NaN  \n",
       "18             NaN               39               NaN              NaN  \n",
       "13             NaN               40               NaN              NaN  \n",
       "31             NaN               41               NaN              NaN  \n",
       "0              NaN               42               NaN              NaN  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000.0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000.0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000.0, solver='liblinear')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ré-entraînement\n",
    "estimator = LogisticRegression(**best_params)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.9618, score test 0.9623\n"
     ]
    }
   ],
   "source": [
    "score(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1210</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>45</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1210      47\n",
       "test_1      45    1136"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622530425720958"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             return_train_score=True, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             return_train_score=True, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LinearSVC()\n",
    "\n",
    "params = {'C': np.logspace(-3, 3, 7)}\n",
    "grid = GridSearchCV(\n",
    "    estimator,\n",
    "    params,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03399878, 0.13939881, 0.8637964 , 1.01370125, 1.03929818,\n",
       "        1.15730135, 1.21389637]),\n",
       " 'std_fit_time': array([0.00454044, 0.03945075, 0.15944753, 0.13962401, 0.15640685,\n",
       "        0.28309661, 0.19119146]),\n",
       " 'mean_score_time': array([0.02279952, 0.01870368, 0.0045032 , 0.00379961, 0.00420053,\n",
       "        0.0049998 , 0.00340095]),\n",
       " 'std_score_time': array([0.00386648, 0.03051772, 0.00246115, 0.00236389, 0.00334087,\n",
       "        0.00252671, 0.00111447]),\n",
       " 'param_C': masked_array(data=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 1.0},\n",
       "  {'C': 10.0},\n",
       "  {'C': 100.0},\n",
       "  {'C': 1000.0}],\n",
       " 'split0_test_score': array([0.91212654, 0.93321617, 0.94551845, 0.95254833, 0.93321617,\n",
       "        0.93497364, 0.89806678]),\n",
       " 'split1_test_score': array([0.92618629, 0.94903339, 0.96660808, 0.96836555, 0.95079086,\n",
       "        0.95782074, 0.95782074]),\n",
       " 'split2_test_score': array([0.91036907, 0.93497364, 0.94551845, 0.95254833, 0.78558875,\n",
       "        0.94376098, 0.93848858]),\n",
       " 'split3_test_score': array([0.91212654, 0.93321617, 0.93848858, 0.94200351, 0.94727592,\n",
       "        0.92794376, 0.92618629]),\n",
       " 'split4_test_score': array([0.90685413, 0.92618629, 0.93848858, 0.93321617, 0.92970123,\n",
       "        0.92091388, 0.9314587 ]),\n",
       " 'split5_test_score': array([0.91739895, 0.94551845, 0.95079086, 0.95782074, 0.94903339,\n",
       "        0.7943761 , 0.93321617]),\n",
       " 'split6_test_score': array([0.91197183, 0.93838028, 0.93661972, 0.92957746, 0.91373239,\n",
       "        0.93309859, 0.92429577]),\n",
       " 'split7_test_score': array([0.91197183, 0.93838028, 0.9471831 , 0.95422535, 0.9471831 ,\n",
       "        0.95774648, 0.94366197]),\n",
       " 'split8_test_score': array([0.92077465, 0.93309859, 0.94014085, 0.93838028, 0.94542254,\n",
       "        0.94366197, 0.9471831 ]),\n",
       " 'split9_test_score': array([0.90492958, 0.93485915, 0.9471831 , 0.9471831 , 0.86971831,\n",
       "        0.95070423, 0.94190141]),\n",
       " 'mean_test_score': array([0.91347094, 0.93668624, 0.94565398, 0.94758688, 0.91716627,\n",
       "        0.92650004, 0.93422795]),\n",
       " 'std_test_score': array([0.00604087, 0.00624239, 0.00827571, 0.0112993 , 0.04974195,\n",
       "        0.0455423 , 0.01539523]),\n",
       " 'rank_test_score': array([7, 3, 2, 1, 6, 5, 4]),\n",
       " 'split0_train_score': array([0.91401212, 0.93902677, 0.94762556, 0.94879812, 0.94254446,\n",
       "        0.94000391, 0.90267735]),\n",
       " 'split1_train_score': array([0.91264413, 0.93589994, 0.94625757, 0.95016611, 0.94000391,\n",
       "        0.95055697, 0.94234903]),\n",
       " 'split2_train_score': array([0.91420754, 0.93746336, 0.9493844 , 0.95524722, 0.78092632,\n",
       "        0.93824507, 0.93570451]),\n",
       " 'split3_train_score': array([0.91342584, 0.93941763, 0.94899355, 0.94899355, 0.9536838 ,\n",
       "        0.93980848, 0.93844049]),\n",
       " 'split4_train_score': array([0.91674809, 0.94176275, 0.94762556, 0.95231581, 0.95075239,\n",
       "        0.92339261, 0.94899355]),\n",
       " 'split5_train_score': array([0.91538011, 0.93570451, 0.94703928, 0.95212038, 0.94488958,\n",
       "        0.79773305, 0.94019934]),\n",
       " 'split6_train_score': array([0.91481047, 0.94157874, 0.94900352, 0.94431419, 0.91715514,\n",
       "        0.94548652, 0.93083236]),\n",
       " 'split7_train_score': array([0.91324736, 0.93610785, 0.94548652, 0.94685424, 0.94294646,\n",
       "        0.95173896, 0.94138335]),\n",
       " 'split8_train_score': array([0.91344275, 0.93903869, 0.94822196, 0.94646346, 0.95076202,\n",
       "        0.9441188 , 0.94177413]),\n",
       " 'split9_train_score': array([0.91383353, 0.93630324, 0.94529113, 0.94744041, 0.86068777,\n",
       "        0.95466979, 0.94685424]),\n",
       " 'mean_train_score': array([0.91417519, 0.93823035, 0.94749291, 0.94927135, 0.91843519,\n",
       "        0.92857542, 0.93692084]),\n",
       " 'std_train_score': array([0.00113678, 0.00216805, 0.00138865, 0.00309598, 0.05284324,\n",
       "        0.04441297, 0.01241604])}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = grid.cv_results_\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.912127</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>0.910369</td>\n",
       "      <td>0.912127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.913426</td>\n",
       "      <td>0.916748</td>\n",
       "      <td>0.915380</td>\n",
       "      <td>0.914810</td>\n",
       "      <td>0.913247</td>\n",
       "      <td>0.913443</td>\n",
       "      <td>0.913834</td>\n",
       "      <td>0.914175</td>\n",
       "      <td>0.001137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139399</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>0.934974</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937463</td>\n",
       "      <td>0.939418</td>\n",
       "      <td>0.941763</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>0.941579</td>\n",
       "      <td>0.936108</td>\n",
       "      <td>0.939039</td>\n",
       "      <td>0.936303</td>\n",
       "      <td>0.938230</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863796</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.945518</td>\n",
       "      <td>0.966608</td>\n",
       "      <td>0.945518</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949384</td>\n",
       "      <td>0.948994</td>\n",
       "      <td>0.947626</td>\n",
       "      <td>0.947039</td>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.945487</td>\n",
       "      <td>0.948222</td>\n",
       "      <td>0.945291</td>\n",
       "      <td>0.947493</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.013701</td>\n",
       "      <td>0.139624</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>0.942004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955247</td>\n",
       "      <td>0.948994</td>\n",
       "      <td>0.952316</td>\n",
       "      <td>0.952120</td>\n",
       "      <td>0.944314</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>0.947440</td>\n",
       "      <td>0.949271</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.039298</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>0.785589</td>\n",
       "      <td>0.947276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780926</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.950752</td>\n",
       "      <td>0.944890</td>\n",
       "      <td>0.917155</td>\n",
       "      <td>0.942946</td>\n",
       "      <td>0.950762</td>\n",
       "      <td>0.860688</td>\n",
       "      <td>0.918435</td>\n",
       "      <td>0.052843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.157301</td>\n",
       "      <td>0.283097</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.934974</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.943761</td>\n",
       "      <td>0.927944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938245</td>\n",
       "      <td>0.939808</td>\n",
       "      <td>0.923393</td>\n",
       "      <td>0.797733</td>\n",
       "      <td>0.945487</td>\n",
       "      <td>0.951739</td>\n",
       "      <td>0.944119</td>\n",
       "      <td>0.954670</td>\n",
       "      <td>0.928575</td>\n",
       "      <td>0.044413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.213896</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.898067</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.938489</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>0.938440</td>\n",
       "      <td>0.948994</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.930832</td>\n",
       "      <td>0.941383</td>\n",
       "      <td>0.941774</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.936921</td>\n",
       "      <td>0.012416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.033999      0.004540         0.022800        0.003866   0.001   \n",
       "1       0.139399      0.039451         0.018704        0.030518    0.01   \n",
       "2       0.863796      0.159448         0.004503        0.002461     0.1   \n",
       "3       1.013701      0.139624         0.003800        0.002364     1.0   \n",
       "4       1.039298      0.156407         0.004201        0.003341    10.0   \n",
       "5       1.157301      0.283097         0.005000        0.002527   100.0   \n",
       "6       1.213896      0.191191         0.003401        0.001114  1000.0   \n",
       "\n",
       "          params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 0.001}           0.912127           0.926186           0.910369   \n",
       "1    {'C': 0.01}           0.933216           0.949033           0.934974   \n",
       "2     {'C': 0.1}           0.945518           0.966608           0.945518   \n",
       "3     {'C': 1.0}           0.952548           0.968366           0.952548   \n",
       "4    {'C': 10.0}           0.933216           0.950791           0.785589   \n",
       "5   {'C': 100.0}           0.934974           0.957821           0.943761   \n",
       "6  {'C': 1000.0}           0.898067           0.957821           0.938489   \n",
       "\n",
       "   split3_test_score  ...  split2_train_score  split3_train_score  \\\n",
       "0           0.912127  ...            0.914208            0.913426   \n",
       "1           0.933216  ...            0.937463            0.939418   \n",
       "2           0.938489  ...            0.949384            0.948994   \n",
       "3           0.942004  ...            0.955247            0.948994   \n",
       "4           0.947276  ...            0.780926            0.953684   \n",
       "5           0.927944  ...            0.938245            0.939808   \n",
       "6           0.926186  ...            0.935705            0.938440   \n",
       "\n",
       "   split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0            0.916748            0.915380            0.914810   \n",
       "1            0.941763            0.935705            0.941579   \n",
       "2            0.947626            0.947039            0.949004   \n",
       "3            0.952316            0.952120            0.944314   \n",
       "4            0.950752            0.944890            0.917155   \n",
       "5            0.923393            0.797733            0.945487   \n",
       "6            0.948994            0.940199            0.930832   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0            0.913247            0.913443            0.913834   \n",
       "1            0.936108            0.939039            0.936303   \n",
       "2            0.945487            0.948222            0.945291   \n",
       "3            0.946854            0.946463            0.947440   \n",
       "4            0.942946            0.950762            0.860688   \n",
       "5            0.951739            0.944119            0.954670   \n",
       "6            0.941383            0.941774            0.946854   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.914175         0.001137  \n",
       "1          0.938230         0.002168  \n",
       "2          0.947493         0.001389  \n",
       "3          0.949271         0.003096  \n",
       "4          0.918435         0.052843  \n",
       "5          0.928575         0.044413  \n",
       "6          0.936921         0.012416  \n",
       "\n",
       "[7 rows x 31 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.013701</td>\n",
       "      <td>0.139624</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.947587</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949271</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863796</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.945654</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947493</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139399</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.936686</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>3</td>\n",
       "      <td>0.938230</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.213896</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.934228</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>4</td>\n",
       "      <td>0.936921</td>\n",
       "      <td>0.012416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.157301</td>\n",
       "      <td>0.283097</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.928575</td>\n",
       "      <td>0.044413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.039298</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>6</td>\n",
       "      <td>0.918435</td>\n",
       "      <td>0.052843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.913471</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>7</td>\n",
       "      <td>0.914175</td>\n",
       "      <td>0.001137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3       1.013701      0.139624         0.003800        0.002364     1.0   \n",
       "2       0.863796      0.159448         0.004503        0.002461     0.1   \n",
       "1       0.139399      0.039451         0.018704        0.030518    0.01   \n",
       "6       1.213896      0.191191         0.003401        0.001114  1000.0   \n",
       "5       1.157301      0.283097         0.005000        0.002527   100.0   \n",
       "4       1.039298      0.156407         0.004201        0.003341    10.0   \n",
       "0       0.033999      0.004540         0.022800        0.003866   0.001   \n",
       "\n",
       "          params  mean_test_score  std_test_score  rank_test_score  \\\n",
       "3     {'C': 1.0}         0.947587        0.011299                1   \n",
       "2     {'C': 0.1}         0.945654        0.008276                2   \n",
       "1    {'C': 0.01}         0.936686        0.006242                3   \n",
       "6  {'C': 1000.0}         0.934228        0.015395                4   \n",
       "5   {'C': 100.0}         0.926500        0.045542                5   \n",
       "4    {'C': 10.0}         0.917166        0.049742                6   \n",
       "0   {'C': 0.001}         0.913471        0.006041                7   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "3          0.949271         0.003096  \n",
       "2          0.947493         0.001389  \n",
       "1          0.938230         0.002168  \n",
       "6          0.936921         0.012416  \n",
       "5          0.928575         0.044413  \n",
       "4          0.918435         0.052843  \n",
       "0          0.914175         0.001137  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [i for i in res.columns if 'split' not in i]\n",
    "res = res[cols]\n",
    "res = res.sort_values('rank_test_score')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.013701</td>\n",
       "      <td>0.139624</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.947587</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949271</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863796</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.945654</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947493</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139399</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.936686</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>3</td>\n",
       "      <td>0.938230</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.213896</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "      <td>0.934228</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>4</td>\n",
       "      <td>0.936921</td>\n",
       "      <td>0.012416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.157301</td>\n",
       "      <td>0.283097</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.928575</td>\n",
       "      <td>0.044413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.039298</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>6</td>\n",
       "      <td>0.918435</td>\n",
       "      <td>0.052843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.913471</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>7</td>\n",
       "      <td>0.914175</td>\n",
       "      <td>0.001137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3       1.013701      0.139624         0.003800        0.002364     1.0   \n",
       "2       0.863796      0.159448         0.004503        0.002461     0.1   \n",
       "1       0.139399      0.039451         0.018704        0.030518    0.01   \n",
       "6       1.213896      0.191191         0.003401        0.001114  1000.0   \n",
       "5       1.157301      0.283097         0.005000        0.002527   100.0   \n",
       "4       1.039298      0.156407         0.004201        0.003341    10.0   \n",
       "0       0.033999      0.004540         0.022800        0.003866   0.001   \n",
       "\n",
       "          params  mean_test_score  std_test_score  rank_test_score  \\\n",
       "3     {'C': 1.0}         0.947587        0.011299                1   \n",
       "2     {'C': 0.1}         0.945654        0.008276                2   \n",
       "1    {'C': 0.01}         0.936686        0.006242                3   \n",
       "6  {'C': 1000.0}         0.934228        0.015395                4   \n",
       "5   {'C': 100.0}         0.926500        0.045542                5   \n",
       "4    {'C': 10.0}         0.917166        0.049742                6   \n",
       "0   {'C': 0.001}         0.913471        0.006041                7   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "3          0.949271         0.003096  \n",
       "2          0.947493         0.001389  \n",
       "1          0.938230         0.002168  \n",
       "6          0.936921         0.012416  \n",
       "5          0.928575         0.044413  \n",
       "4          0.918435         0.052843  \n",
       "0          0.914175         0.001137  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ré-entraînement\n",
    "estimator = LogisticRegression(**best_params)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.9509, score test 0.95\n"
     ]
    }
   ],
   "source": [
    "score(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>1200</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>65</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "test_0    1200      57\n",
       "test_1      65    1116"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949807917322604"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller plus loin\n",
    "\n",
    "Salaud, c'est obligé que je le fasse, ce n'est donc pas encore terminé pour moi.\n",
    "\n",
    "<mark>Ce cours m'aura pris infiniment plus que 10h. Combien mon gars, tu es normalement équipé pour le savoir, just do it !</mark>\n",
    "\n",
    "* Le [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?highlight=labelencoder#sklearn.preprocessing.LabelEncoder) n’est pas conseillé dans ce genre de configuration. On lui préférera  par exemple un [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) ou un [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) . Quelles sont les limites de ce<mark>s</mark> types d’encode<mark>u</mark>rs, quand peut-on ou ne peut-on pas les utiliser? Quels autres encode<mark>u</mark>rs peut-on utiliser à la place ? Quels sont leurs limites ? \n",
    "\n",
    "* Nous avons travaillé sur les données brutes, mais il peut être intéressant de <mark>mettre les données à l'échelle</mark>, avec un [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) par exemple. Quel aurait été l’impact d’une telle transformation ? Quels sont les autres scalers les plus souvent utilisés ? \n",
    "\n",
    "* Nous n’avons pas non plus fait de réduction de dimension sur le jeu de données. Était-il utile ou pertinent de prendre toutes les dimensions à notre disposition ? Appliquer une méthode de réduction de dimensionnalité comme une PCA aurait-il été judicieux ? \n",
    "\n",
    "* Nous avons utilisé une Régression Logistique et une SVM Linéaire. D’autres estimateurs auraient-ils été performants ? Par exemple un [kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) Classifier ou un [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision+tree). Si oui, quels hyper-paramètres aurait-on pu tester ? \n",
    "\n",
    "* Nous avons vu l'impact de certains hyper-paramètres sur nos modèles, pouvez vous faire un graphique avec le mean_test_score en fonction de chaque hyper-paramètre ? \n",
    "\n",
    "* Nous avons travaillé sur le ROC-AUC et l’accuracy score. Quelles sont les autres métriques souvent utilisées en classification ? Qu’est-ce que le recall, la précision ou le f1-score par exemple ?\n",
    "\n",
    "**Ressources internes**\n",
    "* Cours OpenClassrooms : [Initiez vous au Machine Learning](https://openclassrooms.com/fr/courses/4011851-initiez-vous-au-machine-learning).\n",
    "\n",
    "**Ressources externes**\n",
    "* Une vidéo de la chaîne freecodecamp qui couvre de façon très structurée les basiques du Machine lLearning : [vidéo](https://www.youtube.com/watch?v=0B5eIE_1vpU) (en anglais).\n",
    "* La playlist de la chaine machine learnia : [série de vidéos](https://www.youtube.com/watch?v=82KLS2C_gNQ&list=PLO_fdPEVlfKqMDNmCFzQISI2H_nJcEDJq) (notamment vidéos 20 à 27).\n",
    "* la chaine statquest, notamment video sur la [régression logistique](https://www.youtube.com/watch?v=yIYKR4sgzI8) (en anglais) et sur les [SVM](https://www.youtube.com/watch?v=efR1C6CvhmE) (en anglais).\n",
    "\n",
    "**Question, suggestion, remarque ?**\n",
    "\n",
    "[Nous contacter](https://openclassrooms.zendesk.com/hc/fr/requests/new?_gl=1*1ugvg2l*_ga*MTc3OTMyNDgxOS4xNjYyNjM4Nzg0*_ga_8378XJR4H7*MTY2NDg5MDM4Mi41My4wLjE2NjQ4OTAzODIuNjAuMC4w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 TP feuilles d'arbres\n",
    "\n",
    "C'est un sujet proche de l'application data à laquelle j'ai pas mal contribué et sur laquelle j'aimerais revenir fort de mes nouvelles compétences : PlantNet.\n",
    "\n",
    "Le dataset : https://www.kaggle.com/c/leaf-classification/data\n",
    "\n",
    "Mission : déterminer quelle est l’espèce de l’arbre à laquelle appartient la feuille.\n",
    "\n",
    "Les caractéristiques extraites des images des feuilles sont essentiellement 3 vecteurs de dimension 64 (margin, shape & texture), dont la description du dataset détaillée se trouve ici : https://www.kaggle.com/c/leaf-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\franc\\\\Projects\\\\pepper_data-science_practising\\\\OC DS\\\\P4 C2 Entrainez un modèle prédictif linéaire'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.119140</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148440</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>Acer_Pictum</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>Alnus_Maximowiczii</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Quercus_Rubra</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>Quercus_Afares</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "id                                                                              \n",
       "1               Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "2     Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625  0.025391   \n",
       "3      Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812  0.003906   \n",
       "5           Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859  0.021484   \n",
       "6        Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766  0.013672   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "1575   Magnolia_Salicifolia  0.060547  0.119140  0.007812  0.003906  0.000000   \n",
       "1578            Acer_Pictum  0.001953  0.003906  0.021484  0.107420  0.001953   \n",
       "1581     Alnus_Maximowiczii  0.001953  0.003906  0.000000  0.021484  0.078125   \n",
       "1582          Quercus_Rubra  0.000000  0.000000  0.046875  0.056641  0.009766   \n",
       "1584         Quercus_Afares  0.023438  0.019531  0.031250  0.015625  0.005859   \n",
       "\n",
       "       margin6   margin7  margin8   margin9  ...  texture55  texture56  \\\n",
       "id                                           ...                         \n",
       "1     0.009766  0.027344      0.0  0.001953  ...   0.007812   0.000000   \n",
       "2     0.001953  0.019531      0.0  0.000000  ...   0.000977   0.000000   \n",
       "3     0.005859  0.068359      0.0  0.000000  ...   0.154300   0.000000   \n",
       "5     0.019531  0.023438      0.0  0.013672  ...   0.000000   0.000977   \n",
       "6     0.015625  0.005859      0.0  0.000000  ...   0.096680   0.000000   \n",
       "...        ...       ...      ...       ...  ...        ...        ...   \n",
       "1575  0.148440  0.017578      0.0  0.001953  ...   0.242190   0.000000   \n",
       "1578  0.000000  0.000000      0.0  0.029297  ...   0.170900   0.000000   \n",
       "1581  0.003906  0.007812      0.0  0.003906  ...   0.004883   0.000977   \n",
       "1582  0.000000  0.000000      0.0  0.037109  ...   0.083008   0.030273   \n",
       "1584  0.019531  0.035156      0.0  0.003906  ...   0.000000   0.000000   \n",
       "\n",
       "      texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "id                                                                       \n",
       "1      0.002930   0.002930   0.035156   0.000000   0.000000   0.004883   \n",
       "2      0.000000   0.000977   0.023438   0.000000   0.000000   0.000977   \n",
       "3      0.005859   0.000977   0.007812   0.000000   0.000000   0.000000   \n",
       "5      0.000000   0.000000   0.020508   0.000000   0.000000   0.017578   \n",
       "6      0.021484   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1575   0.034180   0.000000   0.010742   0.000000   0.000000   0.000000   \n",
       "1578   0.018555   0.000000   0.011719   0.000000   0.000000   0.000977   \n",
       "1581   0.004883   0.027344   0.016602   0.007812   0.000000   0.027344   \n",
       "1582   0.000977   0.002930   0.014648   0.000000   0.041992   0.000000   \n",
       "1584   0.002930   0.000000   0.012695   0.000000   0.000000   0.023438   \n",
       "\n",
       "      texture63  texture64  \n",
       "id                          \n",
       "1      0.000000   0.025391  \n",
       "2      0.039062   0.022461  \n",
       "3      0.020508   0.002930  \n",
       "5      0.000000   0.047852  \n",
       "6      0.000000   0.031250  \n",
       "...         ...        ...  \n",
       "1575   0.000000   0.018555  \n",
       "1578   0.000000   0.021484  \n",
       "1581   0.000000   0.001953  \n",
       "1582   0.001953   0.002930  \n",
       "1584   0.025391   0.022461  \n",
       "\n",
       "[990 rows x 193 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.006836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136720</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "id                                                                           \n",
       "4     0.019531  0.009766  0.078125  0.011719  0.003906  0.015625  0.005859   \n",
       "7     0.007812  0.005859  0.064453  0.009766  0.003906  0.013672  0.007812   \n",
       "9     0.000000  0.000000  0.001953  0.021484  0.041016  0.000000  0.023438   \n",
       "12    0.000000  0.000000  0.009766  0.011719  0.017578  0.000000  0.003906   \n",
       "13    0.001953  0.000000  0.015625  0.009766  0.039062  0.000000  0.009766   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1576  0.000000  0.000000  0.003906  0.015625  0.041016  0.000000  0.017578   \n",
       "1577  0.000000  0.003906  0.003906  0.005859  0.017578  0.000000  0.017578   \n",
       "1579  0.017578  0.029297  0.015625  0.013672  0.003906  0.015625  0.025391   \n",
       "1580  0.013672  0.009766  0.060547  0.025391  0.035156  0.025391  0.039062   \n",
       "1583  0.000000  0.117190  0.000000  0.019531  0.000000  0.136720  0.001953   \n",
       "\n",
       "       margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n",
       "id                                  ...                                    \n",
       "4     0.000000  0.005859  0.023438  ...   0.006836   0.000000   0.015625   \n",
       "7     0.000000  0.033203  0.023438  ...   0.000000   0.000000   0.006836   \n",
       "9     0.000000  0.011719  0.005859  ...   0.128910   0.000000   0.000977   \n",
       "12    0.000000  0.003906  0.001953  ...   0.012695   0.015625   0.002930   \n",
       "13    0.000000  0.005859  0.000000  ...   0.000000   0.042969   0.016602   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1576  0.000000  0.005859  0.013672  ...   0.098633   0.000000   0.004883   \n",
       "1577  0.005859  0.000000  0.005859  ...   0.012695   0.004883   0.004883   \n",
       "1579  0.000000  0.000000  0.009766  ...   0.073242   0.000000   0.028320   \n",
       "1580  0.000000  0.003906  0.023438  ...   0.003906   0.000000   0.000977   \n",
       "1583  0.005859  0.000000  0.007812  ...   0.107420   0.012695   0.016602   \n",
       "\n",
       "      texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "id                                                                       \n",
       "4      0.000977   0.015625        0.0        0.0   0.000000   0.003906   \n",
       "7      0.001953   0.013672        0.0        0.0   0.000977   0.037109   \n",
       "9      0.000000   0.000000        0.0        0.0   0.015625   0.000000   \n",
       "12     0.036133   0.013672        0.0        0.0   0.089844   0.000000   \n",
       "13     0.010742   0.041016        0.0        0.0   0.007812   0.009766   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1576   0.000000   0.003906        0.0        0.0   0.018555   0.000000   \n",
       "1577   0.002930   0.009766        0.0        0.0   0.090820   0.000000   \n",
       "1579   0.000000   0.001953        0.0        0.0   0.000000   0.042969   \n",
       "1580   0.000000   0.011719        0.0        0.0   0.000000   0.011719   \n",
       "1583   0.000977   0.004883        0.0        0.0   0.015625   0.000000   \n",
       "\n",
       "      texture64  \n",
       "id               \n",
       "4      0.053711  \n",
       "7      0.044922  \n",
       "9      0.000000  \n",
       "12     0.008789  \n",
       "13     0.007812  \n",
       "...         ...  \n",
       "1576   0.000977  \n",
       "1577   0.016602  \n",
       "1579   0.006836  \n",
       "1580   0.018555  \n",
       "1583   0.017578  \n",
       "\n",
       "[594 rows x 192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "source_dir = 'data/source'\n",
    "cleaned_dir = 'data/cleaned'\n",
    "train_filename = 'trees_train.csv'\n",
    "test_filename = 'trees_test.csv'\n",
    "train_filepath = os.path.join(source_dir, train_filename)\n",
    "test_filepath = os.path.join(source_dir, test_filename)\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv(train_filepath, index_col='id')\n",
    "test = pd.read_csv(test_filepath, index_col='id')\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 990 entries, 1 to 1584\n",
      "Columns: 193 entries, species to texture64\n",
      "dtypes: float64(192), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>990</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.028539</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.019420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.060151</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>0.039040</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.022768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.056153</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.029297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.205080</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.169920</td>\n",
       "      <td>0.111330</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429690</td>\n",
       "      <td>0.202150</td>\n",
       "      <td>0.172850</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0.578130</td>\n",
       "      <td>0.151370</td>\n",
       "      <td>0.375980</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.141600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            species     margin1     margin2     margin3     margin4  \\\n",
       "count           990  990.000000  990.000000  990.000000  990.000000   \n",
       "unique           99         NaN         NaN         NaN         NaN   \n",
       "top     Acer_Opalus         NaN         NaN         NaN         NaN   \n",
       "freq             10         NaN         NaN         NaN         NaN   \n",
       "mean            NaN    0.017412    0.028539    0.031988    0.023280   \n",
       "std             NaN    0.019739    0.038855    0.025847    0.028411   \n",
       "min             NaN    0.000000    0.000000    0.000000    0.000000   \n",
       "25%             NaN    0.001953    0.001953    0.013672    0.005859   \n",
       "50%             NaN    0.009766    0.011719    0.025391    0.013672   \n",
       "75%             NaN    0.025391    0.041016    0.044922    0.029297   \n",
       "max             NaN    0.087891    0.205080    0.156250    0.169920   \n",
       "\n",
       "           margin5     margin6     margin7     margin8     margin9  ...  \\\n",
       "count   990.000000  990.000000  990.000000  990.000000  990.000000  ...   \n",
       "unique         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "top            NaN         NaN         NaN         NaN         NaN  ...   \n",
       "freq           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "mean      0.014264    0.038579    0.019202    0.001083    0.007167  ...   \n",
       "std       0.018390    0.052030    0.017511    0.002743    0.008933  ...   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%       0.001953    0.000000    0.005859    0.000000    0.001953  ...   \n",
       "50%       0.007812    0.015625    0.015625    0.000000    0.005859  ...   \n",
       "75%       0.017578    0.056153    0.029297    0.000000    0.007812  ...   \n",
       "max       0.111330    0.310550    0.091797    0.031250    0.076172  ...   \n",
       "\n",
       "         texture55   texture56   texture57   texture58   texture59  \\\n",
       "count   990.000000  990.000000  990.000000  990.000000  990.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean      0.036501    0.005024    0.015944    0.011586    0.016108   \n",
       "std       0.063403    0.019321    0.023214    0.025040    0.015335   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       0.000000    0.000000    0.000977    0.000000    0.004883   \n",
       "50%       0.004883    0.000000    0.005859    0.000977    0.012695   \n",
       "75%       0.043701    0.000000    0.022217    0.009766    0.021484   \n",
       "max       0.429690    0.202150    0.172850    0.200200    0.106450   \n",
       "\n",
       "         texture60   texture61   texture62   texture63   texture64  \n",
       "count   990.000000  990.000000  990.000000  990.000000  990.000000  \n",
       "unique         NaN         NaN         NaN         NaN         NaN  \n",
       "top            NaN         NaN         NaN         NaN         NaN  \n",
       "freq           NaN         NaN         NaN         NaN         NaN  \n",
       "mean      0.014017    0.002688    0.020291    0.008989    0.019420  \n",
       "std       0.060151    0.011415    0.039040    0.013791    0.022768  \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%       0.000000    0.000000    0.000000    0.000000    0.000977  \n",
       "50%       0.000000    0.000000    0.003906    0.002930    0.011719  \n",
       "75%       0.000000    0.000000    0.023438    0.012695    0.029297  \n",
       "max       0.578130    0.151370    0.375980    0.086914    0.141600  \n",
       "\n",
       "[11 rows x 193 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 594 entries, 4 to 1583\n",
      "Columns: 192 entries, margin1 to texture64\n",
      "dtypes: float64(192)\n",
      "memory usage: 895.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.018798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035291</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.015881</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.038351</td>\n",
       "      <td>0.025719</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.051372</td>\n",
       "      <td>0.017122</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.016229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064482</td>\n",
       "      <td>0.026934</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>0.052530</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.023407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.013184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.189450</td>\n",
       "      <td>0.167970</td>\n",
       "      <td>0.164060</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.271480</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353520</td>\n",
       "      <td>0.441410</td>\n",
       "      <td>0.153320</td>\n",
       "      <td>0.177730</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.606450</td>\n",
       "      <td>0.123050</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.149410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          margin1     margin2     margin3     margin4     margin5     margin6  \\\n",
       "count  594.000000  594.000000  594.000000  594.000000  594.000000  594.000000   \n",
       "mean     0.017562    0.028425    0.031858    0.022556    0.014527    0.037497   \n",
       "std      0.019585    0.038351    0.025719    0.028797    0.018029    0.051372   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.001953    0.001953    0.013672    0.005859    0.001953    0.000000   \n",
       "50%      0.009766    0.010743    0.023438    0.013672    0.007812    0.013672   \n",
       "75%      0.028809    0.041016    0.042969    0.027344    0.019531    0.056641   \n",
       "max      0.085938    0.189450    0.167970    0.164060    0.093750    0.271480   \n",
       "\n",
       "          margin7     margin8     margin9    margin10  ...   texture55  \\\n",
       "count  594.000000  594.000000  594.000000  594.000000  ...  594.000000   \n",
       "mean     0.019222    0.001085    0.007092    0.018798  ...    0.035291   \n",
       "std      0.017122    0.002697    0.009515    0.016229  ...    0.064482   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.005859    0.000000    0.001953    0.005859  ...    0.000000   \n",
       "50%      0.015625    0.000000    0.005859    0.015625  ...    0.003906   \n",
       "75%      0.029297    0.000000    0.007812    0.027344  ...    0.038086   \n",
       "max      0.087891    0.021484    0.083984    0.083984  ...    0.353520   \n",
       "\n",
       "        texture56   texture57   texture58   texture59   texture60   texture61  \\\n",
       "count  594.000000  594.000000  594.000000  594.000000  594.000000  594.000000   \n",
       "mean     0.005923    0.015033    0.011762    0.015881    0.011217    0.002617   \n",
       "std      0.026934    0.022318    0.024771    0.014898    0.052530    0.011204   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000977    0.000000    0.004883    0.000000    0.000000   \n",
       "50%      0.000000    0.005859    0.001953    0.012695    0.000000    0.000000   \n",
       "75%      0.000000    0.019531    0.010498    0.022461    0.000000    0.000000   \n",
       "max      0.441410    0.153320    0.177730    0.083984    0.606450    0.123050   \n",
       "\n",
       "        texture62   texture63   texture64  \n",
       "count  594.000000  594.000000  594.000000  \n",
       "mean     0.019975    0.009389    0.020970  \n",
       "std      0.034704    0.013457    0.023407  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000977  \n",
       "50%      0.003418    0.002930    0.013184  \n",
       "75%      0.022461    0.014648    0.032227  \n",
       "max      0.247070    0.086914    0.149410  \n",
       "\n",
       "[8 rows x 192 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.info())\n",
    "display(train.describe(include='all'))\n",
    "display(test.info())\n",
    "display(test.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu</th>\n",
       "      <th>a_0</th>\n",
       "      <th>n_0</th>\n",
       "      <th>f_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>n_1</th>\n",
       "      <th>f_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>n_2</th>\n",
       "      <th>f_2</th>\n",
       "      <th>...</th>\n",
       "      <th>f_984</th>\n",
       "      <th>a_985</th>\n",
       "      <th>n_985</th>\n",
       "      <th>f_985</th>\n",
       "      <th>a_986</th>\n",
       "      <th>n_986</th>\n",
       "      <th>f_986</th>\n",
       "      <th>a_987</th>\n",
       "      <th>n_987</th>\n",
       "      <th>f_987</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <td>-49.000000</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>Crataegus_Monogyna</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>Acer_Mono</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin1</th>\n",
       "      <td>18.623153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.205051</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.061616</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin2</th>\n",
       "      <td>38.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin3</th>\n",
       "      <td>14.461538</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin4</th>\n",
       "      <td>24.488372</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.086869</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.084848</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture60</th>\n",
       "      <td>50.202490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.770707</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture61</th>\n",
       "      <td>25.882619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>0.894949</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture62</th>\n",
       "      <td>61.155172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.056566</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture63</th>\n",
       "      <td>30.591241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0.415152</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.049495</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture64</th>\n",
       "      <td>44.147059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 2965 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mu          a_0    n_0                   f_0  \\\n",
       "species   -49.000000  Acer_Opalus   10.0  0.010101010101010102   \n",
       "margin1    18.623153          0.0  203.0              0.205051   \n",
       "margin2    38.217391          0.0  207.0              0.209091   \n",
       "margin3    14.461538     0.015625   52.0              0.052525   \n",
       "margin4    24.488372     0.003906   86.0              0.086869   \n",
       "...              ...          ...    ...                   ...   \n",
       "texture60  50.202490          0.0  763.0              0.770707   \n",
       "texture61  25.882619          0.0  886.0              0.894949   \n",
       "texture62  61.155172          0.0  348.0              0.351515   \n",
       "texture63  30.591241          0.0  411.0              0.415152   \n",
       "texture64  44.147059          0.0  204.0              0.206061   \n",
       "\n",
       "                          a_1    n_1                   f_1        a_2   n_2  \\\n",
       "species    Crataegus_Monogyna   10.0  0.010101010101010102  Acer_Mono  10.0   \n",
       "margin1              0.001953  105.0              0.106061   0.003906  61.0   \n",
       "margin2              0.001953   87.0              0.087879   0.003906  63.0   \n",
       "margin3              0.013672   51.0              0.051515   0.017578  41.0   \n",
       "margin4              0.005859   84.0              0.084848   0.001953  70.0   \n",
       "...                       ...    ...                   ...        ...   ...   \n",
       "texture60            0.000977   26.0              0.026263   0.001953  17.0   \n",
       "texture61            0.000977   10.0              0.010101   0.001953   7.0   \n",
       "texture62            0.000977   56.0              0.056566   0.001953  44.0   \n",
       "texture63            0.003906   49.0              0.049495   0.000977  39.0   \n",
       "texture64            0.000977   48.0              0.048485   0.001953  41.0   \n",
       "\n",
       "                            f_2  ... f_984 a_985 n_985 f_985 a_986 n_986  \\\n",
       "species    0.010101010101010102  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "margin1                0.061616  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "margin2                0.063636  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "margin3                0.041414  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "margin4                0.070707  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...                         ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "texture60              0.017172  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "texture61              0.007071  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "texture62              0.044444  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "texture63              0.039394  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "texture64              0.041414  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "          f_986 a_987 n_987 f_987  \n",
       "species     NaN   NaN   NaN   NaN  \n",
       "margin1     NaN   NaN   NaN   NaN  \n",
       "margin2     NaN   NaN   NaN   NaN  \n",
       "margin3     NaN   NaN   NaN   NaN  \n",
       "margin4     NaN   NaN   NaN   NaN  \n",
       "...         ...   ...   ...   ...  \n",
       "texture60   NaN   NaN   NaN   NaN  \n",
       "texture61   NaN   NaN   NaN   NaN  \n",
       "texture62   NaN   NaN   NaN   NaN  \n",
       "texture63   NaN   NaN   NaN   NaN  \n",
       "texture64   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[193 rows x 2965 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(super_freqs(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species      0\n",
       "margin1      0\n",
       "margin2      0\n",
       "margin3      0\n",
       "margin4      0\n",
       "            ..\n",
       "texture60    0\n",
       "texture61    0\n",
       "texture62    0\n",
       "texture63    0\n",
       "texture64    0\n",
       "Length: 193, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "margin1      0\n",
       "margin2      0\n",
       "margin3      0\n",
       "margin4      0\n",
       "margin5      0\n",
       "            ..\n",
       "texture60    0\n",
       "texture61    0\n",
       "texture62    0\n",
       "texture63    0\n",
       "texture64    0\n",
       "Length: 192, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.isna().sum())\n",
    "display(train.duplicated().sum())\n",
    "display(test.isna().sum())\n",
    "display(test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de nettoyage particulier à effectuer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation X, y\n",
    "X = train.drop(columns='species')\n",
    "y = train.species\n",
    "\n",
    "# NB > test ne contient pas d'étiquettes qui permettraient de vérifier les prédictions\n",
    "\n",
    "# partition train / test (à distinguer du jeu de test final = simulation de production)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifieur naïf\n",
    "estimator = DummyClassifier(strategy='most_frequent')\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla'], dtype='<U19')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quercus_Rhysophylla    297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cytisus_Battandieri        0.020202\n",
       "Liquidambar_Styraciflua    0.020202\n",
       "Quercus_Ilex               0.020202\n",
       "Magnolia_Salicifolia       0.020202\n",
       "Salix_Fragilis             0.020202\n",
       "                             ...   \n",
       "Lithocarpus_Edulis         0.003367\n",
       "Quercus_Ellipsoidalis      0.003367\n",
       "Cornus_Macrophylla         0.003367\n",
       "Alnus_Rubra                0.003367\n",
       "Quercus_Infectoria_sub     0.003367\n",
       "Name: species, Length: 96, dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.0144, score test 0.0\n"
     ]
    }
   ],
   "source": [
    "tr_score = estimator.score(X_train, y_train).round(4)\n",
    "ts_score = estimator.score(X_test, y_test).round(4)\n",
    "print(f'score train : {tr_score}, score test {ts_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.0144, score test 0.0\n"
     ]
    }
   ],
   "source": [
    "def score(estimator):\n",
    "    \"\"\"compute and print train score and test score\"\"\"\n",
    "    tr_score = estimator.score(X_train, y_train).round(4)\n",
    "    ts_score = estimator.score(X_test, y_test).round(4)\n",
    "    print(f'score train : {tr_score}, score test {ts_score}')\n",
    "\n",
    "score(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quercus_x_Turneri          0.0144\n",
       "Quercus_Variabilis         0.0144\n",
       "Quercus_Rhysophylla        0.0144\n",
       "Acer_Circinatum            0.0130\n",
       "Salix_Intergra             0.0130\n",
       "                            ...  \n",
       "Cytisus_Battandieri        0.0058\n",
       "Salix_Fragilis             0.0058\n",
       "Quercus_Ilex               0.0058\n",
       "Magnolia_Salicifolia       0.0058\n",
       "Liquidambar_Styraciflua    0.0058\n",
       "Name: species, Length: 99, dtype: float64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cytisus_Battandieri        0.0202\n",
       "Liquidambar_Styraciflua    0.0202\n",
       "Quercus_Ilex               0.0202\n",
       "Magnolia_Salicifolia       0.0202\n",
       "Salix_Fragilis             0.0202\n",
       "                            ...  \n",
       "Lithocarpus_Edulis         0.0034\n",
       "Quercus_Ellipsoidalis      0.0034\n",
       "Cornus_Macrophylla         0.0034\n",
       "Alnus_Rubra                0.0034\n",
       "Quercus_Infectoria_sub     0.0034\n",
       "Name: species, Length: 96, dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_87</th>\n",
       "      <th>pred_88</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_90</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>pred_92</th>\n",
       "      <th>pred_93</th>\n",
       "      <th>pred_94</th>\n",
       "      <th>pred_95</th>\n",
       "      <th>pred_96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "test_0        0       0       0       0       0       0       0       0   \n",
       "test_1        0       0       0       0       0       0       0       0   \n",
       "test_2        0       0       0       0       0       0       0       0   \n",
       "test_3        0       0       0       0       0       0       0       0   \n",
       "test_4        0       0       0       0       0       0       0       0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "test_92       0       0       0       0       0       0       0       0   \n",
       "test_93       0       0       0       0       0       0       0       0   \n",
       "test_94       0       0       0       0       0       0       0       0   \n",
       "test_95       0       0       0       0       0       0       0       0   \n",
       "test_96       0       0       0       0       0       0       0       0   \n",
       "\n",
       "         pred_8  pred_9  ...  pred_87  pred_88  pred_89  pred_90  pred_91  \\\n",
       "test_0        0       0  ...        0        0        0        0        0   \n",
       "test_1        0       0  ...        0        0        0        0        0   \n",
       "test_2        0       0  ...        0        0        0        0        0   \n",
       "test_3        0       0  ...        0        0        0        0        0   \n",
       "test_4        0       0  ...        0        0        0        0        0   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "test_92       0       0  ...        0        0        0        0        0   \n",
       "test_93       0       0  ...        0        0        0        0        0   \n",
       "test_94       0       0  ...        0        0        0        0        0   \n",
       "test_95       0       0  ...        0        0        0        0        0   \n",
       "test_96       0       0  ...        0        0        0        0        0   \n",
       "\n",
       "         pred_92  pred_93  pred_94  pred_95  pred_96  \n",
       "test_0         0        0        0        0        0  \n",
       "test_1         0        0        0        0        0  \n",
       "test_2         0        0        0        0        0  \n",
       "test_3         0        0        0        0        0  \n",
       "test_4         0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "test_92        0        0        0        0        0  \n",
       "test_93        0        0        0        0        0  \n",
       "test_94        0        0        0        0        0  \n",
       "test_95        0        0        0        0        0  \n",
       "test_96        0        0        0        0        0  \n",
       "\n",
       "[97 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = pd.DataFrame(mat)\n",
    "mat.columns = [f'pred_{i}' for i in mat.columns]\n",
    "mat.index = [f'test_{i}' for i in mat.index]\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_87</th>\n",
       "      <th>pred_88</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_90</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>pred_92</th>\n",
       "      <th>pred_93</th>\n",
       "      <th>pred_94</th>\n",
       "      <th>pred_95</th>\n",
       "      <th>pred_96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "test_0        0       0       0       0       0       0       0       0   \n",
       "test_1        0       0       0       0       0       0       0       0   \n",
       "test_2        0       0       0       0       0       0       0       0   \n",
       "test_3        0       0       0       0       0       0       0       0   \n",
       "test_4        0       0       0       0       0       0       0       0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "test_92       0       0       0       0       0       0       0       0   \n",
       "test_93       0       0       0       0       0       0       0       0   \n",
       "test_94       0       0       0       0       0       0       0       0   \n",
       "test_95       0       0       0       0       0       0       0       0   \n",
       "test_96       0       0       0       0       0       0       0       0   \n",
       "\n",
       "         pred_8  pred_9  ...  pred_87  pred_88  pred_89  pred_90  pred_91  \\\n",
       "test_0        0       0  ...        0        0        0        0        0   \n",
       "test_1        0       0  ...        0        0        0        0        0   \n",
       "test_2        0       0  ...        0        0        0        0        0   \n",
       "test_3        0       0  ...        0        0        0        0        0   \n",
       "test_4        0       0  ...        0        0        0        0        0   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "test_92       0       0  ...        0        0        0        0        0   \n",
       "test_93       0       0  ...        0        0        0        0        0   \n",
       "test_94       0       0  ...        0        0        0        0        0   \n",
       "test_95       0       0  ...        0        0        0        0        0   \n",
       "test_96       0       0  ...        0        0        0        0        0   \n",
       "\n",
       "         pred_92  pred_93  pred_94  pred_95  pred_96  \n",
       "test_0         0        0        0        0        0  \n",
       "test_1         0        0        0        0        0  \n",
       "test_2         0        0        0        0        0  \n",
       "test_3         0        0        0        0        0  \n",
       "test_4         0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "test_92        0        0        0        0        0  \n",
       "test_93        0        0        0        0        0  \n",
       "test_94        0        0        0        0        0  \n",
       "test_95        0        0        0        0        0  \n",
       "test_96        0        0        0        0        0  \n",
       "\n",
       "[97 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion(y_test, y_pred):\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    mat = pd.DataFrame(mat)\n",
    "    mat.columns = [f'pred_{i}' for i in mat.columns]\n",
    "    mat.index = [f'test_{i}' for i in mat.index]\n",
    "    return mat\n",
    "\n",
    "display(confusion(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Projects\\pepper_data-science_practising\\OC DS\\P4 C2 Entrainez un modèle prédictif linéaire\\4444646_ml_linear_model_training.ipynb Cellule 144\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y300sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m false_positive_rate, true_positive_rate, thresholds \u001b[39m=\u001b[39m roc_curve(y_test, y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y300sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(false_positive_rate)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y300sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(true_positive_rate)\n",
      "File \u001b[1;32mc:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:981\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    893\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    894\u001b[0m ):\n\u001b[0;32m    895\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \n\u001b[0;32m    897\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m \n\u001b[0;32m    980\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    982\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    983\u001b[0m     )\n\u001b[0;32m    985\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m    993\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:740\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    738\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m--> 740\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    742\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    743\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "print(false_positive_rate)\n",
    "print(true_positive_rate)\n",
    "print(thresholds)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='red', label=f'AUC={roc_auc:0.2f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver='liblinear')\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Quercus_x_Turneri', 'Olea_Europaea', 'Acer_Pictum',\n",
       "       'Acer_Palmatum', 'Arundinaria_Simonii', 'Quercus_Suber',\n",
       "       'Acer_Rubrum', 'Quercus_x_Turneri', 'Quercus_Variabilis',\n",
       "       'Quercus_Crassipes', 'Quercus_Variabilis', 'Quercus_Suber',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Pontica', 'Quercus_Suber',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Rhysophylla', 'Acer_Palmatum',\n",
       "       'Quercus_Suber', 'Quercus_Rhysophylla', 'Quercus_Chrysolepis',\n",
       "       'Acer_Rubrum', 'Quercus_Rhysophylla', 'Lithocarpus_Edulis',\n",
       "       'Quercus_Pontica', 'Acer_Palmatum', 'Quercus_Chrysolepis',\n",
       "       'Quercus_Infectoria_sub', 'Acer_Palmatum', 'Alnus_Rubra',\n",
       "       'Quercus_Coccifera', 'Quercus_x_Turneri', 'Quercus_Suber',\n",
       "       'Quercus_x_Turneri', 'Quercus_Chrysolepis', 'Quercus_Variabilis',\n",
       "       'Acer_Rubrum', 'Quercus_Variabilis', 'Callicarpa_Bodinieri',\n",
       "       'Lithocarpus_Edulis', 'Alnus_Rubra', 'Quercus_Rhysophylla',\n",
       "       'Lithocarpus_Edulis', 'Alnus_Rubra', 'Tilia_Tomentosa',\n",
       "       'Quercus_x_Turneri', 'Quercus_Dolicholepis', 'Olea_Europaea',\n",
       "       'Sorbus_Aria', 'Cornus_Macrophylla', 'Quercus_Suber',\n",
       "       'Quercus_Ellipsoidalis', 'Arundinaria_Simonii',\n",
       "       'Quercus_x_Turneri', 'Quercus_Rhysophylla', 'Alnus_Rubra',\n",
       "       'Eucalyptus_Urnigera', 'Lithocarpus_Edulis',\n",
       "       'Quercus_Ellipsoidalis', 'Acer_Rubrum', 'Lithocarpus_Edulis',\n",
       "       'Quercus_Infectoria_sub', 'Quercus_Infectoria_sub',\n",
       "       'Ginkgo_Biloba', 'Quercus_Variabilis', 'Quercus_Crassifolia',\n",
       "       'Quercus_Rhysophylla', 'Lithocarpus_Edulis', 'Quercus_x_Turneri',\n",
       "       'Betula_Austrosinensis', 'Acer_Rubrum', 'Ginkgo_Biloba',\n",
       "       'Quercus_x_Turneri', 'Tilia_Tomentosa', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_x_Turneri', 'Alnus_Rubra', 'Quercus_Rhysophylla',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Rhysophylla', 'Lithocarpus_Edulis',\n",
       "       'Alnus_Rubra', 'Acer_Rubrum', 'Quercus_Suber', 'Alnus_Rubra',\n",
       "       'Quercus_Variabilis', 'Quercus_Variabilis', 'Quercus_Variabilis',\n",
       "       'Alnus_Rubra', 'Acer_Palmatum', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Variabilis', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Ellipsoidalis', 'Rhododendron_x_Russellianum',\n",
       "       'Ginkgo_Biloba', 'Quercus_Rhysophylla', 'Alnus_Rubra',\n",
       "       'Acer_Palmatum', 'Acer_Rubrum', 'Acer_Palmatum', 'Acer_Palmatum',\n",
       "       'Callicarpa_Bodinieri', 'Cornus_Macrophylla',\n",
       "       'Betula_Austrosinensis', 'Quercus_Chrysolepis', 'Salix_Intergra',\n",
       "       'Quercus_Pubescens', 'Quercus_x_Turneri', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Rhysophylla', 'Quercus_x_Turneri', 'Acer_Palmatum',\n",
       "       'Ginkgo_Biloba', 'Acer_Palmatum', 'Alnus_Rubra', 'Quercus_Suber',\n",
       "       'Quercus_Ellipsoidalis', 'Tilia_Tomentosa', 'Quercus_Rhysophylla',\n",
       "       'Quercus_x_Turneri', 'Tilia_Tomentosa', 'Acer_Palmatum',\n",
       "       'Acer_Palmatum', 'Lithocarpus_Edulis', 'Quercus_Rhysophylla',\n",
       "       'Sorbus_Aria', 'Quercus_Variabilis', 'Quercus_Rhysophylla',\n",
       "       'Acer_Rubrum', 'Quercus_Ellipsoidalis', 'Acer_Palmatum',\n",
       "       'Acer_Rubrum', 'Alnus_Viridis', 'Magnolia_Heptapeta',\n",
       "       'Quercus_Coccinea', 'Quercus_Variabilis', 'Quercus_Chrysolepis',\n",
       "       'Quercus_Ellipsoidalis', 'Quercus_Ellipsoidalis',\n",
       "       'Betula_Austrosinensis', 'Alnus_Rubra', 'Quercus_Dolicholepis',\n",
       "       'Acer_Capillipes', 'Alnus_Rubra', 'Eucalyptus_Neglecta',\n",
       "       'Eucalyptus_Urnigera', 'Quercus_Chrysolepis',\n",
       "       'Quercus_Chrysolepis', 'Quercus_Variabilis', 'Alnus_Rubra',\n",
       "       'Quercus_Chrysolepis', 'Quercus_Rhysophylla', 'Cornus_Macrophylla',\n",
       "       'Quercus_Variabilis', 'Arundinaria_Simonii', 'Quercus_Rhysophylla',\n",
       "       'Quercus_x_Turneri', 'Rhododendron_x_Russellianum',\n",
       "       'Tilia_Tomentosa', 'Quercus_Pubescens', 'Quercus_Suber',\n",
       "       'Betula_Austrosinensis', 'Quercus_Crassipes',\n",
       "       'Quercus_Chrysolepis', 'Acer_Rubrum',\n",
       "       'Rhododendron_x_Russellianum', 'Quercus_x_Turneri',\n",
       "       'Quercus_Ellipsoidalis', 'Lithocarpus_Edulis', 'Alnus_Rubra',\n",
       "       'Quercus_x_Turneri', 'Quercus_x_Turneri', 'Eucalyptus_Urnigera',\n",
       "       'Quercus_Ellipsoidalis', 'Acer_Palmatum', 'Quercus_Variabilis',\n",
       "       'Quercus_Palustris', 'Quercus_Variabilis', 'Quercus_Variabilis',\n",
       "       'Acer_Palmatum', 'Quercus_Variabilis', 'Quercus_Variabilis',\n",
       "       'Acer_Rubrum', 'Tilia_Tomentosa', 'Lithocarpus_Edulis',\n",
       "       'Cornus_Macrophylla', 'Quercus_Greggii', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Ellipsoidalis', 'Ilex_Aquifolium', 'Alnus_Rubra',\n",
       "       'Sorbus_Aria', 'Quercus_Rhysophylla', 'Lithocarpus_Edulis',\n",
       "       'Fagus_Sylvatica', 'Quercus_Rhysophylla', 'Acer_Palmatum',\n",
       "       'Acer_Rubrum', 'Acer_Circinatum', 'Quercus_Kewensis',\n",
       "       'Cornus_Macrophylla', 'Ginkgo_Biloba', 'Eucalyptus_Urnigera',\n",
       "       'Quercus_x_Turneri', 'Acer_Rubrum', 'Acer_Palmatum',\n",
       "       'Quercus_Ellipsoidalis', 'Alnus_Rubra', 'Lithocarpus_Edulis',\n",
       "       'Quercus_Infectoria_sub', 'Eucalyptus_Urnigera',\n",
       "       'Rhododendron_x_Russellianum', 'Quercus_Dolicholepis',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Variabilis', 'Lithocarpus_Edulis',\n",
       "       'Tilia_Tomentosa', 'Acer_Palmatum', 'Acer_Rubrum',\n",
       "       'Tilia_Tomentosa', 'Tilia_Tomentosa', 'Tilia_Oliveri',\n",
       "       'Quercus_Chrysolepis', 'Quercus_x_Turneri', 'Acer_Palmatum',\n",
       "       'Lithocarpus_Edulis', 'Quercus_x_Turneri', 'Quercus_Chrysolepis',\n",
       "       'Ginkgo_Biloba', 'Lithocarpus_Edulis', 'Quercus_Variabilis',\n",
       "       'Olea_Europaea', 'Quercus_Chrysolepis', 'Tilia_Tomentosa',\n",
       "       'Acer_Capillipes', 'Quercus_Infectoria_sub', 'Alnus_Rubra',\n",
       "       'Acer_Capillipes', 'Lithocarpus_Edulis', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Chrysolepis', 'Acer_Palmatum', 'Olea_Europaea',\n",
       "       'Acer_Rubrum', 'Quercus_Variabilis', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Dolicholepis', 'Alnus_Rubra', 'Quercus_Variabilis',\n",
       "       'Quercus_Rhysophylla', 'Lithocarpus_Edulis', 'Acer_Palmatum',\n",
       "       'Acer_Circinatum', 'Quercus_x_Turneri', 'Quercus_Rhysophylla',\n",
       "       'Acer_Palmatum', 'Olea_Europaea', 'Acer_Rubrum',\n",
       "       'Quercus_Infectoria_sub', 'Quercus_Suber', 'Acer_Capillipes',\n",
       "       'Alnus_Rubra', 'Lithocarpus_Edulis', 'Lithocarpus_Edulis',\n",
       "       'Tilia_Oliveri', 'Lithocarpus_Edulis', 'Quercus_Chrysolepis',\n",
       "       'Tilia_Tomentosa', 'Cornus_Macrophylla', 'Callicarpa_Bodinieri',\n",
       "       'Quercus_Infectoria_sub', 'Olea_Europaea', 'Cornus_Macrophylla',\n",
       "       'Quercus_x_Turneri', 'Betula_Austrosinensis', 'Acer_Palmatum',\n",
       "       'Quercus_Variabilis', 'Acer_Capillipes', 'Alnus_Rubra',\n",
       "       'Quercus_Suber', 'Quercus_Chrysolepis', 'Cornus_Macrophylla',\n",
       "       'Tilia_Tomentosa', 'Acer_Rubrum', 'Quercus_Dolicholepis',\n",
       "       'Acer_Palmatum', 'Acer_Palmatum', 'Lithocarpus_Edulis',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Rhysophylla', 'Acer_Circinatum', 'Quercus_Coccifera',\n",
       "       'Acer_Rubrum', 'Quercus_Suber', 'Quercus_Rhysophylla'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       ...,\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = estimator.predict_proba(X_test).round(2)\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 0.3709, score test 0.165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_90</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>pred_92</th>\n",
       "      <th>pred_93</th>\n",
       "      <th>pred_94</th>\n",
       "      <th>pred_95</th>\n",
       "      <th>pred_96</th>\n",
       "      <th>pred_97</th>\n",
       "      <th>pred_98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "test_0        2       0       0       0       0       0       0       0   \n",
       "test_1        0       1       0       0       0       0       0       0   \n",
       "test_2        0       0       0       0       1       0       0       0   \n",
       "test_3        0       0       0       0       0       0       0       0   \n",
       "test_4        0       0       0       0       1       0       0       0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "test_94       0       0       0       0       0       0       0       0   \n",
       "test_95       0       0       0       0       0       0       0       0   \n",
       "test_96       0       0       0       0       0       0       0       0   \n",
       "test_97       0       0       0       0       0       0       0       0   \n",
       "test_98       0       0       0       0       0       0       0       0   \n",
       "\n",
       "         pred_8  pred_9  ...  pred_89  pred_90  pred_91  pred_92  pred_93  \\\n",
       "test_0        0       0  ...        0        0        0        0        0   \n",
       "test_1        0       0  ...        0        0        0        0        0   \n",
       "test_2        0       0  ...        0        0        0        0        0   \n",
       "test_3        0       0  ...        0        0        0        0        0   \n",
       "test_4        0       0  ...        0        0        0        0        0   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "test_94       0       0  ...        0        0        0        0        0   \n",
       "test_95       0       0  ...        0        0        0        0        0   \n",
       "test_96       0       0  ...        0        0        0        0        0   \n",
       "test_97       0       0  ...        0        0        0        0        0   \n",
       "test_98       0       0  ...        0        0        0        0        0   \n",
       "\n",
       "         pred_94  pred_95  pred_96  pred_97  pred_98  \n",
       "test_0         0        0        0        0        0  \n",
       "test_1         0        0        0        0        0  \n",
       "test_2         0        0        0        0        0  \n",
       "test_3         0        0        0        0        0  \n",
       "test_4         0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "test_94        1        0        0        0        0  \n",
       "test_95        0        0        0        0        0  \n",
       "test_96        0        0        0        0        0  \n",
       "test_97        0        0        0        0        0  \n",
       "test_98        3        0        0        0        0  \n",
       "\n",
       "[99 rows x 99 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(estimator)\n",
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Projects\\pepper_data-science_practising\\OC DS\\P4 C2 Entrainez un modèle prédictif linéaire\\4444646_ml_linear_model_training.ipynb Cellule 151\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m estimator \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mlogspace(\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m11\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpenalty\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39melasticnet\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m }\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     estimator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Projects/pepper_data-science_practising/OC%20DS/P4%20C2%20Entrainez%20un%20mod%C3%A8le%20pr%C3%A9dictif%20lin%C3%A9aire/4444646_ml_linear_model_training.ipynb#Y303sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'C': np.logspace(-5, 5, 11),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator,\n",
    "    params,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10000.0, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000.0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000.0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10000.0, solver='liblinear')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ré-entraînement\n",
    "estimator = LogisticRegression(**best_params)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Acer_Pictum', 'Quercus_Phillyraeoides', 'Acer_Pictum',\n",
       "       'Acer_Saccharinum', 'Ilex_Aquifolium', 'Populus_Nigra',\n",
       "       'Betula_Pendula', 'Quercus_Pyrenaica', 'Celtis_Koraiensis',\n",
       "       'Quercus_Crassipes', 'Quercus_Rubra', 'Quercus_Suber',\n",
       "       'Liriodendron_Tulipifera', 'Celtis_Koraiensis',\n",
       "       'Quercus_Alnifolia', 'Magnolia_Heptapeta', 'Ulmus_Bergmanniana',\n",
       "       'Ilex_Aquifolium', 'Populus_Nigra', 'Alnus_Maximowiczii',\n",
       "       'Betula_Pendula', 'Quercus_Pubescens', 'Quercus_Crassifolia',\n",
       "       'Magnolia_Heptapeta', 'Quercus_Pontica', 'Quercus_Phellos',\n",
       "       'Alnus_Sieboldiana', 'Alnus_Cordata', 'Magnolia_Salicifolia',\n",
       "       'Alnus_Rubra', 'Quercus_Coccifera', 'Quercus_Pyrenaica',\n",
       "       'Quercus_Alnifolia', 'Acer_Pictum', 'Populus_Adenopoda',\n",
       "       'Quercus_Phellos', 'Crataegus_Monogyna', 'Quercus_Castaneifolia',\n",
       "       'Salix_Fragilis', 'Lithocarpus_Edulis', 'Prunus_X_Shmittii',\n",
       "       'Quercus_Ilex', 'Liriodendron_Tulipifera', 'Prunus_X_Shmittii',\n",
       "       'Zelkova_Serrata', 'Quercus_Imbricaria', 'Salix_Fragilis',\n",
       "       'Quercus_Trojana', 'Sorbus_Aria', 'Viburnum_Tinus',\n",
       "       'Quercus_Suber', 'Quercus_Shumardii', 'Arundinaria_Simonii',\n",
       "       'Ilex_Cornuta', 'Cornus_Chinensis', 'Quercus_Brantii',\n",
       "       'Eucalyptus_Urnigera', 'Lithocarpus_Cleistocarpus',\n",
       "       'Quercus_Rubra', 'Pterocarya_Stenoptera', 'Quercus_Nigra',\n",
       "       'Populus_Grandidentata', 'Cercis_Siliquastrum', 'Ginkgo_Biloba',\n",
       "       'Quercus_Hartwissiana', 'Quercus_Crassifolia',\n",
       "       'Cytisus_Battandieri', 'Cotinus_Coggygria', 'Zelkova_Serrata',\n",
       "       'Celtis_Koraiensis', 'Quercus_Trojana', 'Ginkgo_Biloba',\n",
       "       'Castanea_Sativa', 'Populus_Grandidentata', 'Quercus_Coccinea',\n",
       "       'Quercus_Imbricaria', 'Morus_Nigra', 'Quercus_Ilex',\n",
       "       'Magnolia_Salicifolia', 'Viburnum_x_Rhytidophylloides',\n",
       "       'Quercus_Semecarpifolia', 'Quercus_Vulcanica', 'Tilia_Oliveri',\n",
       "       'Quercus_Afares', 'Quercus_Vulcanica', 'Quercus_Canariensis',\n",
       "       'Populus_Grandidentata', 'Quercus_Canariensis',\n",
       "       'Tilia_Platyphyllos', 'Acer_Saccharinum', 'Castanea_Sativa',\n",
       "       'Populus_Grandidentata', 'Ulmus_Bergmanniana', 'Quercus_Palustris',\n",
       "       'Rhododendron_x_Russellianum', 'Quercus_Greggii',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Crataegus_Monogyna',\n",
       "       'Quercus_Hartwissiana', 'Quercus_Phillyraeoides',\n",
       "       'Acer_Saccharinum', 'Cotinus_Coggygria', 'Callicarpa_Bodinieri',\n",
       "       'Viburnum_Tinus', 'Alnus_Maximowiczii', 'Betula_Pendula',\n",
       "       'Salix_Intergra', 'Quercus_Pubescens', 'Populus_Nigra',\n",
       "       'Quercus_Ilex', 'Quercus_Imbricaria', 'Cercis_Siliquastrum',\n",
       "       'Ilex_Aquifolium', 'Ginkgo_Biloba', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Vulcanica', 'Liriodendron_Tulipifera', 'Quercus_Rubra',\n",
       "       'Alnus_Cordata', 'Quercus_Ilex', 'Acer_Mono', 'Acer_Platanoids',\n",
       "       'Quercus_Phellos', 'Liquidambar_Styraciflua', 'Cornus_Controversa',\n",
       "       'Quercus_Crassifolia', 'Sorbus_Aria', 'Populus_Nigra',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Quercus_Phillyraeoides',\n",
       "       'Crataegus_Monogyna', 'Quercus_Pontica', 'Crataegus_Monogyna',\n",
       "       'Alnus_Viridis', 'Magnolia_Salicifolia', 'Quercus_Coccinea',\n",
       "       'Quercus_Castaneifolia', 'Cytisus_Battandieri',\n",
       "       'Quercus_Shumardii', 'Quercus_Texana', 'Betula_Austrosinensis',\n",
       "       'Alnus_Rubra', 'Quercus_Dolicholepis', 'Acer_Capillipes',\n",
       "       'Morus_Nigra', 'Eucalyptus_Neglecta', 'Ilex_Cornuta',\n",
       "       'Populus_Adenopoda', 'Populus_Adenopoda', 'Quercus_Agrifolia',\n",
       "       'Prunus_X_Shmittii', 'Populus_Adenopoda', 'Alnus_Viridis',\n",
       "       'Cornus_Macrophylla', 'Quercus_Agrifolia', 'Arundinaria_Simonii',\n",
       "       'Tilia_Platyphyllos', 'Eucalyptus_Glaucescens', 'Quercus_Ilex',\n",
       "       'Liriodendron_Tulipifera', 'Quercus_Pubescens',\n",
       "       'Quercus_Alnifolia', 'Alnus_Maximowiczii', 'Quercus_Crassipes',\n",
       "       'Cytisus_Battandieri', 'Alnus_Cordata', 'Quercus_Coccifera',\n",
       "       'Quercus_Agrifolia', 'Quercus_Palustris', 'Eucalyptus_Glaucescens',\n",
       "       'Tilia_Platyphyllos', 'Quercus_Imbricaria', 'Quercus_Cerris',\n",
       "       'Liriodendron_Tulipifera', 'Quercus_Texana',\n",
       "       'Liquidambar_Styraciflua', 'Quercus_Hartwissiana',\n",
       "       'Quercus_Palustris', 'Prunus_Avium', 'Quercus_Canariensis',\n",
       "       'Fagus_Sylvatica', 'Celtis_Koraiensis', 'Zelkova_Serrata',\n",
       "       'Pterocarya_Stenoptera', 'Morus_Nigra', 'Eucalyptus_Glaucescens',\n",
       "       'Phildelphus', 'Quercus_Greggii', 'Quercus_Ilex', 'Quercus_Texana',\n",
       "       'Ilex_Aquifolium', 'Quercus_Brantii', 'Sorbus_Aria',\n",
       "       'Alnus_Sieboldiana', 'Lithocarpus_Cleistocarpus', 'Acer_Mono',\n",
       "       'Quercus_Ilex', 'Liquidambar_Styraciflua', 'Betula_Pendula',\n",
       "       'Acer_Rufinerve', 'Quercus_Kewensis', 'Acer_Saccharinum',\n",
       "       'Acer_Opalus', 'Eucalyptus_Urnigera', 'Quercus_Cerris',\n",
       "       'Quercus_x_Hispanica', 'Ilex_Aquifolium', 'Quercus_Texana',\n",
       "       'Morus_Nigra', 'Ilex_Cornuta', 'Pterocarya_Stenoptera',\n",
       "       'Cercis_Siliquastrum', 'Rhododendron_x_Russellianum',\n",
       "       'Cytisus_Battandieri', 'Eucalyptus_Neglecta', 'Acer_Platanoids',\n",
       "       'Viburnum_Tinus', 'Prunus_Avium', 'Acer_Palmatum',\n",
       "       'Quercus_x_Hispanica', 'Tilia_Tomentosa', 'Populus_Nigra',\n",
       "       'Alnus_Cordata', 'Quercus_Chrysolepis', 'Quercus_Afares',\n",
       "       'Acer_Rufinerve', 'Quercus_Nigra', 'Prunus_Avium',\n",
       "       'Alnus_Sieboldiana', 'Quercus_Greggii', 'Eucalyptus_Neglecta',\n",
       "       'Quercus_Agrifolia', 'Olea_Europaea', 'Betula_Pendula',\n",
       "       'Alnus_Cordata', 'Quercus_Hartwissiana', 'Quercus_Canariensis',\n",
       "       'Prunus_X_Shmittii', 'Acer_Saccharinum', 'Cotinus_Coggygria',\n",
       "       'Quercus_Shumardii', 'Populus_Adenopoda', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Trojana', 'Quercus_Coccifera', 'Acer_Platanoids',\n",
       "       'Quercus_Palustris', 'Quercus_Dolicholepis', 'Quercus_Brantii',\n",
       "       'Quercus_Semecarpifolia', 'Quercus_Ilex',\n",
       "       'Lithocarpus_Cleistocarpus', 'Acer_Mono', 'Acer_Circinatum',\n",
       "       'Quercus_Pyrenaica', 'Ulmus_Bergmanniana',\n",
       "       'Liquidambar_Styraciflua', 'Quercus_x_Hispanica', 'Acer_Rubrum',\n",
       "       'Quercus_Infectoria_sub', 'Quercus_Alnifolia', 'Acer_Capillipes',\n",
       "       'Quercus_Vulcanica', 'Magnolia_Heptapeta',\n",
       "       'Lithocarpus_Cleistocarpus', 'Tilia_Oliveri', 'Cornus_Controversa',\n",
       "       'Salix_Fragilis', 'Zelkova_Serrata', 'Phildelphus',\n",
       "       'Callicarpa_Bodinieri', 'Populus_Nigra', 'Quercus_Afares',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Cercis_Siliquastrum',\n",
       "       'Alnus_Viridis', 'Liquidambar_Styraciflua', 'Quercus_Phellos',\n",
       "       'Quercus_Pyrenaica', 'Acer_Opalus', 'Viburnum_Tinus',\n",
       "       'Cytisus_Battandieri', 'Phildelphus', 'Zelkova_Serrata',\n",
       "       'Pterocarya_Stenoptera', 'Cytisus_Battandieri',\n",
       "       'Liquidambar_Styraciflua', 'Magnolia_Salicifolia',\n",
       "       'Liriodendron_Tulipifera', 'Acer_Platanoids', 'Quercus_Rubra',\n",
       "       'Phildelphus', 'Prunus_X_Shmittii', 'Salix_Fragilis',\n",
       "       'Acer_Rubrum', 'Quercus_x_Hispanica', 'Ulmus_Bergmanniana'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 1.0, score test 0.936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_86</th>\n",
       "      <th>pred_87</th>\n",
       "      <th>pred_88</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_90</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>pred_92</th>\n",
       "      <th>pred_93</th>\n",
       "      <th>pred_94</th>\n",
       "      <th>pred_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "test_0        2       0       0       0       0       0       0       0   \n",
       "test_1        0       1       0       0       0       0       0       0   \n",
       "test_2        0       0       3       0       0       0       0       0   \n",
       "test_3        0       0       0       2       0       0       0       0   \n",
       "test_4        0       0       0       0       1       0       0       0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "test_91       0       0       0       0       0       0       0       0   \n",
       "test_92       0       0       0       0       0       0       0       0   \n",
       "test_93       0       0       0       0       0       0       0       0   \n",
       "test_94       0       0       0       0       0       0       0       0   \n",
       "test_95       0       0       0       0       0       0       0       0   \n",
       "\n",
       "         pred_8  pred_9  ...  pred_86  pred_87  pred_88  pred_89  pred_90  \\\n",
       "test_0        0       0  ...        0        0        0        0        0   \n",
       "test_1        0       0  ...        0        0        0        0        0   \n",
       "test_2        0       0  ...        0        0        0        0        0   \n",
       "test_3        0       0  ...        0        0        0        0        0   \n",
       "test_4        0       0  ...        0        0        0        0        0   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "test_91       0       0  ...        0        0        0        0        0   \n",
       "test_92       0       0  ...        0        0        0        0        0   \n",
       "test_93       0       0  ...        0        0        0        0        0   \n",
       "test_94       0       0  ...        0        0        0        0        0   \n",
       "test_95       0       0  ...        0        0        0        0        0   \n",
       "\n",
       "         pred_91  pred_92  pred_93  pred_94  pred_95  \n",
       "test_0         0        0        0        0        0  \n",
       "test_1         0        0        0        0        0  \n",
       "test_2         0        0        0        0        0  \n",
       "test_3         0        0        0        0        0  \n",
       "test_4         0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "test_91        1        0        0        0        0  \n",
       "test_92        0        4        0        0        0  \n",
       "test_93        0        0        2        0        0  \n",
       "test_94        0        0        0        4        0  \n",
       "test_95        0        0        0        0        5  \n",
       "\n",
       "[96 rows x 96 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(estimator)\n",
    "confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([  10.        ,   10.47615753,   10.97498765,   11.49756995,\n",
       "         12.0450354 ,   12.61856883,   13.21941148,   13.84886371,\n",
       "         14.50828778,   15.19911083,   15.92282793,   16.68100537,\n",
       "         17.475284  ,   18.3073828 ,   19.17910262,   20.09233003,\n",
       "         21.04904145,   22.0513074 ,   23.101297  ,   24.20128265,\n",
       "         25.35364494,   26.56087783,   27.82559402,   29.15053063,\n",
       "         30....\n",
       "        284.80358684,  298.36472403,  312.57158497,  327.45491629,\n",
       "        343.04692863,  359.38136638,  376.49358068,  394.42060594,\n",
       "        413.20124001,  432.87612811,  453.48785081,  475.08101621,\n",
       "        497.70235643,  521.4008288 ,  546.22772177,  572.23676594,\n",
       "        599.48425032,  628.02914418,  657.93322466,  689.26121043,\n",
       "        722.08090184,  756.46332755,  792.48289835,  830.21756813,\n",
       "        869.74900262,  911.16275612,  954.54845666, 1000.        ])},\n",
       "             return_train_score=True, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([  10.        ,   10.47615753,   10.97498765,   11.49756995,\n",
       "         12.0450354 ,   12.61856883,   13.21941148,   13.84886371,\n",
       "         14.50828778,   15.19911083,   15.92282793,   16.68100537,\n",
       "         17.475284  ,   18.3073828 ,   19.17910262,   20.09233003,\n",
       "         21.04904145,   22.0513074 ,   23.101297  ,   24.20128265,\n",
       "         25.35364494,   26.56087783,   27.82559402,   29.15053063,\n",
       "         30....\n",
       "        284.80358684,  298.36472403,  312.57158497,  327.45491629,\n",
       "        343.04692863,  359.38136638,  376.49358068,  394.42060594,\n",
       "        413.20124001,  432.87612811,  453.48785081,  475.08101621,\n",
       "        497.70235643,  521.4008288 ,  546.22772177,  572.23676594,\n",
       "        599.48425032,  628.02914418,  657.93322466,  689.26121043,\n",
       "        722.08090184,  756.46332755,  792.48289835,  830.21756813,\n",
       "        869.74900262,  911.16275612,  954.54845666, 1000.        ])},\n",
       "             return_train_score=True, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'C': array([  10.        ,   10.47615753,   10.97498765,   11.49756995,\n",
       "         12.0450354 ,   12.61856883,   13.21941148,   13.84886371,\n",
       "         14.50828778,   15.19911083,   15.92282793,   16.68100537,\n",
       "         17.475284  ,   18.3073828 ,   19.17910262,   20.09233003,\n",
       "         21.04904145,   22.0513074 ,   23.101297  ,   24.20128265,\n",
       "         25.35364494,   26.56087783,   27.82559402,   29.15053063,\n",
       "         30....\n",
       "        284.80358684,  298.36472403,  312.57158497,  327.45491629,\n",
       "        343.04692863,  359.38136638,  376.49358068,  394.42060594,\n",
       "        413.20124001,  432.87612811,  453.48785081,  475.08101621,\n",
       "        497.70235643,  521.4008288 ,  546.22772177,  572.23676594,\n",
       "        599.48425032,  628.02914418,  657.93322466,  689.26121043,\n",
       "        722.08090184,  756.46332755,  792.48289835,  830.21756813,\n",
       "        869.74900262,  911.16275612,  954.54845666, 1000.        ])},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LinearSVC()\n",
    "\n",
    "params = {'C': np.logspace(1, 3, 100)}\n",
    "grid = GridSearchCV(\n",
    "    estimator,\n",
    "    params,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 129.1549665014884}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.693291</td>\n",
       "      <td>0.338384</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>129.154967</td>\n",
       "      <td>{'C': 129.1549665014884}</td>\n",
       "      <td>0.945155</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.634200</td>\n",
       "      <td>0.148756</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>102.353102</td>\n",
       "      <td>{'C': 102.35310218990269}</td>\n",
       "      <td>0.943727</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.808500</td>\n",
       "      <td>0.496180</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.016188</td>\n",
       "      <td>155.567614</td>\n",
       "      <td>{'C': 155.56761439304722}</td>\n",
       "      <td>0.943706</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2.582699</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>148.496826</td>\n",
       "      <td>{'C': 148.4968262254465}</td>\n",
       "      <td>0.943706</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2.635898</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>187.381742</td>\n",
       "      <td>{'C': 187.3817422860385}</td>\n",
       "      <td>0.943706</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.604098</td>\n",
       "      <td>0.221585</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>12.045035</td>\n",
       "      <td>{'C': 12.045035402587823}</td>\n",
       "      <td>0.916294</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>96</td>\n",
       "      <td>0.998717</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.494899</td>\n",
       "      <td>0.156397</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>11.49757</td>\n",
       "      <td>{'C': 11.497569953977356}</td>\n",
       "      <td>0.914845</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>97</td>\n",
       "      <td>0.998396</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.557297</td>\n",
       "      <td>0.242319</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>10.974988</td>\n",
       "      <td>{'C': 10.974987654930562}</td>\n",
       "      <td>0.913395</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>98</td>\n",
       "      <td>0.998076</td>\n",
       "      <td>0.001397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.475398</td>\n",
       "      <td>0.214254</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>10.476158</td>\n",
       "      <td>{'C': 10.476157527896646}</td>\n",
       "      <td>0.911967</td>\n",
       "      <td>0.027843</td>\n",
       "      <td>99</td>\n",
       "      <td>0.998076</td>\n",
       "      <td>0.001397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.568096</td>\n",
       "      <td>0.349256</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.911967</td>\n",
       "      <td>0.027843</td>\n",
       "      <td>99</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time     param_C  \\\n",
       "55       2.693291      0.338384         0.006004        0.001003  129.154967   \n",
       "50       2.634200      0.148756         0.006200        0.002039  102.353102   \n",
       "59       2.808500      0.496180         0.011600        0.016188  155.567614   \n",
       "58       2.582699      0.204783         0.006400        0.001281  148.496826   \n",
       "63       2.635898      0.335134         0.006501        0.001360  187.381742   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "4        1.604098      0.221585         0.008801        0.009098   12.045035   \n",
       "3        1.494899      0.156397         0.007100        0.003506    11.49757   \n",
       "2        1.557297      0.242319         0.006101        0.000942   10.974988   \n",
       "1        1.475398      0.214254         0.005301        0.000459   10.476158   \n",
       "0        1.568096      0.349256         0.008100        0.004060        10.0   \n",
       "\n",
       "                       params  mean_test_score  std_test_score  \\\n",
       "55   {'C': 129.1549665014884}         0.945155        0.020275   \n",
       "50  {'C': 102.35310218990269}         0.943727        0.022830   \n",
       "59  {'C': 155.56761439304722}         0.943706        0.020954   \n",
       "58   {'C': 148.4968262254465}         0.943706        0.020954   \n",
       "63   {'C': 187.3817422860385}         0.943706        0.020954   \n",
       "..                        ...              ...             ...   \n",
       "4   {'C': 12.045035402587823}         0.916294        0.029581   \n",
       "3   {'C': 11.497569953977356}         0.914845        0.030747   \n",
       "2   {'C': 10.974987654930562}         0.913395        0.027558   \n",
       "1   {'C': 10.476157527896646}         0.911967        0.027843   \n",
       "0                 {'C': 10.0}         0.911967        0.027843   \n",
       "\n",
       "    rank_test_score  mean_train_score  std_train_score  \n",
       "55                1          1.000000         0.000000  \n",
       "50                2          1.000000         0.000000  \n",
       "59                3          1.000000         0.000000  \n",
       "58                3          1.000000         0.000000  \n",
       "63                3          1.000000         0.000000  \n",
       "..              ...               ...              ...  \n",
       "4                96          0.998717         0.001571  \n",
       "3                97          0.998396         0.001434  \n",
       "2                98          0.998076         0.001397  \n",
       "1                99          0.998076         0.001397  \n",
       "0                99          0.997595         0.001478  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train : 1.0, score test 0.9091\n"
     ]
    }
   ],
   "source": [
    "# ré-entraînement\n",
    "estimator = LogisticRegression(**best_params, max_iter=1000)\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "score(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A déplacer ailleurs\n",
    "\n",
    "Là, le désir me prend d'une fonction d'analyse à réutiliser.\n",
    "\n",
    "Etant donné un jeu de données composé des $p$ variables qualitatives et de $n$ observations.\n",
    "\n",
    "Désignons par la famille $(\\boldsymbol{x}^{(j)})_{j \\in J}$ l'ensemble des $p$ variables qualitatives, indexée par l'ensemble $J = \\left[\\![0, \\, p - 1\\right]\\!]$.\n",
    "\n",
    "Posons $(A^{(j)})_{j \\in J}$, l'ensemble des alphabets de modalités respectivement associés à chacune des variables $\\boldsymbol{x}^{(j)}$.\n",
    "\n",
    "Posons $q^{(j)} = |A^{(j)}|$ le cardinal de l'aphabet $A^{(j)}$.\n",
    "\n",
    "Observons que $0 \\lt q^{(j)} \\le n$.\n",
    "\n",
    "Considérons que les index 0 à $q^{(j)}$ sont attribués aux éléments de $A^{(j)}$ par ordre d'effectif décroissant des modalités, et par ordre lexicographique si deux modalités ont des effectifs identiques.\n",
    "\n",
    "Posons $K^{(j)} = \\left[\\![0, \\, q^{(j)} - 1\\right]\\!]$\n",
    "\n",
    "Notons $a^{(j)}_k, k \\in K^{(j)}$, la $k$-ième modalité de $A^{(j)}$.\n",
    "\n",
    "Notons $n^{(j)}_k$ l'effectif de la $k$-ième modalité de $A^{(j)}$.\n",
    "\n",
    "Observons que $\\forall j \\in J, \\,  \\displaystyle\\sum_{K^{(j)}} n^{(j)}_k = n$. \n",
    "\n",
    "Notons enfin $\\nu^{(j)}_k$ l'la fréquence relative de la $k$-ième modalité de $A^{(j)}$ ($\\nu^{(j)}_k = \\frac{n^{(j)}_k}{n}$).\n",
    "\n",
    "La fonction ... produit de $p$ lignes, la ligne $j$ représentant la variable $\\boldsymbol{x}^{(j)}$, dont les colonnes sont :\n",
    "1. les cardinaux $q^{(j)}$ des alphabets $A^{(j)}$.\n",
    "4. une mesure inspirée de la courbe de <mark>???? (la courbe des inégalités)</mark>\n",
    "3. les triplets successifs $(a^{(j)}_k, n^{(j)}_k, \\nu^{(j)}_k)$\n",
    "\n",
    "\n",
    "Intuitivement, en prenant les cas extrèmes, ... bla\n",
    "\n",
    "on comprend qu'il y a une relation entre $q^{(j)}$ et la fréquence moyenne\n",
    "\n",
    "Le but est de former une mesure qui décrit la forme de la distribution des effectifs des modalités de chacune des variables.\n",
    "\n",
    "Pour ce faire, nous souhaitons normaliser l'ensemble de ces effectifs de sorte à pouvoir les comparer à l'identité dans l'intervalle $[0, \\, 1]$.\n",
    "\n",
    "A (0, 0) correspond un effectif nul, à (1, 1) correspond l'effectif de la modalité $a_0$ d'effectif maximum.\n",
    "\n",
    "Entre les deux, les abscisses 1/q, 2/q, .., (q - 1)/q correspondent respectivement aux modalités $a_{q-1}$, $a_{q-2}$, .., $a_1$ et les ordonnées aux effectifs de ces modalités rapportés à celui de $a_0$.\n",
    "\n",
    "Notons $\\alpha_k$ l'abscisse qui représente la modalité $a_k$, alors $\\alpha_k = \\frac{q - k}{q}$.\n",
    "\n",
    "Etendons par convention pratique, l'alphabet $A$ en lui adjoignant l'élément $a_q$ d'effectif nul.\n",
    "\n",
    "Définissons l'éffectif normalisé de $a_k$ par $\\pi_k = \\frac{n_k}{n_0}$.\n",
    "\n",
    "Définissons sur [[0, q]] la fonction qui à k associe $\\pi_k$.\n",
    "\n",
    "Les termes étant posés, nous pouvons définir notre mesure.\n",
    "\n",
    "Cette mesure $\\mu$ est la surface située entre les effectifs normalisés et la droite identité, négatifs si ces effectifs sont supérieurs à la valeur identité.\n",
    "\n",
    "En d'autres terme $\\mu = \\displaystyle\\sum_{0 \\le k \\le q} (\\alpha_k - \\pi_k)$.\n",
    "\n",
    "Observons que $\\alpha_0 - \\pi_0 = \\frac{n_0}{n_0} - \\frac{q}{q}  = 0$ et que $\\alpha_q - \\pi_q = 0$\n",
    "\n",
    "D'où\n",
    "$\\mu =\n",
    "\\displaystyle\\sum_{0 \\lt k \\lt q} (\\alpha_k - \\pi_k) =\n",
    "\\displaystyle\\sum_{0 \\lt k \\lt q} (\\frac{q - k}{q} - \\pi_k) =\n",
    "\\frac{1}{q} \\left( q(q - 1) - \\frac{1}{2}(q - 1)q \\right) - \\displaystyle\\sum_{0 \\lt k \\lt q} \\pi_k$.\n",
    "\n",
    "Soit\n",
    "$\\mu =\n",
    "\\frac{1}{2}(q - 1) - \\displaystyle\\sum_{0 \\lt k \\lt q} \\pi_k =\n",
    "\\frac{1}{2}(q - 1) - \\displaystyle\\frac{n - n_0}{n_0}\n",
    "$.\n",
    "\n",
    "Appliquons à quelques cas remarquables.\n",
    "\n",
    "**Répartition constante des effectifs**\n",
    "\n",
    "Dans ce cas $\\forall k \\in [0, q-1], \\, n_k = n_0 \\Rightarrow \\pi_k = 1$\n",
    "\n",
    "Et donc $\\mu = - \\frac{1}{2}(q - 1)$\n",
    "\n",
    "**Répartition arihtmétique des effectifs**\n",
    "\n",
    "$n_q = 0$, $n_{q-1} = d$, $n_{q-2} = 2d$, $n_{q-k} = kd$, $n_0 = qd$.\n",
    "\n",
    "Et donc, par changement de variable indicielle, $n_k = (q - k)d$.\n",
    "\n",
    "On en déduit que $\\pi_k = \\frac{(q - k)d}{qd} = \\frac{(q - k)}{q}$ et donc que $\\mu = 0$.\n",
    "\n",
    "**Un contre tous**\n",
    "\n",
    "$n_0 = n - (q - 2)$ et $\\forall k, \\, 0 \\lt k \\lt q, \\, n_k = 1$.\n",
    "\n",
    "On en déduit que $\\forall k, \\, 0 \\lt k \\lt q, \\, \\pi_k = \\frac{1}{n - (q - 2)}$\n",
    "\n",
    "Et\n",
    "$\\mu =\n",
    "\\frac{1}{2}(q - 1) - \\displaystyle\\frac{q - 2}{n - (q - 2)}$.\n",
    "\n",
    "Rappelons que $0 \\lt q \\le n$\n",
    "\n",
    "Posons $x = q - 2$ il vient\n",
    "$\\mu = \\frac{1}{2}(x + 1) -\\displaystyle\\frac{x}{n - x}$\n",
    "\n",
    "Chercher le maximum nous mène au 3ème degré :\n",
    "\n",
    "$\\left( \\frac{1}{2}(x + 1) -\\displaystyle\\frac{x}{n - x} \\right)' = \\frac{1}{2}x - \\displaystyle\\frac{n}{(n - x)^2}$\n",
    "\n",
    "La dérivée s'annule pour $\\frac{1}{2}x = \\displaystyle\\frac{n}{(n - x)^2}$\n",
    "\n",
    "Soit en posant $y = n - x$, $(n - y)y^2 = 2n \\Leftrightarrow y^3 -ny^2 + 2n = 0$\n",
    "\n",
    "En divisant par $n^3$ et en posant $z = \\displaystyle\\frac{y}{n}$, il vient $z^3 - z^2 + \\displaystyle\\frac{2}{n^2}$.\n",
    "\n",
    "Développons $(z - a)(z - b)(z - c) = z^3 + (a + b + c)z^2 +(ab + ac + bc)z + abc$\n",
    "\n",
    "$\\begin{cases}\n",
    "      a + b + c = -1\\\\\n",
    "      ab + ac + bc = 0\\\\\n",
    "      abc = \\displaystyle\\frac{2}{n^2} > 0\n",
    "\\end{cases}$\n",
    "\n",
    "... Pas suffisant pour résoudre facilement..\n",
    "\n",
    "Je sais que j'ai deux racines négatives et une positive, aucune nulle évidemment.\n",
    "\n",
    "Une conséquence qui ne semble mener nulle part : $(a + 1)(b + 1)(c + 1) = abc$\n",
    "\n",
    "Tentons le coup en posant $a > 0$ et $d = -(b + c) > 0$\n",
    "\n",
    "Alors $d = a + 1$, $bc = ad = a(a + 1)$, $abc = a^2d = a^2(a + 1)$\n",
    "\n",
    "Résolution (méthode de Viète) :\n",
    "\n",
    "1/ se ramener à la forme $\\chi^3 + p\\chi + q = 0$\n",
    "\n",
    "Posons $z = \\chi + \\displaystyle\\frac{1}{3}$\n",
    "\n",
    "Nous obtenons $(\\chi + \\frac{1}{3})^3 - (\\chi + \\frac{1}{3})^2 + \\displaystyle\\frac{2}{n^2} = 0$\n",
    "\n",
    "En développant et en regroupant les degrés, on obtient\n",
    "$\\chi^3 - \\displaystyle\\frac{1}{3}\\chi - \\displaystyle\\frac{2}{27} + \\displaystyle\\frac{2}{n^2} = 0$\n",
    "\n",
    "Posons $\\chi = \\zeta + \\displaystyle\\frac{1}{9 \\zeta}$ et $\\Zeta = \\zeta^3$\n",
    "\n",
    "Il vient $\\Zeta^2 + 2\\left(\\displaystyle\\frac{1}{n^2} - \\displaystyle\\frac{1}{27}\\right)\\Zeta + \\displaystyle\\frac{1}{27^2} = 0$\n",
    "\n",
    "Dont le discriminant est\n",
    "$\\delta = 4\\left(\\displaystyle\\frac{1}{n^2} - \\displaystyle\\frac{1}{27}\\right)^2 - \\displaystyle\\frac{1}{27^2} =\n",
    "4\\left(\\displaystyle\\frac{1}{n^4} - \\displaystyle\\frac{2}{27n^2}\\right) = -\\displaystyle\\frac{\\Delta}{27}$\n",
    "\n",
    "Notons que ce discrimant est négatif pour $n > \\sqrt{\\frac{27}{2}} = 3,67..$ ce qui entraîne alors que l'équation d'origine possède 3 racines réelles.\n",
    "\n",
    "A terminer un jour de loisir.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 1000\n",
    "x = np.linspace(-1, n - 2, n).astype(float)\n",
    "y = (1 / 2) * (x + 1) - x / (n - x)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "# asymptote linéaire de pente 1/2 tant que x << n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

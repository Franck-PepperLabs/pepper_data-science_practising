{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Faire mieux qu'un dictionnaire de traductions, faire un index et glossaire !</mark>\n",
    "\n",
    "R√©cup√©rer tout ce que j'ai d√©j√† enregistr√© dans :\n",
    "* mon journal\n",
    "* le journal de formation\n",
    "* les doc de projet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Maths for Machine learning : statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Derni√®res entr√©es\n",
    "\n",
    "#### ‚¶ø [**Student's t-test**](https://en.wikipedia.org/wiki/Student's_t-test) ([*Test de Student*](https://fr.wikipedia.org/wiki/Test_de_Student))\n",
    "\n",
    "#### ‚¶ø [**F-test of equality of variances**](https://en.wikipedia.org/wiki/F-test_of_equality_of_variances) ([*Test de Fisher d'√©galit√© de deux variances*](https://fr.wikipedia.org/wiki/Test_de_Fisher_d'√©galit√©_de_deux_variances))\n",
    "\n",
    "#### ‚¶ø [**Category:Statistical tests**](https://en.wikipedia.org/wiki/Category:Statistical_tests) ([*Cat√©gorie:Test statistique*](https://fr.wikipedia.org/wiki/Cat√©gorie:Test_statistique))\n",
    "\n",
    "#### ‚¶ø [**Normality test**](https://en.wikipedia.org/wiki/Normality_test) ([*Test de normalit√©*](https://fr.wikipedia.org/wiki/Test_de_normalit√©))\n",
    "\n",
    "#### ‚¶ø [**Omnibus test**](https://en.wikipedia.org/wiki/Omnibus_test) ([*Test Omnibus*]())\n",
    "\n",
    "#### ‚¶ø [**Category:Statistical deviation and dispersion**](https://en.wikipedia.org/wiki/Category:Statistical_deviation_and_dispersion) ([*Ecart et dispersion statistiques*]())\n",
    "\n",
    "#### ‚¶ø [**Category:Statistical ratios**](https://en.wikipedia.org/wiki/Category:Statistical_ratios) ([*Ratios statistiques*]())\n",
    "\n",
    "#### ‚¶ø [**Brown‚ÄìForsythe test**](https://en.wikipedia.org/wiki/Brown‚ÄìForsythe_test) ([**]())\n",
    "\n",
    "#### ‚¶ø [**Bartlett's test**](https://en.wikipedia.org/wiki/Bartlett%27s_test) ([*Test de Bartlett*](https://fr.wikipedia.org/wiki/Test_de_Bartlett))\n",
    "\n",
    "#### ‚¶ø [**Levene's test**](https://en.wikipedia.org/wiki/Levene's_test) ([*Test de Levene*](https://fr.wikipedia.org/wiki/Test_de_Levene))\n",
    "\n",
    "#### ‚¶ø [**Goldfeld‚ÄìQuandt test**](https://en.wikipedia.org/wiki/Goldfeld‚ÄìQuandt_test) ([*Test de Goldfeld et Quandt*](https://fr.wikipedia.org/wiki/Test_de_Goldfeld_et_Quandt))\n",
    "\n",
    "#### ‚¶ø [**Hartley's test**](https://en.wikipedia.org/wiki/Hartley's_test) ([**]())\n",
    "\n",
    "#### ‚¶ø [**Analysis of variance (ANOVA)**](https://en.wikipedia.org/wiki/Analysis_of_variance) ([*Analyse de la variance (ANOVA)*](https://fr.wikipedia.org/wiki/Analyse_de_la_variance))\n",
    "\n",
    "#### ‚¶ø [**Null hypothesis**](https://en.wikipedia.org/wiki/Null_hypothesis) ([*Hypoth√®se nulle*](https://fr.wikipedia.org/wiki/Hypoth√®se_nulle))\n",
    "\n",
    "$H_0$\n",
    "\n",
    "#### ‚¶ø [**Hypothesis**](https://en.wikipedia.org/wiki/Hypothesis) ([*Hypoth√®se*](https://fr.wikipedia.org/wiki/Hypoth√®se))\n",
    "\n",
    "#### ‚¶ø [**Statistical hypothesis testing**](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) ([*Test statistique*](https://fr.wikipedia.org/wiki/Test_statistique))\n",
    "\n",
    "#### ‚¶ø [**Category:Parametric statistics**](https://en.wikipedia.org/wiki/Category:Parametric_statistics) ([**]())\n",
    "\n",
    "#### ‚¶ø [**Parametric statistics**](https://en.wikipedia.org/wiki/Parametric_statistics) ([**]())\n",
    "\n",
    "#### ‚¶ø [**<i>t</i>-statistic**](https://en.wikipedia.org/wiki/T-statistic) ([**]())\n",
    "\n",
    "#### ‚¶ø [**<i>p</i>-value**](https://en.wikipedia.org/wiki/P-value) ([*Valeur p*](https://fr.wikipedia.org/wiki/Valeur_p))\n",
    "\n",
    "#### ‚¶ø [**Statistical significance**](https://en.wikipedia.org/wiki/Statistical_significance) ([*Signification statistique*](https://fr.wikipedia.org/wiki/Signification_statistique))\n",
    "\n",
    "\n",
    "#### ‚¶ø [**Category:Nonparametric statistics**](https://en.wikipedia.org/wiki/Category:Nonparametric_statistics) ([*Cat√©gorie:Statistiques non param√©triques*](https://fr.wikipedia.org/wiki/Cat√©gorie:Statistiques_non_param√©triques))\n",
    "\n",
    "#### ‚¶ø [****]() ([**]())\n",
    "\n",
    "#### ‚¶ø [****]() ([**]())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouvelles entr√©es √† int√©grer\n",
    "\n",
    "* *d√©pendance partielle*\n",
    "* **classifier** : *classifieur* (et non *classificateur*)\n",
    "* **feature** : *caract√©ristique* (et non *fonctionnalit√©*, ni *entit√©*)\n",
    "\n",
    "Toutes les r√©f√©rences enregistr√©es dans les journaux et non encore class√©es\n",
    "\n",
    "Lien vers les fiches traduites quand elles l'ont √©t√© + les priorit√©s de traduction.\n",
    "\n",
    "Sortir les inserts dans les cours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [**Kaniadakis statistics**](https://en.wikipedia.org/wiki/Kaniadakis_statistics) (*Statistique de Kaniadakis*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚¶ø [**Goodness of fit**](https://en.wikipedia.org/wiki/Goodness_of_fit) ([*Qualit√© de l'ajustement*](https://fr.wikipedia.org/wiki/Qualit√©_de_l'ajustement))\n",
    "\n",
    "The **goodness of fit** of a **statistical model** describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model in question. Such measures can be used in **statistical hypothesis testing**, e.g. to **test for normality** of **residuals**, to test whether two samples are drawn from identical distributions (see **Kolmogorov‚ÄìSmirnov** test), or whether outcome frequencies follow a specified distribution (see **Pearson's chi-square test**). In the **analysis of variance**, one of the components into which the variance is partitioned may be a **lack-of-fit sum of squares**.\n",
    "\n",
    "---\n",
    "\n",
    "La **qualit√© d'ajustement** d'un **mod√®le statistique** d√©crit dans quelle mesure il s'ajuste √† un ensemble d'observations. Les mesures de la qualit√© de l'ajustement r√©sument g√©n√©ralement l'√©cart entre les valeurs observ√©es et les valeurs attendues dans le cadre du mod√®le en question. Ces mesures peuvent √™tre utilis√©es dans les **tests d'hypoth√®ses statistiques**, par ex. pour **tester la normalit√©** des **r√©sidus**, pour tester si deux √©chantillons sont tir√©s de distributions identiques (voir **test de Kolmogorov-Smirnov**), ou si les fr√©quences des r√©sultats suivent une distribution sp√©cifi√©e (voir **Pearson's test du chi carr√©**). Dans l'**analyse de la variance**, l'une des composantes dans lesquelles la variance est r√©partie peut √™tre une **somme des carr√©s sans ajustement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚¶ø [**Studentized residual**](https://en.wikipedia.org/wiki/Studentized_residual) (*R√©sidu studentis√©*)\n",
    "\n",
    "In statistics, a **studentized residual** is the quotient resulting from the division of a **residual** by an **estimate** of its **standard deviation**. It is a form of a **Student's t-statistic**, with the estimate of error varying between points.\n",
    "\n",
    "This is an important technique in the detection of **outliers**. It is among several named in honor of **William Sealey Gosset**, who wrote under the pseudonym *Student*. Dividing a statistic by a **sample standard deviation** is called *studentizing*, in analogy with **standardizing** and **normalizing**.\n",
    "\n",
    "---\n",
    "\n",
    "En statistique, un **r√©sidu studentis√©** est le quotient r√©sultant de la division d'un **r√©sidu** par une **estimation** de son **√©cart type**. Il s'agit d'une forme de **statistique t de Student**, l'estimation de l'erreur variant d'un point √† l'autre.\n",
    "\n",
    "Il s'agit d'une technique importante dans la d√©tection des **valeurs aberrantes**. Il fait partie de plusieurs nomm√©s en l'honneur de **William Sealey Gosset**, qui a √©crit sous le pseudonyme *Student*. La division d'une statistique par un **√©cart-type d'√©chantillon** s'appelle *studentizing*, par analogie avec **standardizing** et **normalizing**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚¶ø [**Gauss‚ÄìMarkov theorem**](https://en.wikipedia.org/wiki/Gauss-Markov_theorem) ([*Th√©or√®me de Gauss-Markov*](https://fr.wikipedia.org/wiki/Th√©or√®me_de_Gauss-Markov))\n",
    "\n",
    "In **statistics**, the **Gauss‚ÄìMarkov theorem** (or simply **Gauss theorem** for some authors)[1] states that the **ordinary least squares** (OLS) estimator has the lowest **sampling variance** within the **class** of **linear unbiased estimators**, if the **errors** in the **linear regression model** are **uncorrelated**, have **equal variances** and expectation value of zero.[2] The errors do not need to be **normal**, nor do they need to be **independent and identically distributed** (only **uncorrelated** with mean zero and **homoscedastic** with finite variance). The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the **James‚ÄìStein estimator** (which also drops linearity), **ridge regression**, or simply any **degenerate** estimator.\n",
    "\n",
    "---\n",
    "\n",
    "En **statistiques**, le **th√©or√®me de Gauss‚ÄìMarkov** (ou simplement le **th√©or√®me de Gauss** pour certains auteurs)[1] stipule que l'estimateur des **moindres carr√©s ordinaires** (OLS) a le plus basse **variance d'√©chantillonnage** dans la **classe** des **estimateurs lin√©aires sans biais**, si les **erreurs** du **mod√®le de r√©gression lin√©aire** sont **non corr√©l√©es**, ont des **variances √©gales** et valeur d'esp√©rance de z√©ro.[2] Les erreurs n'ont pas besoin d'√™tre **normales**, ni d'√™tre **ind√©pendantes et distribu√©es de mani√®re identique** (seulement **non corr√©l√©es** avec une moyenne nulle et **homosc√©dastiques** avec une variance finie). L'exigence que l'estimateur soit sans biais ne peut pas √™tre abandonn√©e, car il existe des estimateurs biais√©s avec une variance plus faible. Voir, par exemple, l'**estimateur James-Stein** (qui supprime √©galement la lin√©arit√©), la **r√©gression ridge** ou simplement tout estimateur **d√©g√©n√©r√©**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚¶ø [**Homoscedasticity and heteroscedasticity**](https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity)\n",
    "\n",
    "In **statistics**, a **sequence** (or a vector) of **random variables** is **homoscedastic** if all its random variables have the same finite **variance**. This is also known as **homogeneity of variance**. The complementary notion is called **heteroscedasticity**. The spellings *homoskedasticity* and *heteroskedasticity* are also frequently used.[1][2][3]\n",
    "\n",
    "Assuming a variable is homoscedastic when in reality it is heteroscedastic results in unbiased but inefficient point estimates and in biased estimates of standard errors, and may result in overestimating the **goodness of fit** as measured by the **Pearson coefficient**.\n",
    "\n",
    "The existence of heteroscedasticity is a major concern in **regression analysis** and the **analysis of variance**, as it invalidates **statistical tests of significance** that assume that the **modelling errors** all have the same variance. While the **ordinary least squares** estimator is still unbiased in the presence of heteroscedasticity, it is inefficient and **generalized least squares** should be used instead.[4][5]\n",
    "\n",
    "Because heteroscedasticity concerns **expectations** of the second **moment** of the errors, its presence is referred to as **misspecification** of the second order.[6]\n",
    "\n",
    "The **econometrician** **Robert Engle** was awarded the 2003 **Nobel Memorial Prize for Economics** for his studies on **regression analysis** in the presence of heteroscedasticity, which led to his formulation of the **autoregressive conditional heteroscedasticity** (ARCH) modeling technique.[7]\n",
    "\n",
    "---\n",
    "\n",
    "En **statistiques**, une **s√©quence** (ou un vecteur) de **variables al√©atoires** est **homosc√©dastique** si toutes ses variables al√©atoires ont la m√™me **variance** finie. Ceci est √©galement connu sous le nom d'**homog√©n√©it√© de la variance**. La notion compl√©mentaire est appel√©e **h√©t√©rosc√©dasticit√©**. Les orthographes *homoskedasticity* et *heteroskedasticity* sont √©galement fr√©quemment utilis√©es.[1][2][3]\n",
    "\n",
    "Supposer qu'une variable est homosc√©dastique alors qu'en r√©alit√© elle est h√©t√©rosc√©dastique donne des estimations ponctuelles non biais√©es mais inefficaces et des estimations biais√©es des erreurs types, et peut entra√Æner une surestimation de la **qualit√© de l'ajustement** telle que mesur√©e par le **coefficient de Pearson**.\n",
    "\n",
    "L'existence d'h√©t√©rosc√©dasticit√© est une pr√©occupation majeure dans l'**analyse de r√©gression** et l'**analyse de variance**, car elle invalide les **tests statistiques de signification** qui supposent que les **erreurs de mod√©lisation** ont toutes la m√™me variance. Bien que l'estimateur des **moindres carr√©s ordinaires** soit toujours sans biais en pr√©sence d'h√©t√©rosc√©dasticit√©, il est inefficace et les **moindres carr√©s g√©n√©ralis√©s** doivent √™tre utilis√©s √† la place.\n",
    "\n",
    "Comme l'h√©t√©rosc√©dasticit√© concerne les **attentes** du deuxi√®me **moment** des erreurs, sa pr√©sence est appel√©e **sp√©cification erron√©e** du second ordre.[6]\n",
    "\n",
    "L'**√©conom√®tre** **Robert Engle** a re√ßu le **prix Nobel d'√©conomie** en 2003 pour ses √©tudes sur l'**analyse de r√©gression** en pr√©sence d'h√©t√©rosc√©dasticit√©, ce qui l'a conduit √† la formulation de la technique de mod√©lisation **h√©t√©rosc√©dasticit√© conditionnelle autor√©gressive** (ARCH).[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [‚öì](https://en.wikipedia.org/wiki/Category:Statistics) [**Statistics**](https://en.wikipedia.org/wiki/Statistics) ([*Statistique*](https://fr.wikipedia.org/wiki/Statistique))\n",
    "\n",
    "**Outline üëÄ** [**Statistics**](https://en.wikipedia.org/wiki/Outline_of_statistics) ‚Ä¢ \n",
    "**Index üíΩ** [**Statistics**](https://en.wikipedia.org/wiki/List_of_statistics_articles) ‚Ä¢ **Glossary** [**Probability and statistics**](https://en.wikipedia.org/wiki/Glossary_of_probability_and_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öì [**Descriptive statistics**](https://en.wikipedia.org/wiki/Descriptive_statistics) ([*Statistique descriptive*](https://fr.wikipedia.org/wiki/Statistique_descriptive))\n",
    "\n",
    "**Outline üëÄ** [**Descriptive statistics**](https://en.wikipedia.org/wiki/Category:Descriptive_statistics)\n",
    "\n",
    "**Parent categories   [‚öì]**: Statistical analysis ¬∑ Summary statistics\n",
    "\n",
    "**Child categories  [‚öì]**:\n",
    "* ‚öì Exploratory data analysis (14 P)\n",
    "* ‚öì Contingency table (2 C, 3 P)\n",
    "* * ‚öì Statistical tests for contingency tables (9 P)\n",
    "* * ‚öì Summary statistics for contingency tables (28 P)\n",
    "* ‚öì Statistical deviation and dispersion (5 C, 83 P)\n",
    "* * ‚öì Measurement of biodiversity (21 P)\n",
    "* * ‚öì Point estimation performance (12 P)\n",
    "* * ‚öì Scale statistics (8 P)\n",
    "* * ‚öì Signal processing metrics (5 P)\n",
    "* * ‚öì Variance reduction (8 P)\n",
    "* ‚öì Statistical distance (2 C, 37 P)\n",
    "* * ‚öì Clustering criteria (20 P)\n",
    "* * ‚öì F-divergences (5 P)\n",
    "* ‚öì Statistical ratios (70 P)\n",
    "* ‚öì Statistical indicators (4 C, 2 P)\n",
    "* ‚öì Statistical charts and diagrams (1 C, 116 P)\n",
    "* * ‚öì Financial charts (11 P)\n",
    "\n",
    "**Corpus**:\n",
    "* [**Continuous data**](https://en.wikipedia.org/wiki/Probability_distribution#Absolutely_continuous_probability_distribution)\n",
    "* * **Center**: Mean (Arithmetic ¬∑ Cubic ¬∑ Generalized/power ¬∑ Geometric ¬∑ Harmonic ¬∑ Heinz ¬∑ Lehmer) ¬∑ Median ¬∑ Mode\n",
    "* * **Dispersion**: Average absolute deviation ¬∑ Coefficient of variation ¬∑ Interquartile range ¬∑ Percentile ¬∑ Range ¬∑ Standard deviation ¬∑ Variance\n",
    "* * **Shape**: Central limit theorem ¬∑ Moments (Kurtosis ¬∑ L-moments ¬∑ Skewness)\n",
    "* **Count data**: Index of dispersion\n",
    "* **Summary tables**: Contingency table ¬∑ Frequency distribution ¬∑ Grouped data\n",
    "* **Dependence**: Partial correlation ¬∑ Pearson product-moment correlation ¬∑ Rank correlation (Kendall's œÑ ¬∑ Spearman's œÅ) ¬∑ Scatter plot\n",
    "* **Graphics**: Bar chart ¬∑ Biplot ¬∑ Box plot ¬∑ Control chart ¬∑ Correlogram ¬∑ Fan chart ¬∑ Forest plot ¬∑ Histogram ¬∑ Pie chart ¬∑ Q‚ÄìQ plot ¬∑ Radar chart ¬∑ Run chart ¬∑ Scatter plot ¬∑ Stem-and-leaf display ¬∑ Violin plot\n",
    "\n",
    "\n",
    "**Index üíΩ**:\n",
    "* ‚öì [**Descriptive statistics**](https://en.wikipedia.org/wiki/Descriptive_statistics) ([*Statistique descriptive*](https://fr.wikipedia.org/wiki/Statistique_descriptive))\n",
    "* [**Data reporting**](https://en.wikipedia.org/wiki/Data_reporting) (*???*)\n",
    "* [**Descriptive research**](https://en.wikipedia.org/wiki/Descriptive_research) (*???*)\n",
    "* [**Geometric median**](https://en.wikipedia.org/wiki/Geometric_median) (*???*)\n",
    "* [**Grand mean (*pooled mean*)**](https://en.wikipedia.org/wiki/Grand_mean) (*???*)\n",
    "* [**Grouped data**](https://en.wikipedia.org/wiki/Grouped_data) (*???*)\n",
    "* [**Mean log deviation (MLD)**](https://en.wikipedia.org/wiki/Mean_log_deviation) (*???*)\n",
    "* [**Spatial descriptive statistics**](https://en.wikipedia.org/wiki/Spatial_descriptive_statistics) (*???*)\n",
    "* [**Strictly standardized mean difference (SSMD)**](https://en.wikipedia.org/wiki/Strictly_standardized_mean_difference) (*???*)\n",
    "* [**Wide and narrow data**](https://en.wikipedia.org/wiki/Wide_and_narrow_data) (*???*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Exploratory_data_analysis) [**Exploratory data analysis**](https://en.wikipedia.org/wiki/Exploratory_data_analysis) (14 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Exploratory data analysis\n",
    "* Data reduction\n",
    "* Exploratory causal analysis\n",
    "* Table diagonalization\n",
    "* Configural frequency analysis\n",
    "* Grand Tour (data visualisation)\n",
    "* Median polish\n",
    "* Midhinge\n",
    "* Projection pursuit\n",
    "* Stem-and-leaf display\n",
    "* TinkerPlots\n",
    "* Trimean\n",
    "* John Tukey\n",
    "* Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Contingency_table) [**Contingency table**](https://en.wikipedia.org/wiki/Contingency_table) (2 C, 3 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Contingency table**](https://en.wikipedia.org/wiki/Contingency_table) ([Tableau de contingence](https://fr.wikipedia.org/wiki/Tableau_de_contingence))\n",
    "* Iterative proportional fitting\n",
    "* NM-method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_tests_for_contingency_tables) **Statistical tests for contingency tables** (9 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Barnard's test\n",
    "* Boschloo's test\n",
    "* [**Chi-squared test**](https://en.wikipedia.org/wiki/Chi-squared_test) ([Test du œá¬≤](https://fr.wikipedia.org/wiki/Test_du_œá¬≤))\n",
    "* Cochran‚ÄìArmitage test for trend\n",
    "* Cochran‚ÄìMantel‚ÄìHaenszel statistics\n",
    "* Fisher's exact test\n",
    "* G-test\n",
    "* Pearson's chi-squared test\n",
    "* Yates's correction for continuity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [‚öì](https://en.wikipedia.org/wiki/Category:Summary_statistics_for_contingency_tables) **Summary statistics for contingency tables** (28 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cochran‚ÄìMantel‚ÄìHaenszel statistics\n",
    "* Coefficient of colligation\n",
    "* Cohen's kappa\n",
    "* Cram√©r's V\n",
    "* Diagnostic odds ratio\n",
    "* F-score\n",
    "* False discovery rate\n",
    "* Fleiss' kappa\n",
    "* Goodman and Kruskal's gamma\n",
    "* Goodman and Kruskal's lambda\n",
    "* Index of coincidence\n",
    "* Likelihood ratios in diagnostic testing\n",
    "* McNemar's test\n",
    "* Odds ratio\n",
    "* P4-metric\n",
    "* Phi coefficient\n",
    "* Pointwise mutual information\n",
    "* Polychoric correlation\n",
    "* Positive and negative predictive values\n",
    "* Pre- and post-test probability\n",
    "* Rand index\n",
    "* Receiver operating characteristic\n",
    "* Sample odds ratio\n",
    "* Total operating characteristic\n",
    "* Tschuprow's T\n",
    "* Uncertainty coefficient\n",
    "* Variation of information\n",
    "* Yule's Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_deviation_and_dispersion) **Statistical deviation and dispersion** (5 C, 83 P)\n",
    "\n",
    "* ‚öì Measurement of biodiversity (21 P)\n",
    "* ‚öì Point estimation performance (12 P)\n",
    "* ‚öì Scale statistics (8 P)\n",
    "* ‚öì Signal processing metrics (5 P)\n",
    "* ‚öì Variance reduction (8 P)\n",
    "* Average absolute deviation\n",
    "* Algorithms for calculating variance\n",
    "* Berkson error model\n",
    "* Bessel's correction\n",
    "* Bhattacharyya distance\n",
    "* Bollinger Bands\n",
    "* Central moment\n",
    "* Circular standard deviation\n",
    "* Circular variance\n",
    "* Clustered standard errors\n",
    "* Coefficient of variation\n",
    "* Cokurtosis\n",
    "* Common-method variance\n",
    "* Conditional variance\n",
    "* Cornish‚ÄìFisher expansion\n",
    "* Cosmic variance\n",
    "* Deviance (statistics)\n",
    "* Deviation (statistics)\n",
    "* Engineering tolerance\n",
    "* Errors and residuals\n",
    "* Estimation of covariance matrices\n",
    "* F-test of equality of variances\n",
    "* Fano factor\n",
    "* Full width at half maximum\n",
    "* Goldfeld‚ÄìQuandt test\n",
    "* Greenwood statistic\n",
    "* Homoscedasticity and heteroscedasticity\n",
    "* Index of dispersion\n",
    "* Kurtosis\n",
    "* Law of total variance\n",
    "* Margin of error\n",
    "* Market risk\n",
    "* McKay's approximation for the coefficient of variation\n",
    "* Mean absolute difference\n",
    "* Mean absolute error\n",
    "* Mean absolute percentage error\n",
    "* Mean absolute scaled error\n",
    "* Mean square quantization error\n",
    "* Mean squared displacement\n",
    "* Mean squared error\n",
    "* Mean squared prediction error\n",
    "* Medcouple\n",
    "* Median absolute deviation\n",
    "* Minimum mean square error\n",
    "* MINQUE\n",
    "* Negentropy\n",
    "* Option on realized variance\n",
    "* Option on realized volatility\n",
    "* Otsu's method\n",
    "* Pooled variance\n",
    "* Popoviciu's inequality on variances\n",
    "* Population variance\n",
    "* Precision (statistics)\n",
    "* Probable error\n",
    "* Propagation of uncertainty\n",
    "* Qualitative variation\n",
    "* Quartile coefficient of dispersion\n",
    "* Quasi-variance\n",
    "* Range (statistics)\n",
    "* Ratio estimator\n",
    "* Reduced chi-squared statistic\n",
    "* Rescaled range\n",
    "* Robust measures of scale\n",
    "* Root mean square\n",
    "* Root-mean-square deviation\n",
    "* Root-mean-square deviation of atomic positions\n",
    "* Skewness\n",
    "* Skewness risk\n",
    "* Squared deviations from the mean\n",
    "* Standard deviation\n",
    "* Standard error\n",
    "* Standardized moment\n",
    "* Statistical dispersion\n",
    "* Studentized residual\n",
    "* Symmetric mean absolute percentage error\n",
    "* Taylor's law\n",
    "* Tracking signal\n",
    "* True variance\n",
    "* Variance\n",
    "* Variance inflation factor\n",
    "* Variation ratio\n",
    "* Variogram\n",
    "* WMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_distance) [**Statistical distance**](https://en.wikipedia.org/wiki/Statistical_distance) (2 C, 37 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [‚öì _](https://en.wikipedia.org/wiki/Category:Statistical_distance) (37 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. [**Statistical distance**](https://en.wikipedia.org/wiki/Statistical_distance) ([*Distance statistique*](https://fr.wikipedia.org/wiki/Distance_statistique))\n",
    "2. Bhattacharyya angle\n",
    "3. Bhattacharyya distance\n",
    "4. Bregman divergence\n",
    "5. Canonical divergence\n",
    "6. Chentsov's theorem\n",
    "7. Circular error probable\n",
    "8. Cook's distance\n",
    "9. Cram√©r‚Äìvon Mises criterion\n",
    "10. Deviation (statistics)\n",
    "11. Discrepancy (statistics)\n",
    "12. DiShIn\n",
    "13. Distance correlation\n",
    "14. Divergence (statistics)\n",
    "15. Energy distance\n",
    "16. Earth mover's distance\n",
    "17. Fisher information metric\n",
    "18. Hellinger distance\n",
    "19. Information distance\n",
    "20. Jensen‚ÄìShannon divergence\n",
    "21. Kendall tau distance\n",
    "22. Kolmogorov‚ÄìSmirnov test\n",
    "23. Mahalanobis distance\n",
    "24. Minimum-distance estimation\n",
    "25. Normalized compression distance\n",
    "26. Normalized Google distance\n",
    "27. Optimal matching\n",
    "28. Pitman closeness criterion\n",
    "29. Process Window Index\n",
    "30. Second-order co-occurrence pointwise mutual information\n",
    "31. Semantic similarity\n",
    "32. Signal-to-noise statistic\n",
    "33. Similarity measure\n",
    "34. Squared Euclidean distance\n",
    "35. Stein discrepancy\n",
    "36. Stein's method\n",
    "37. Wasserstein metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [‚öì](https://en.wikipedia.org/wiki/Category:Clustering_criteria) **Clustering criteria** (20 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted mutual information\n",
    "* Automatic clustering algorithms\n",
    "* Balanced clustering\n",
    "* Dasgupta's objective\n",
    "* Davies‚ÄìBouldin index\n",
    "* Determining the number of clusters in a data set\n",
    "* Dunn index\n",
    "* Elbow method (clustering)\n",
    "* F-score\n",
    "* Fowlkes‚ÄìMallows index\n",
    "* Hopkins statistic\n",
    "* Jaccard index\n",
    "* MinHash\n",
    "* P4-metric\n",
    "* Rand index\n",
    "* Silhouette (clustering)\n",
    "* SimHash\n",
    "* Similarity measure\n",
    "* Simple matching coefficient\n",
    "* Variation of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [‚öì](https://en.wikipedia.org/wiki/Category:F-divergences) [**F-divergence**](https://en.wikipedia.org/wiki/F-divergence) (5 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**<i>f</i>-divergence**](https://en.wikipedia.org/wiki/F-divergence)\n",
    "* [**Divergence (statistics)**](https://en.wikipedia.org/wiki/Divergence_(statistics))\n",
    "* [**Hellinger distance**](https://en.wikipedia.org/wiki/Hellinger_distance)\n",
    "* [**Kullback‚ÄìLeibler divergence**](https://en.wikipedia.org/wiki/Kullback-Leibler_divergence)\n",
    "* [**Total variation distance of probability measures**](https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_ratios) **Statistical ratios** (70 P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Attack rate\n",
    "* Bayes factor\n",
    "* Beta (finance)\n",
    "* [**Coefficient of determination**](https://en.wikipedia.org/wiki/Coefficient_of_determination) ([*Coefficient de d√©termination*](https://fr.wikipedia.org/wiki/Coefficient_de_d√©termination))\n",
    "* Coefficient of variation\n",
    "* Conditional probability\n",
    "* Correlation ratio\n",
    "* Cram√©r's V\n",
    "* Diagnostic odds ratio\n",
    "* Experimental event rate\n",
    "* F-test\n",
    "* F-test of equality of variances\n",
    "* F-score\n",
    "* Failure rate\n",
    "* False positive rate\n",
    "* Fano factor\n",
    "* Fraction of variance unexplained\n",
    "* Goodman and Kruskal's lambda\n",
    "* Ground ball/fly ball ratio\n",
    "* Hansen‚ÄìJagannathan bound\n",
    "* Hazard ratio\n",
    "* Index of dispersion\n",
    "* Information gain ratio\n",
    "* Information ratio\n",
    "* Ka/Ks ratio\n",
    "* Lexis ratio\n",
    "* Likelihood-ratio test\n",
    "* Wilks' theorem\n",
    "* Mills ratio\n",
    "* Normalization (statistics)\n",
    "* Odds\n",
    "* Outliers ratio\n",
    "* P4-metric\n",
    "* [**Pearson correlation coefficient**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "* Phi coefficient\n",
    "* Polynomial and rational function modeling\n",
    "* Positive and negative predictive values\n",
    "* Prevalence\n",
    "* Prevalence effect\n",
    "* Pseudo-R-squared\n",
    "* Quadrant count ratio\n",
    "* Quartile coefficient of dispersion\n",
    "* Ratio distribution\n",
    "* Ratio estimator\n",
    "* Relative change and difference\n",
    "* Relative index of inequality\n",
    "* Relative risk\n",
    "* Relative risk reduction\n",
    "* Rescaled range\n",
    "* Response-rate ratio\n",
    "* Sampling fraction\n",
    "* Sensitivity and specificity\n",
    "* Sharpe ratio\n",
    "* Signal-to-noise ratio\n",
    "* Signal-to-noise statistic\n",
    "* Sortino ratio\n",
    "* Standard score\n",
    "* Standardized moment\n",
    "* Standardized mortality ratio\n",
    "* Strikeout-to-walk ratio\n",
    "* Studentization\n",
    "* Studentized range\n",
    "* Studentized residual\n",
    "* Survival rate\n",
    "* T-statistic\n",
    "* Treynor ratio\n",
    "* Uncertainty coefficient\n",
    "* Upside potential ratio\n",
    "* Variance inflation factor\n",
    "* Variation ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_indicators) **Statistical indicators** (4 C, 2 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öì **_** (2 P)\n",
    "\n",
    "* [**Index (statistics)**](https://en.wikipedia.org/wiki/Index_(statistics))\n",
    "* [**Stonewall Workplace Equality Index**](https://en.wikipedia.org/wiki/Stonewall_Workplace_Equality_Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öì **Concentration indicators** (1 C, 36 P)\n",
    "\n",
    "* [**Gini coefficient**](https://en.wikipedia.org/wiki/Gini_coefficient)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öì **Correlation indicators** (5 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Correlation coefficient**](https://en.wikipedia.org/wiki/Correlation_coefficient) (*Coefficient de corr√©lation*)\n",
    "* [**Coefficient of multiple correlation**](https://en.wikipedia.org/wiki/Coefficient_of_multiple_correlation)\n",
    "* [**Pearson (product-moment) correlation coefficient (P(PM)CC)**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "* [**Point-biserial correlation coefficient**](https://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient)\n",
    "* [**Coefficient of determination ($R^2$)**](https://en.wikipedia.org/wiki/Coefficient_of_determination) ([*Coefficient de d√©termination*](https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚¶ø [**Correlation coefficient**](https://en.wikipedia.org/wiki/Correlation_coefficient) (*Coefficient de corr√©lation*)\n",
    "\n",
    "A **correlation coefficient** is a **numerical measure** of some type of **correlation**, meaning a statistical relationship between two **variables**.[a] The variables may be two **columns** of a given **data** set of observations, often called a **sample**, or two components of a **multivariate random variable** with a known distribution.[citation needed]\n",
    "\n",
    "Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics. They all assume values in the range from ‚àí1 to +1, where ¬±1 indicates the strongest possible agreement and 0 the strongest possible disagreement.[2] As tools of analysis, correlation coefficients present certain problems, including the propensity of some types to be distorted by **outliers** and the possibility of incorrectly being used to infer a **causal relationship** between the variables (for more, see **Correlation does not imply causation**).[3]\n",
    "\n",
    "---\n",
    "\n",
    "Un **coefficient de corr√©lation** est une **mesure num√©rique** d'un certain type de **corr√©lation**, c'est-√†-dire une relation statistique entre deux **variables**.[a] Les variables peuvent √™tre deux **colonnes**. d'un **jeu de donn√©es** d'observations donn√©, souvent appel√© un **√©chantillon**, ou de deux composants d'une **variable al√©atoire multivari√©e** avec une distribution connue. [citation n√©cessaire]\n",
    "\n",
    "Il existe plusieurs types de coefficients de corr√©lation, chacun avec sa propre d√©finition et sa propre gamme d'applications et de caract√©ristiques. Ils prennent tous des valeurs comprises entre ‚àí1 et +1, o√π ¬±1 indique l'accord le plus fort possible et 0 le d√©saccord le plus fort possible.[2] En tant qu'outils d'analyse, les coefficients de corr√©lation pr√©sentent certains probl√®mes, notamment la propension de certains types √† √™tre fauss√©s par des **valeurs aberrantes** et la possibilit√© d'√™tre utilis√©s √† tort pour d√©duire une **relation causale** entre les variables (pour en savoir plus, voir **Corr√©lation n'implique pas causalit√©**).[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öì **Demographics indicators** (1 C, 8 P)\n",
    "\n",
    "\n",
    "* ‚öì International quality of life rankings (2 C, 15 P)\n",
    "* Carrying capacity\n",
    "* EU Social Progress Index\n",
    "* Net migration rate\n",
    "* Population ageing\n",
    "* Rate of natural increase\n",
    "* Survival rate\n",
    "* World Development Indicators\n",
    "* World Governance Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öì **Social statistics indicators** (3 P)\n",
    "\n",
    "* Clearance rate\n",
    "* Good Country Index\n",
    "* Index of Economic Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_charts_and_diagrams) **Statistical charts and diagrams** (1 C, 116 P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [‚öì](https://en.wikipedia.org/wiki/Category:Statistical_charts_and_diagrams) **Statistical charts and diagrams**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List of graphical methods\n",
    "* Statistical graphics\n",
    "* Andrews plot\n",
    "* Anscombe's quartet\n",
    "* Area chart\n",
    "* Bagplot\n",
    "* Bar chart\n",
    "* Barber‚ÄìJohnson diagram\n",
    "* Biplot\n",
    "* Bland‚ÄìAltman plot\n",
    "* Bow-tie diagram\n",
    "* Box plot\n",
    "* C-chart\n",
    "* Carpet plot\n",
    "* Cartogram\n",
    "* Chernoff face\n",
    "* Chord diagram (information visualization)\n",
    "* Choropleth map\n",
    "* Circular distribution\n",
    "* Composite bar chart\n",
    "* Contour boxplot\n",
    "* Control chart\n",
    "* Control limits\n",
    "* Correlation diagram\n",
    "* Correlogram\n",
    "* Cumulative flow diagram\n",
    "* CUSUM\n",
    "* Data point\n",
    "* Data and information visualization\n",
    "* DataScene\n",
    "* Defect concentration diagram\n",
    "* Dendrogram\n",
    "* Distribution-free control chart\n",
    "* Dot plot (bioinformatics)\n",
    "* Dot plot (statistics)\n",
    "* Double mass analysis\n",
    "* Dual-flashlight plot\n",
    "* Election apportionment diagram\n",
    "* Epidemic curve\n",
    "* Ergograph\n",
    "* Error bar\n",
    "* EWMA chart\n",
    "* Fan chart (statistics)\n",
    "* Fan chart (time series)\n",
    "* Forest plot\n",
    "* Freedman‚ÄìDiaconis rule\n",
    "* Functional boxplot\n",
    "* Funnel plot\n",
    "* Galbraith plot\n",
    "* Graph literacy\n",
    "* Histogram\n",
    "* Identity line\n",
    "* Lexis diagram\n",
    "* Line chart\n",
    "* Log‚Äìlog plot\n",
    "* [**Lorenz curve**](https://en.wikipedia.org/wiki/Lorenz_curve) ([*Courbe de Lorenz*](https://fr.wikipedia.org/wiki/Courbe_de_Lorenz))\n",
    "* Manhattan plot\n",
    "* Mosaic plot\n",
    "* Moving average\n",
    "* Multi-vari chart\n",
    "* Nelson rules\n",
    "* Normal probability plot\n",
    "* Np-chart\n",
    "* Outlier\n",
    "* P-chart\n",
    "* P‚ÄìP plot\n",
    "* Parallel coordinates\n",
    "* Pareto analysis\n",
    "* Pareto chart\n",
    "* Parity plot\n",
    "* Partial regression plot\n",
    "* Partial residual plot\n",
    "* Pictogram\n",
    "* Pie chart\n",
    "* William Playfair\n",
    "* Poincar√© plot\n",
    "* Population pyramid\n",
    "* Price-Jones curve\n",
    "* Probability plot correlation coefficient plot\n",
    "* Q‚ÄìQ plot\n",
    "* Radar chart\n",
    "* Rank abundance curve\n",
    "* Rankit\n",
    "* Regression control chart\n",
    "* Rug plot\n",
    "* Run chart\n",
    "* Scagnostics\n",
    "* Scatter plot\n",
    "* Scatterplot smoothing\n",
    "* Scree plot\n",
    "* Seasonal subseries plot\n",
    "* Self-similarity matrix\n",
    "* Semi-log plot\n",
    "* Sequence logo\n",
    "* Shewhart individuals control chart\n",
    "* Smoothing\n",
    "* Spaghetti plot\n",
    "* Spatial distribution\n",
    "* Statistics of the COVID-19 pandemic in Poland\n",
    "* Stem-and-leaf display\n",
    "* Streamgraph\n",
    "* Targeted projection pursuit\n",
    "* Temporal raster plot\n",
    "* Timeline\n",
    "* Treemapping\n",
    "* U-chart\n",
    "* UpSet Plot\n",
    "* V-optimal histograms\n",
    "* Venn diagram\n",
    "* Violin plot\n",
    "* Volcano plot (statistics)\n",
    "* Weibull chart\n",
    "* Western Electric rules\n",
    "* XÃÖ and R chart\n",
    "* XÃÖ and s chart\n",
    "* X-bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚¶ø [**Lorenz curve**](https://en.wikipedia.org/wiki/Lorenz_curve) ([*Courbe de Lorenz*](https://fr.wikipedia.org/wiki/Courbe_de_Lorenz))\n",
    "\n",
    "**Categories**: Economics curves ¬∑ Welfare economics ¬∑ Statistical charts and diagrams ¬∑ Income inequality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Contributeurs cl√©s**\n",
    "\n",
    "#### ‚¶ø [**Grothendieck**, Alexander](https://en.wikipedia.org/wiki/Alexander_Grothendieck) ([*Alexandre Grothendieck*](https://fr.wikipedia.org/wiki/Alexandre_Grothendieck))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

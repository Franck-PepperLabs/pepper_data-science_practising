{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Faire mieux qu'un dictionnaire de traductions, faire un index et glossaire !</mark>\n",
    "\n",
    "Récupérer tout ce que j'ai déjà enregistré dans :\n",
    "* mon journal\n",
    "* le journal de formation\n",
    "* les doc de projet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Maths for Machine learning : statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Dernières entrées\n",
    "\n",
    "#### ⦿ [**Student's t-test**](https://en.wikipedia.org/wiki/Student's_t-test) ([*Test de Student*](https://fr.wikipedia.org/wiki/Test_de_Student))\n",
    "\n",
    "#### ⦿ [**F-test of equality of variances**](https://en.wikipedia.org/wiki/F-test_of_equality_of_variances) ([*Test de Fisher d'égalité de deux variances*](https://fr.wikipedia.org/wiki/Test_de_Fisher_d'égalité_de_deux_variances))\n",
    "\n",
    "#### ⦿ [**Category:Statistical tests**](https://en.wikipedia.org/wiki/Category:Statistical_tests) ([*Catégorie:Test statistique*](https://fr.wikipedia.org/wiki/Catégorie:Test_statistique))\n",
    "\n",
    "#### ⦿ [**Normality test**](https://en.wikipedia.org/wiki/Normality_test) ([*Test de normalité*](https://fr.wikipedia.org/wiki/Test_de_normalité))\n",
    "\n",
    "#### ⦿ [**Omnibus test**](https://en.wikipedia.org/wiki/Omnibus_test) ([*Test Omnibus*]())\n",
    "\n",
    "#### ⦿ [**Category:Statistical deviation and dispersion**](https://en.wikipedia.org/wiki/Category:Statistical_deviation_and_dispersion) ([*Ecart et dispersion statistiques*]())\n",
    "\n",
    "#### ⦿ [**Category:Statistical ratios**](https://en.wikipedia.org/wiki/Category:Statistical_ratios) ([*Ratios statistiques*]())\n",
    "\n",
    "#### ⦿ [**Brown–Forsythe test**](https://en.wikipedia.org/wiki/Brown–Forsythe_test) ([**]())\n",
    "\n",
    "#### ⦿ [**Bartlett's test**](https://en.wikipedia.org/wiki/Bartlett%27s_test) ([*Test de Bartlett*](https://fr.wikipedia.org/wiki/Test_de_Bartlett))\n",
    "\n",
    "#### ⦿ [**Levene's test**](https://en.wikipedia.org/wiki/Levene's_test) ([*Test de Levene*](https://fr.wikipedia.org/wiki/Test_de_Levene))\n",
    "\n",
    "#### ⦿ [**Goldfeld–Quandt test**](https://en.wikipedia.org/wiki/Goldfeld–Quandt_test) ([*Test de Goldfeld et Quandt*](https://fr.wikipedia.org/wiki/Test_de_Goldfeld_et_Quandt))\n",
    "\n",
    "#### ⦿ [**Hartley's test**](https://en.wikipedia.org/wiki/Hartley's_test) ([**]())\n",
    "\n",
    "#### ⦿ [**Analysis of variance (ANOVA)**](https://en.wikipedia.org/wiki/Analysis_of_variance) ([*Analyse de la variance (ANOVA)*](https://fr.wikipedia.org/wiki/Analyse_de_la_variance))\n",
    "\n",
    "#### ⦿ [**Null hypothesis**](https://en.wikipedia.org/wiki/Null_hypothesis) ([*Hypothèse nulle*](https://fr.wikipedia.org/wiki/Hypothèse_nulle))\n",
    "\n",
    "$H_0$\n",
    "\n",
    "#### ⦿ [**Hypothesis**](https://en.wikipedia.org/wiki/Hypothesis) ([*Hypothèse*](https://fr.wikipedia.org/wiki/Hypothèse))\n",
    "\n",
    "#### ⦿ [**Statistical hypothesis testing**](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) ([*Test statistique*](https://fr.wikipedia.org/wiki/Test_statistique))\n",
    "\n",
    "#### ⦿ [**Category:Parametric statistics**](https://en.wikipedia.org/wiki/Category:Parametric_statistics) ([**]())\n",
    "\n",
    "#### ⦿ [**Parametric statistics**](https://en.wikipedia.org/wiki/Parametric_statistics) ([**]())\n",
    "\n",
    "#### ⦿ [**<i>t</i>-statistic**](https://en.wikipedia.org/wiki/T-statistic) ([**]())\n",
    "\n",
    "#### ⦿ [**<i>p</i>-value**](https://en.wikipedia.org/wiki/P-value) ([*Valeur p*](https://fr.wikipedia.org/wiki/Valeur_p))\n",
    "\n",
    "#### ⦿ [**Statistical significance**](https://en.wikipedia.org/wiki/Statistical_significance) ([*Signification statistique*](https://fr.wikipedia.org/wiki/Signification_statistique))\n",
    "\n",
    "\n",
    "#### ⦿ [**Category:Nonparametric statistics**](https://en.wikipedia.org/wiki/Category:Nonparametric_statistics) ([*Catégorie:Statistiques non paramétriques*](https://fr.wikipedia.org/wiki/Catégorie:Statistiques_non_paramétriques))\n",
    "\n",
    "#### ⦿ [****]() ([**]())\n",
    "\n",
    "#### ⦿ [****]() ([**]())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouvelles entrées à intégrer\n",
    "\n",
    "* *dépendance partielle*\n",
    "* **classifier** : *classifieur* (et non *classificateur*)\n",
    "* **feature** : *caractéristique* (et non *fonctionnalité*, ni *entité*)\n",
    "\n",
    "Toutes les références enregistrées dans les journaux et non encore classées\n",
    "\n",
    "Lien vers les fiches traduites quand elles l'ont été + les priorités de traduction.\n",
    "\n",
    "Sortir les inserts dans les cours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [**Kaniadakis statistics**](https://en.wikipedia.org/wiki/Kaniadakis_statistics) (*Statistique de Kaniadakis*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⦿ [**Goodness of fit**](https://en.wikipedia.org/wiki/Goodness_of_fit) ([*Qualité de l'ajustement*](https://fr.wikipedia.org/wiki/Qualité_de_l'ajustement))\n",
    "\n",
    "The **goodness of fit** of a **statistical model** describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model in question. Such measures can be used in **statistical hypothesis testing**, e.g. to **test for normality** of **residuals**, to test whether two samples are drawn from identical distributions (see **Kolmogorov–Smirnov** test), or whether outcome frequencies follow a specified distribution (see **Pearson's chi-square test**). In the **analysis of variance**, one of the components into which the variance is partitioned may be a **lack-of-fit sum of squares**.\n",
    "\n",
    "---\n",
    "\n",
    "La **qualité d'ajustement** d'un **modèle statistique** décrit dans quelle mesure il s'ajuste à un ensemble d'observations. Les mesures de la qualité de l'ajustement résument généralement l'écart entre les valeurs observées et les valeurs attendues dans le cadre du modèle en question. Ces mesures peuvent être utilisées dans les **tests d'hypothèses statistiques**, par ex. pour **tester la normalité** des **résidus**, pour tester si deux échantillons sont tirés de distributions identiques (voir **test de Kolmogorov-Smirnov**), ou si les fréquences des résultats suivent une distribution spécifiée (voir **Pearson's test du chi carré**). Dans l'**analyse de la variance**, l'une des composantes dans lesquelles la variance est répartie peut être une **somme des carrés sans ajustement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⦿ [**Studentized residual**](https://en.wikipedia.org/wiki/Studentized_residual) (*Résidu studentisé*)\n",
    "\n",
    "In statistics, a **studentized residual** is the quotient resulting from the division of a **residual** by an **estimate** of its **standard deviation**. It is a form of a **Student's t-statistic**, with the estimate of error varying between points.\n",
    "\n",
    "This is an important technique in the detection of **outliers**. It is among several named in honor of **William Sealey Gosset**, who wrote under the pseudonym *Student*. Dividing a statistic by a **sample standard deviation** is called *studentizing*, in analogy with **standardizing** and **normalizing**.\n",
    "\n",
    "---\n",
    "\n",
    "En statistique, un **résidu studentisé** est le quotient résultant de la division d'un **résidu** par une **estimation** de son **écart type**. Il s'agit d'une forme de **statistique t de Student**, l'estimation de l'erreur variant d'un point à l'autre.\n",
    "\n",
    "Il s'agit d'une technique importante dans la détection des **valeurs aberrantes**. Il fait partie de plusieurs nommés en l'honneur de **William Sealey Gosset**, qui a écrit sous le pseudonyme *Student*. La division d'une statistique par un **écart-type d'échantillon** s'appelle *studentizing*, par analogie avec **standardizing** et **normalizing**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⦿ [**Gauss–Markov theorem**](https://en.wikipedia.org/wiki/Gauss-Markov_theorem) ([*Théorème de Gauss-Markov*](https://fr.wikipedia.org/wiki/Théorème_de_Gauss-Markov))\n",
    "\n",
    "In **statistics**, the **Gauss–Markov theorem** (or simply **Gauss theorem** for some authors)[1] states that the **ordinary least squares** (OLS) estimator has the lowest **sampling variance** within the **class** of **linear unbiased estimators**, if the **errors** in the **linear regression model** are **uncorrelated**, have **equal variances** and expectation value of zero.[2] The errors do not need to be **normal**, nor do they need to be **independent and identically distributed** (only **uncorrelated** with mean zero and **homoscedastic** with finite variance). The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the **James–Stein estimator** (which also drops linearity), **ridge regression**, or simply any **degenerate** estimator.\n",
    "\n",
    "---\n",
    "\n",
    "En **statistiques**, le **théorème de Gauss–Markov** (ou simplement le **théorème de Gauss** pour certains auteurs)[1] stipule que l'estimateur des **moindres carrés ordinaires** (OLS) a le plus basse **variance d'échantillonnage** dans la **classe** des **estimateurs linéaires sans biais**, si les **erreurs** du **modèle de régression linéaire** sont **non corrélées**, ont des **variances égales** et valeur d'espérance de zéro.[2] Les erreurs n'ont pas besoin d'être **normales**, ni d'être **indépendantes et distribuées de manière identique** (seulement **non corrélées** avec une moyenne nulle et **homoscédastiques** avec une variance finie). L'exigence que l'estimateur soit sans biais ne peut pas être abandonnée, car il existe des estimateurs biaisés avec une variance plus faible. Voir, par exemple, l'**estimateur James-Stein** (qui supprime également la linéarité), la **régression ridge** ou simplement tout estimateur **dégénéré**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⦿ [**Homoscedasticity and heteroscedasticity**](https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity)\n",
    "\n",
    "In **statistics**, a **sequence** (or a vector) of **random variables** is **homoscedastic** if all its random variables have the same finite **variance**. This is also known as **homogeneity of variance**. The complementary notion is called **heteroscedasticity**. The spellings *homoskedasticity* and *heteroskedasticity* are also frequently used.[1][2][3]\n",
    "\n",
    "Assuming a variable is homoscedastic when in reality it is heteroscedastic results in unbiased but inefficient point estimates and in biased estimates of standard errors, and may result in overestimating the **goodness of fit** as measured by the **Pearson coefficient**.\n",
    "\n",
    "The existence of heteroscedasticity is a major concern in **regression analysis** and the **analysis of variance**, as it invalidates **statistical tests of significance** that assume that the **modelling errors** all have the same variance. While the **ordinary least squares** estimator is still unbiased in the presence of heteroscedasticity, it is inefficient and **generalized least squares** should be used instead.[4][5]\n",
    "\n",
    "Because heteroscedasticity concerns **expectations** of the second **moment** of the errors, its presence is referred to as **misspecification** of the second order.[6]\n",
    "\n",
    "The **econometrician** **Robert Engle** was awarded the 2003 **Nobel Memorial Prize for Economics** for his studies on **regression analysis** in the presence of heteroscedasticity, which led to his formulation of the **autoregressive conditional heteroscedasticity** (ARCH) modeling technique.[7]\n",
    "\n",
    "---\n",
    "\n",
    "En **statistiques**, une **séquence** (ou un vecteur) de **variables aléatoires** est **homoscédastique** si toutes ses variables aléatoires ont la même **variance** finie. Ceci est également connu sous le nom d'**homogénéité de la variance**. La notion complémentaire est appelée **hétéroscédasticité**. Les orthographes *homoskedasticity* et *heteroskedasticity* sont également fréquemment utilisées.[1][2][3]\n",
    "\n",
    "Supposer qu'une variable est homoscédastique alors qu'en réalité elle est hétéroscédastique donne des estimations ponctuelles non biaisées mais inefficaces et des estimations biaisées des erreurs types, et peut entraîner une surestimation de la **qualité de l'ajustement** telle que mesurée par le **coefficient de Pearson**.\n",
    "\n",
    "L'existence d'hétéroscédasticité est une préoccupation majeure dans l'**analyse de régression** et l'**analyse de variance**, car elle invalide les **tests statistiques de signification** qui supposent que les **erreurs de modélisation** ont toutes la même variance. Bien que l'estimateur des **moindres carrés ordinaires** soit toujours sans biais en présence d'hétéroscédasticité, il est inefficace et les **moindres carrés généralisés** doivent être utilisés à la place.\n",
    "\n",
    "Comme l'hétéroscédasticité concerne les **attentes** du deuxième **moment** des erreurs, sa présence est appelée **spécification erronée** du second ordre.[6]\n",
    "\n",
    "L'**économètre** **Robert Engle** a reçu le **prix Nobel d'économie** en 2003 pour ses études sur l'**analyse de régression** en présence d'hétéroscédasticité, ce qui l'a conduit à la formulation de la technique de modélisation **hétéroscédasticité conditionnelle autorégressive** (ARCH).[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [⚓](https://en.wikipedia.org/wiki/Category:Statistics) [**Statistics**](https://en.wikipedia.org/wiki/Statistics) ([*Statistique*](https://fr.wikipedia.org/wiki/Statistique))\n",
    "\n",
    "**Outline 👀** [**Statistics**](https://en.wikipedia.org/wiki/Outline_of_statistics) • \n",
    "**Index 💽** [**Statistics**](https://en.wikipedia.org/wiki/List_of_statistics_articles) • **Glossary** [**Probability and statistics**](https://en.wikipedia.org/wiki/Glossary_of_probability_and_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚓ [**Descriptive statistics**](https://en.wikipedia.org/wiki/Descriptive_statistics) ([*Statistique descriptive*](https://fr.wikipedia.org/wiki/Statistique_descriptive))\n",
    "\n",
    "**Outline 👀** [**Descriptive statistics**](https://en.wikipedia.org/wiki/Category:Descriptive_statistics)\n",
    "\n",
    "**Parent categories   [⚓]**: Statistical analysis · Summary statistics\n",
    "\n",
    "**Child categories  [⚓]**:\n",
    "* ⚓ Exploratory data analysis (14 P)\n",
    "* ⚓ Contingency table (2 C, 3 P)\n",
    "* * ⚓ Statistical tests for contingency tables (9 P)\n",
    "* * ⚓ Summary statistics for contingency tables (28 P)\n",
    "* ⚓ Statistical deviation and dispersion (5 C, 83 P)\n",
    "* * ⚓ Measurement of biodiversity (21 P)\n",
    "* * ⚓ Point estimation performance (12 P)\n",
    "* * ⚓ Scale statistics (8 P)\n",
    "* * ⚓ Signal processing metrics (5 P)\n",
    "* * ⚓ Variance reduction (8 P)\n",
    "* ⚓ Statistical distance (2 C, 37 P)\n",
    "* * ⚓ Clustering criteria (20 P)\n",
    "* * ⚓ F-divergences (5 P)\n",
    "* ⚓ Statistical ratios (70 P)\n",
    "* ⚓ Statistical indicators (4 C, 2 P)\n",
    "* ⚓ Statistical charts and diagrams (1 C, 116 P)\n",
    "* * ⚓ Financial charts (11 P)\n",
    "\n",
    "**Corpus**:\n",
    "* [**Continuous data**](https://en.wikipedia.org/wiki/Probability_distribution#Absolutely_continuous_probability_distribution)\n",
    "* * **Center**: Mean (Arithmetic · Cubic · Generalized/power · Geometric · Harmonic · Heinz · Lehmer) · Median · Mode\n",
    "* * **Dispersion**: Average absolute deviation · Coefficient of variation · Interquartile range · Percentile · Range · Standard deviation · Variance\n",
    "* * **Shape**: Central limit theorem · Moments (Kurtosis · L-moments · Skewness)\n",
    "* **Count data**: Index of dispersion\n",
    "* **Summary tables**: Contingency table · Frequency distribution · Grouped data\n",
    "* **Dependence**: Partial correlation · Pearson product-moment correlation · Rank correlation (Kendall's τ · Spearman's ρ) · Scatter plot\n",
    "* **Graphics**: Bar chart · Biplot · Box plot · Control chart · Correlogram · Fan chart · Forest plot · Histogram · Pie chart · Q–Q plot · Radar chart · Run chart · Scatter plot · Stem-and-leaf display · Violin plot\n",
    "\n",
    "\n",
    "**Index 💽**:\n",
    "* ⚓ [**Descriptive statistics**](https://en.wikipedia.org/wiki/Descriptive_statistics) ([*Statistique descriptive*](https://fr.wikipedia.org/wiki/Statistique_descriptive))\n",
    "* [**Data reporting**](https://en.wikipedia.org/wiki/Data_reporting) (*???*)\n",
    "* [**Descriptive research**](https://en.wikipedia.org/wiki/Descriptive_research) (*???*)\n",
    "* [**Geometric median**](https://en.wikipedia.org/wiki/Geometric_median) (*???*)\n",
    "* [**Grand mean (*pooled mean*)**](https://en.wikipedia.org/wiki/Grand_mean) (*???*)\n",
    "* [**Grouped data**](https://en.wikipedia.org/wiki/Grouped_data) (*???*)\n",
    "* [**Mean log deviation (MLD)**](https://en.wikipedia.org/wiki/Mean_log_deviation) (*???*)\n",
    "* [**Spatial descriptive statistics**](https://en.wikipedia.org/wiki/Spatial_descriptive_statistics) (*???*)\n",
    "* [**Strictly standardized mean difference (SSMD)**](https://en.wikipedia.org/wiki/Strictly_standardized_mean_difference) (*???*)\n",
    "* [**Wide and narrow data**](https://en.wikipedia.org/wiki/Wide_and_narrow_data) (*???*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Exploratory_data_analysis) [**Exploratory data analysis**](https://en.wikipedia.org/wiki/Exploratory_data_analysis) (14 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Exploratory data analysis\n",
    "* Data reduction\n",
    "* Exploratory causal analysis\n",
    "* Table diagonalization\n",
    "* Configural frequency analysis\n",
    "* Grand Tour (data visualisation)\n",
    "* Median polish\n",
    "* Midhinge\n",
    "* Projection pursuit\n",
    "* Stem-and-leaf display\n",
    "* TinkerPlots\n",
    "* Trimean\n",
    "* John Tukey\n",
    "* Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Contingency_table) [**Contingency table**](https://en.wikipedia.org/wiki/Contingency_table) (2 C, 3 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Contingency table**](https://en.wikipedia.org/wiki/Contingency_table) ([Tableau de contingence](https://fr.wikipedia.org/wiki/Tableau_de_contingence))\n",
    "* Iterative proportional fitting\n",
    "* NM-method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_tests_for_contingency_tables) **Statistical tests for contingency tables** (9 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Barnard's test\n",
    "* Boschloo's test\n",
    "* [**Chi-squared test**](https://en.wikipedia.org/wiki/Chi-squared_test) ([Test du χ²](https://fr.wikipedia.org/wiki/Test_du_χ²))\n",
    "* Cochran–Armitage test for trend\n",
    "* Cochran–Mantel–Haenszel statistics\n",
    "* Fisher's exact test\n",
    "* G-test\n",
    "* Pearson's chi-squared test\n",
    "* Yates's correction for continuity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [⚓](https://en.wikipedia.org/wiki/Category:Summary_statistics_for_contingency_tables) **Summary statistics for contingency tables** (28 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cochran–Mantel–Haenszel statistics\n",
    "* Coefficient of colligation\n",
    "* Cohen's kappa\n",
    "* Cramér's V\n",
    "* Diagnostic odds ratio\n",
    "* F-score\n",
    "* False discovery rate\n",
    "* Fleiss' kappa\n",
    "* Goodman and Kruskal's gamma\n",
    "* Goodman and Kruskal's lambda\n",
    "* Index of coincidence\n",
    "* Likelihood ratios in diagnostic testing\n",
    "* McNemar's test\n",
    "* Odds ratio\n",
    "* P4-metric\n",
    "* Phi coefficient\n",
    "* Pointwise mutual information\n",
    "* Polychoric correlation\n",
    "* Positive and negative predictive values\n",
    "* Pre- and post-test probability\n",
    "* Rand index\n",
    "* Receiver operating characteristic\n",
    "* Sample odds ratio\n",
    "* Total operating characteristic\n",
    "* Tschuprow's T\n",
    "* Uncertainty coefficient\n",
    "* Variation of information\n",
    "* Yule's Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_deviation_and_dispersion) **Statistical deviation and dispersion** (5 C, 83 P)\n",
    "\n",
    "* ⚓ Measurement of biodiversity (21 P)\n",
    "* ⚓ Point estimation performance (12 P)\n",
    "* ⚓ Scale statistics (8 P)\n",
    "* ⚓ Signal processing metrics (5 P)\n",
    "* ⚓ Variance reduction (8 P)\n",
    "* Average absolute deviation\n",
    "* Algorithms for calculating variance\n",
    "* Berkson error model\n",
    "* Bessel's correction\n",
    "* Bhattacharyya distance\n",
    "* Bollinger Bands\n",
    "* Central moment\n",
    "* Circular standard deviation\n",
    "* Circular variance\n",
    "* Clustered standard errors\n",
    "* Coefficient of variation\n",
    "* Cokurtosis\n",
    "* Common-method variance\n",
    "* Conditional variance\n",
    "* Cornish–Fisher expansion\n",
    "* Cosmic variance\n",
    "* Deviance (statistics)\n",
    "* Deviation (statistics)\n",
    "* Engineering tolerance\n",
    "* Errors and residuals\n",
    "* Estimation of covariance matrices\n",
    "* F-test of equality of variances\n",
    "* Fano factor\n",
    "* Full width at half maximum\n",
    "* Goldfeld–Quandt test\n",
    "* Greenwood statistic\n",
    "* Homoscedasticity and heteroscedasticity\n",
    "* Index of dispersion\n",
    "* Kurtosis\n",
    "* Law of total variance\n",
    "* Margin of error\n",
    "* Market risk\n",
    "* McKay's approximation for the coefficient of variation\n",
    "* Mean absolute difference\n",
    "* Mean absolute error\n",
    "* Mean absolute percentage error\n",
    "* Mean absolute scaled error\n",
    "* Mean square quantization error\n",
    "* Mean squared displacement\n",
    "* Mean squared error\n",
    "* Mean squared prediction error\n",
    "* Medcouple\n",
    "* Median absolute deviation\n",
    "* Minimum mean square error\n",
    "* MINQUE\n",
    "* Negentropy\n",
    "* Option on realized variance\n",
    "* Option on realized volatility\n",
    "* Otsu's method\n",
    "* Pooled variance\n",
    "* Popoviciu's inequality on variances\n",
    "* Population variance\n",
    "* Precision (statistics)\n",
    "* Probable error\n",
    "* Propagation of uncertainty\n",
    "* Qualitative variation\n",
    "* Quartile coefficient of dispersion\n",
    "* Quasi-variance\n",
    "* Range (statistics)\n",
    "* Ratio estimator\n",
    "* Reduced chi-squared statistic\n",
    "* Rescaled range\n",
    "* Robust measures of scale\n",
    "* Root mean square\n",
    "* Root-mean-square deviation\n",
    "* Root-mean-square deviation of atomic positions\n",
    "* Skewness\n",
    "* Skewness risk\n",
    "* Squared deviations from the mean\n",
    "* Standard deviation\n",
    "* Standard error\n",
    "* Standardized moment\n",
    "* Statistical dispersion\n",
    "* Studentized residual\n",
    "* Symmetric mean absolute percentage error\n",
    "* Taylor's law\n",
    "* Tracking signal\n",
    "* True variance\n",
    "* Variance\n",
    "* Variance inflation factor\n",
    "* Variation ratio\n",
    "* Variogram\n",
    "* WMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_distance) [**Statistical distance**](https://en.wikipedia.org/wiki/Statistical_distance) (2 C, 37 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [⚓ _](https://en.wikipedia.org/wiki/Category:Statistical_distance) (37 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. [**Statistical distance**](https://en.wikipedia.org/wiki/Statistical_distance) ([*Distance statistique*](https://fr.wikipedia.org/wiki/Distance_statistique))\n",
    "2. Bhattacharyya angle\n",
    "3. Bhattacharyya distance\n",
    "4. Bregman divergence\n",
    "5. Canonical divergence\n",
    "6. Chentsov's theorem\n",
    "7. Circular error probable\n",
    "8. Cook's distance\n",
    "9. Cramér–von Mises criterion\n",
    "10. Deviation (statistics)\n",
    "11. Discrepancy (statistics)\n",
    "12. DiShIn\n",
    "13. Distance correlation\n",
    "14. Divergence (statistics)\n",
    "15. Energy distance\n",
    "16. Earth mover's distance\n",
    "17. Fisher information metric\n",
    "18. Hellinger distance\n",
    "19. Information distance\n",
    "20. Jensen–Shannon divergence\n",
    "21. Kendall tau distance\n",
    "22. Kolmogorov–Smirnov test\n",
    "23. Mahalanobis distance\n",
    "24. Minimum-distance estimation\n",
    "25. Normalized compression distance\n",
    "26. Normalized Google distance\n",
    "27. Optimal matching\n",
    "28. Pitman closeness criterion\n",
    "29. Process Window Index\n",
    "30. Second-order co-occurrence pointwise mutual information\n",
    "31. Semantic similarity\n",
    "32. Signal-to-noise statistic\n",
    "33. Similarity measure\n",
    "34. Squared Euclidean distance\n",
    "35. Stein discrepancy\n",
    "36. Stein's method\n",
    "37. Wasserstein metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [⚓](https://en.wikipedia.org/wiki/Category:Clustering_criteria) **Clustering criteria** (20 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted mutual information\n",
    "* Automatic clustering algorithms\n",
    "* Balanced clustering\n",
    "* Dasgupta's objective\n",
    "* Davies–Bouldin index\n",
    "* Determining the number of clusters in a data set\n",
    "* Dunn index\n",
    "* Elbow method (clustering)\n",
    "* F-score\n",
    "* Fowlkes–Mallows index\n",
    "* Hopkins statistic\n",
    "* Jaccard index\n",
    "* MinHash\n",
    "* P4-metric\n",
    "* Rand index\n",
    "* Silhouette (clustering)\n",
    "* SimHash\n",
    "* Similarity measure\n",
    "* Simple matching coefficient\n",
    "* Variation of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [⚓](https://en.wikipedia.org/wiki/Category:F-divergences) [**F-divergence**](https://en.wikipedia.org/wiki/F-divergence) (5 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**<i>f</i>-divergence**](https://en.wikipedia.org/wiki/F-divergence)\n",
    "* [**Divergence (statistics)**](https://en.wikipedia.org/wiki/Divergence_(statistics))\n",
    "* [**Hellinger distance**](https://en.wikipedia.org/wiki/Hellinger_distance)\n",
    "* [**Kullback–Leibler divergence**](https://en.wikipedia.org/wiki/Kullback-Leibler_divergence)\n",
    "* [**Total variation distance of probability measures**](https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_ratios) **Statistical ratios** (70 P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Attack rate\n",
    "* Bayes factor\n",
    "* Beta (finance)\n",
    "* [**Coefficient of determination**](https://en.wikipedia.org/wiki/Coefficient_of_determination) ([*Coefficient de détermination*](https://fr.wikipedia.org/wiki/Coefficient_de_détermination))\n",
    "* Coefficient of variation\n",
    "* Conditional probability\n",
    "* Correlation ratio\n",
    "* Cramér's V\n",
    "* Diagnostic odds ratio\n",
    "* Experimental event rate\n",
    "* F-test\n",
    "* F-test of equality of variances\n",
    "* F-score\n",
    "* Failure rate\n",
    "* False positive rate\n",
    "* Fano factor\n",
    "* Fraction of variance unexplained\n",
    "* Goodman and Kruskal's lambda\n",
    "* Ground ball/fly ball ratio\n",
    "* Hansen–Jagannathan bound\n",
    "* Hazard ratio\n",
    "* Index of dispersion\n",
    "* Information gain ratio\n",
    "* Information ratio\n",
    "* Ka/Ks ratio\n",
    "* Lexis ratio\n",
    "* Likelihood-ratio test\n",
    "* Wilks' theorem\n",
    "* Mills ratio\n",
    "* Normalization (statistics)\n",
    "* Odds\n",
    "* Outliers ratio\n",
    "* P4-metric\n",
    "* [**Pearson correlation coefficient**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "* Phi coefficient\n",
    "* Polynomial and rational function modeling\n",
    "* Positive and negative predictive values\n",
    "* Prevalence\n",
    "* Prevalence effect\n",
    "* Pseudo-R-squared\n",
    "* Quadrant count ratio\n",
    "* Quartile coefficient of dispersion\n",
    "* Ratio distribution\n",
    "* Ratio estimator\n",
    "* Relative change and difference\n",
    "* Relative index of inequality\n",
    "* Relative risk\n",
    "* Relative risk reduction\n",
    "* Rescaled range\n",
    "* Response-rate ratio\n",
    "* Sampling fraction\n",
    "* Sensitivity and specificity\n",
    "* Sharpe ratio\n",
    "* Signal-to-noise ratio\n",
    "* Signal-to-noise statistic\n",
    "* Sortino ratio\n",
    "* Standard score\n",
    "* Standardized moment\n",
    "* Standardized mortality ratio\n",
    "* Strikeout-to-walk ratio\n",
    "* Studentization\n",
    "* Studentized range\n",
    "* Studentized residual\n",
    "* Survival rate\n",
    "* T-statistic\n",
    "* Treynor ratio\n",
    "* Uncertainty coefficient\n",
    "* Upside potential ratio\n",
    "* Variance inflation factor\n",
    "* Variation ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_indicators) **Statistical indicators** (4 C, 2 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚓ **_** (2 P)\n",
    "\n",
    "* [**Index (statistics)**](https://en.wikipedia.org/wiki/Index_(statistics))\n",
    "* [**Stonewall Workplace Equality Index**](https://en.wikipedia.org/wiki/Stonewall_Workplace_Equality_Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚓ **Concentration indicators** (1 C, 36 P)\n",
    "\n",
    "* [**Gini coefficient**](https://en.wikipedia.org/wiki/Gini_coefficient)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚓ **Correlation indicators** (5 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Correlation coefficient**](https://en.wikipedia.org/wiki/Correlation_coefficient) (*Coefficient de corrélation*)\n",
    "* [**Coefficient of multiple correlation**](https://en.wikipedia.org/wiki/Coefficient_of_multiple_correlation)\n",
    "* [**Pearson (product-moment) correlation coefficient (P(PM)CC)**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "* [**Point-biserial correlation coefficient**](https://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient)\n",
    "* [**Coefficient of determination ($R^2$)**](https://en.wikipedia.org/wiki/Coefficient_of_determination) ([*Coefficient de détermination*](https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ⦿ [**Correlation coefficient**](https://en.wikipedia.org/wiki/Correlation_coefficient) (*Coefficient de corrélation*)\n",
    "\n",
    "A **correlation coefficient** is a **numerical measure** of some type of **correlation**, meaning a statistical relationship between two **variables**.[a] The variables may be two **columns** of a given **data** set of observations, often called a **sample**, or two components of a **multivariate random variable** with a known distribution.[citation needed]\n",
    "\n",
    "Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics. They all assume values in the range from −1 to +1, where ±1 indicates the strongest possible agreement and 0 the strongest possible disagreement.[2] As tools of analysis, correlation coefficients present certain problems, including the propensity of some types to be distorted by **outliers** and the possibility of incorrectly being used to infer a **causal relationship** between the variables (for more, see **Correlation does not imply causation**).[3]\n",
    "\n",
    "---\n",
    "\n",
    "Un **coefficient de corrélation** est une **mesure numérique** d'un certain type de **corrélation**, c'est-à-dire une relation statistique entre deux **variables**.[a] Les variables peuvent être deux **colonnes**. d'un **jeu de données** d'observations donné, souvent appelé un **échantillon**, ou de deux composants d'une **variable aléatoire multivariée** avec une distribution connue. [citation nécessaire]\n",
    "\n",
    "Il existe plusieurs types de coefficients de corrélation, chacun avec sa propre définition et sa propre gamme d'applications et de caractéristiques. Ils prennent tous des valeurs comprises entre −1 et +1, où ±1 indique l'accord le plus fort possible et 0 le désaccord le plus fort possible.[2] En tant qu'outils d'analyse, les coefficients de corrélation présentent certains problèmes, notamment la propension de certains types à être faussés par des **valeurs aberrantes** et la possibilité d'être utilisés à tort pour déduire une **relation causale** entre les variables (pour en savoir plus, voir **Corrélation n'implique pas causalité**).[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚓ **Demographics indicators** (1 C, 8 P)\n",
    "\n",
    "\n",
    "* ⚓ International quality of life rankings (2 C, 15 P)\n",
    "* Carrying capacity\n",
    "* EU Social Progress Index\n",
    "* Net migration rate\n",
    "* Population ageing\n",
    "* Rate of natural increase\n",
    "* Survival rate\n",
    "* World Development Indicators\n",
    "* World Governance Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚓ **Social statistics indicators** (3 P)\n",
    "\n",
    "* Clearance rate\n",
    "* Good Country Index\n",
    "* Index of Economic Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [⚓](https://en.wikipedia.org/wiki/Category:Statistical_charts_and_diagrams) **Statistical charts and diagrams** (1 C, 116 P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [⚓](https://en.wikipedia.org/wiki/Category:Statistical_charts_and_diagrams) **Statistical charts and diagrams**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List of graphical methods\n",
    "* Statistical graphics\n",
    "* Andrews plot\n",
    "* Anscombe's quartet\n",
    "* Area chart\n",
    "* Bagplot\n",
    "* Bar chart\n",
    "* Barber–Johnson diagram\n",
    "* Biplot\n",
    "* Bland–Altman plot\n",
    "* Bow-tie diagram\n",
    "* Box plot\n",
    "* C-chart\n",
    "* Carpet plot\n",
    "* Cartogram\n",
    "* Chernoff face\n",
    "* Chord diagram (information visualization)\n",
    "* Choropleth map\n",
    "* Circular distribution\n",
    "* Composite bar chart\n",
    "* Contour boxplot\n",
    "* Control chart\n",
    "* Control limits\n",
    "* Correlation diagram\n",
    "* Correlogram\n",
    "* Cumulative flow diagram\n",
    "* CUSUM\n",
    "* Data point\n",
    "* Data and information visualization\n",
    "* DataScene\n",
    "* Defect concentration diagram\n",
    "* Dendrogram\n",
    "* Distribution-free control chart\n",
    "* Dot plot (bioinformatics)\n",
    "* Dot plot (statistics)\n",
    "* Double mass analysis\n",
    "* Dual-flashlight plot\n",
    "* Election apportionment diagram\n",
    "* Epidemic curve\n",
    "* Ergograph\n",
    "* Error bar\n",
    "* EWMA chart\n",
    "* Fan chart (statistics)\n",
    "* Fan chart (time series)\n",
    "* Forest plot\n",
    "* Freedman–Diaconis rule\n",
    "* Functional boxplot\n",
    "* Funnel plot\n",
    "* Galbraith plot\n",
    "* Graph literacy\n",
    "* Histogram\n",
    "* Identity line\n",
    "* Lexis diagram\n",
    "* Line chart\n",
    "* Log–log plot\n",
    "* [**Lorenz curve**](https://en.wikipedia.org/wiki/Lorenz_curve) ([*Courbe de Lorenz*](https://fr.wikipedia.org/wiki/Courbe_de_Lorenz))\n",
    "* Manhattan plot\n",
    "* Mosaic plot\n",
    "* Moving average\n",
    "* Multi-vari chart\n",
    "* Nelson rules\n",
    "* Normal probability plot\n",
    "* Np-chart\n",
    "* Outlier\n",
    "* P-chart\n",
    "* P–P plot\n",
    "* Parallel coordinates\n",
    "* Pareto analysis\n",
    "* Pareto chart\n",
    "* Parity plot\n",
    "* Partial regression plot\n",
    "* Partial residual plot\n",
    "* Pictogram\n",
    "* Pie chart\n",
    "* William Playfair\n",
    "* Poincaré plot\n",
    "* Population pyramid\n",
    "* Price-Jones curve\n",
    "* Probability plot correlation coefficient plot\n",
    "* Q–Q plot\n",
    "* Radar chart\n",
    "* Rank abundance curve\n",
    "* Rankit\n",
    "* Regression control chart\n",
    "* Rug plot\n",
    "* Run chart\n",
    "* Scagnostics\n",
    "* Scatter plot\n",
    "* Scatterplot smoothing\n",
    "* Scree plot\n",
    "* Seasonal subseries plot\n",
    "* Self-similarity matrix\n",
    "* Semi-log plot\n",
    "* Sequence logo\n",
    "* Shewhart individuals control chart\n",
    "* Smoothing\n",
    "* Spaghetti plot\n",
    "* Spatial distribution\n",
    "* Statistics of the COVID-19 pandemic in Poland\n",
    "* Stem-and-leaf display\n",
    "* Streamgraph\n",
    "* Targeted projection pursuit\n",
    "* Temporal raster plot\n",
    "* Timeline\n",
    "* Treemapping\n",
    "* U-chart\n",
    "* UpSet Plot\n",
    "* V-optimal histograms\n",
    "* Venn diagram\n",
    "* Violin plot\n",
    "* Volcano plot (statistics)\n",
    "* Weibull chart\n",
    "* Western Electric rules\n",
    "* X̅ and R chart\n",
    "* X̅ and s chart\n",
    "* X-bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⦿ [**Lorenz curve**](https://en.wikipedia.org/wiki/Lorenz_curve) ([*Courbe de Lorenz*](https://fr.wikipedia.org/wiki/Courbe_de_Lorenz))\n",
    "\n",
    "**Categories**: Economics curves · Welfare economics · Statistical charts and diagrams · Income inequality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Contributeurs clés**\n",
    "\n",
    "#### ⦿ [**Grothendieck**, Alexander](https://en.wikipedia.org/wiki/Alexander_Grothendieck) ([*Alexandre Grothendieck*](https://fr.wikipedia.org/wiki/Alexandre_Grothendieck))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

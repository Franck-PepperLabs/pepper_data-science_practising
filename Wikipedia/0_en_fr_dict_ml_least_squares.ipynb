{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Maths for Machine learning : least squares**\n",
    "\n",
    "At the crossroads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [⚓](https://en.wikipedia.org/wiki/Category:Least_squares) [**Least squares**](https://en.wikipedia.org/wiki/Least_squares)<br/>([*Moindres carrés*](https://fr.wikipedia.org/wiki/Méthode_des_moindres_carrés))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ☔ Analysis of variance\n",
    "* ☔ Numerical linear algebra\n",
    "* ☔ Optimization algorithms and methods\n",
    "* Least squares\n",
    "* Coefficient of determination\n",
    "* Constrained least squares\n",
    "* Discrete least squares meshless method\n",
    "* Errors-in-variables models\n",
    "* Explained sum of squares\n",
    "* Fraction of variance unexplained\n",
    "* Gauss–Newton algorithm\n",
    "* Generalized least squares\n",
    "* Generated regressor\n",
    "* Helmert–Wolf blocking\n",
    "* Iteratively reweighted least squares\n",
    "* Lack-of-fit sum of squares\n",
    "* Least absolute deviations\n",
    "* Least-squares adjustment\n",
    "* Least-squares function approximation\n",
    "* Least-squares spectral analysis\n",
    "* Least-squares support vector machine\n",
    "* Levenberg–Marquardt algorithm\n",
    "* Linear least squares\n",
    "* Mean squared error\n",
    "* Moment matrix\n",
    "* Moving least squares\n",
    "* Non-linear least squares\n",
    "* Non-negative least squares\n",
    "* Numerical methods for linear least squares\n",
    "* Numerical smoothing and differentiation\n",
    "* Ordinary least squares\n",
    "* Partial least squares path modeling\n",
    "* Partial least squares regression\n",
    "* Partition of sums of squares\n",
    "* Powell's dog leg method\n",
    "* Proofs involving ordinary least squares\n",
    "* Regularized least squares\n",
    "* Residual sum of squares\n",
    "* Rietveld refinement\n",
    "* Total least squares\n",
    "* Total sum of squares\n",
    "* Weighted least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [☔](https://en.wikipedia.org/wiki/Category:Analysis_of_variance) [**Analysis of variance (ANOVA)**](https://en.wikipedia.org/wiki/Analysis_of_variance)<br/>([*Analyse de la variance (ANOVA)*](https://fr.wikipedia.org/wiki/Analyse_de_la_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ⚓ Least squares (39 P)\n",
    "* Analysis of variance\n",
    "* Permutational analysis of variance\n",
    "* Scheirer–Ray–Hare test\n",
    "* Analysis of covariance\n",
    "* Analysis of molecular variance\n",
    "* Analysis of rhythmic variance\n",
    "* ANOVA gauge R&R\n",
    "* ANOVA on ranks\n",
    "* ANOVA–simultaneous component analysis\n",
    "* Arellano–Bond estimator\n",
    "* Association scheme\n",
    "* Bartlett's test\n",
    "* Between-group design\n",
    "* Bose–Mesner algebra\n",
    "* Bühlmann model\n",
    "* Completely randomized design\n",
    "* Confounding\n",
    "* Contrast (statistics)\n",
    "* Expected mean squares\n",
    "* F-distribution\n",
    "* F-test\n",
    "* False positive rate\n",
    "* Fixed effects model\n",
    "* Friedman test\n",
    "* Generalized linear mixed model\n",
    "* Generalized randomized block design\n",
    "* Growth curve (statistics)\n",
    "* Hartley's test\n",
    "* Interaction (statistics)\n",
    "* Kaiser–Meyer–Olkin test\n",
    "* Kruskal–Wallis one-way analysis of variance\n",
    "* Lack-of-fit sum of squares\n",
    "* Least-squares spectral analysis\n",
    "* Levene's test\n",
    "* Main effect\n",
    "* Multivariate analysis of covariance\n",
    "* Mauchly's sphericity test\n",
    "* Mixed model\n",
    "* Mixed-design analysis of variance\n",
    "* Multilevel model\n",
    "* Multilevel regression with poststratification\n",
    "* Multiple abstract variance analysis\n",
    "* Multivariate analysis of variance\n",
    "* One-way analysis of variance\n",
    "* Partition of sums of squares\n",
    "* Pooled variance\n",
    "* Principle of marginality\n",
    "* Random effects model\n",
    "* Repeated measures design\n",
    "* Restricted randomization\n",
    "* Standardized mean of a contrast variable\n",
    "* Squared deviations from the mean\n",
    "* Squared ranks test\n",
    "* Tukey's range test\n",
    "* Tukey's test of additivity\n",
    "* Two-way analysis of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [☔](https://en.wikipedia.org/wiki/Category:Numerical_linear_algebra) [**Numerical linear algebra**](https://en.wikipedia.org/wiki/Numerical_linear_algebra)<br/>(*Algèbre linéaire numérique*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ⚓ Domain decomposition methods (15 P)\n",
    "* ⚓ Exchange algorithms (10 P)\n",
    "* ⚓ Least squares (39 P)\n",
    "* ⚓ Matrix decompositions (1 C, 23 P)\n",
    "* * ⚓ Singular value decomposition (13 P)\n",
    "* ⚓ Matrix multiplication algorithms (4 P)\n",
    "* ⚓ Relaxation (iterative methods) (6 P)\n",
    "* ⚓ Sparse matrices (21 P)\n",
    "* Numerical linear algebra\n",
    "* ABS methods\n",
    "* Armadillo (C++ library)\n",
    "* Arnoldi iteration\n",
    "* Walter Edwin Arnoldi\n",
    "* Automatically Tuned Linear Algebra Software\n",
    "* Backfitting algorithm\n",
    "* Bareiss algorithm\n",
    "* Bartels–Stewart algorithm\n",
    "* Basic Linear Algebra Subprograms\n",
    "* Basis function\n",
    "* Biconjugate gradient method\n",
    "* Biconjugate gradient stabilized method\n",
    "* Bidiagonalization\n",
    "* BLIS (software)\n",
    "* Block Lanczos algorithm\n",
    "* Block matrix pseudoinverse\n",
    "* Block Wiedemann algorithm\n",
    "* Chebyshev iteration\n",
    "* Cholesky decomposition\n",
    "* Circulant matrix\n",
    "* Comparison of linear algebra libraries\n",
    "* Conjugate gradient method\n",
    "* Conjugate residual method\n",
    "* Convergent matrix\n",
    "* DADiSP\n",
    "* Data Analytics Library\n",
    "* Derivation of the conjugate gradient method\n",
    "* Diagonally dominant matrix\n",
    "* DIIS\n",
    "* Divide-and-conquer eigenvalue algorithm\n",
    "* Dune (software)\n",
    "* Eigenmode expansion\n",
    "* Eigenvalue algorithm\n",
    "* Eigenvalue perturbation\n",
    "* EISPACK\n",
    "* Fangcheng (mathematics)\n",
    "* Folded spectrum method\n",
    "* Frontal solver\n",
    "* Gauss–Seidel method\n",
    "* Gaussian elimination\n",
    "* Generalized minimal residual method\n",
    "* Givens rotation\n",
    "* GotoBLAS\n",
    "* Gradient method\n",
    "* GraphBLAS\n",
    "* Hilbert matrix\n",
    "* Householder operator\n",
    "* Householder transformation\n",
    "* Hypre\n",
    "* ILNumerics\n",
    "* In-place matrix transposition\n",
    "* Incomplete Cholesky factorization\n",
    "* Incomplete LU factorization\n",
    "* Interpolative decomposition\n",
    "* Inverse iteration\n",
    "* Iterative refinement\n",
    "* Jacobi eigenvalue algorithm\n",
    "* Jacobi method\n",
    "* Jacobi method for complex Hermitian matrices\n",
    "* Jacobi rotation\n",
    "* Julia (programming language)\n",
    "* Kaczmarz method\n",
    "* Kernel (linear algebra)\n",
    "* Krylov subspace\n",
    "* Lanczos algorithm\n",
    "* LAPACK\n",
    "* Numerical methods for linear least squares\n",
    "* Least-squares spectral analysis\n",
    "* Librsb\n",
    "* LINPACK\n",
    "* Lis (linear algebra library)\n",
    "* LOBPCG\n",
    "* Low-rank approximation\n",
    "* LU decomposition\n",
    "* LU reduction\n",
    "* Mathcad\n",
    "* MATLAB\n",
    "* Matrix multiplication\n",
    "* Frobenius inner product\n",
    "* Matrix multiplication algorithm\n",
    "* Matrix splitting\n",
    "* Matrix-free methods\n",
    "* Method of Four Russians\n",
    "* Minimum degree algorithm\n",
    "* MINRES\n",
    "* Modal analysis using FEM\n",
    "* Modified Richardson iteration\n",
    "* Moore–Penrose inverse\n",
    "* Nested dissection\n",
    "* OpenBLAS\n",
    "* Pivot element\n",
    "* Portable, Extensible Toolkit for Scientific Computation\n",
    "* Power iteration\n",
    "* Preconditioner\n",
    "* Pseudospectrum\n",
    "* QR algorithm\n",
    "* QR decomposition\n",
    "* Rayleigh quotient iteration\n",
    "* Relaxation (iterative method)\n",
    "* Row echelon form\n",
    "* RRQR factorization\n",
    "* Rybicki Press algorithm\n",
    "* Samuelson–Berkowitz algorithm\n",
    "* SequenceL\n",
    "* Singular value decomposition\n",
    "* SLEPc\n",
    "* Sparse approximation\n",
    "* Speakeasy (computational environment)\n",
    "* SPIKE algorithm\n",
    "* Stieltjes matrix\n",
    "* Stone's method\n",
    "* Successive over-relaxation\n",
    "* Symmetric successive over-relaxation\n",
    "* System of linear equations\n",
    "* Triangular matrix\n",
    "* Tridiagonal matrix algorithm\n",
    "* Vandermonde matrix\n",
    "* Wilkinson matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [☔](https://en.wikipedia.org/wiki/Category:Optimization_algorithms_and_methods) [**Optimization algorithms and methods**](https://en.wikipedia.org/wiki/List_of_algorithms)<br/>(*Algorithmes et méthodes d'optimisation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ⚓ Decomposition methods (8 P)\n",
    "* ⚓ Dynamic programming (45 P)\n",
    "* ⚓ Evolutionary algorithms (4 C, 44 P, 2 F)\n",
    "* * ⚓ Gene expression programming (1 P)\n",
    "* * ⚓ Genetic algorithms (2 C, 43 P)\n",
    "* * * ⚓ Artificial immune systems (5 P)\n",
    "* * * ⚓ Gene expression programming (1 P)\n",
    "* * ⚓ Genetic programming (14 P)\n",
    "* * ⚓ Nature-inspired metaheuristics (20 P)\n",
    "* ⚓ Exchange algorithms (10 P)\n",
    "* ⚓ Gradient methods (18 P)\n",
    "* ⚓ Least squares (39 P)\n",
    "* ⚓ Linear programming (1 C, 56 P)\n",
    "* * ⚓ Polyhedra (23 C, 186 P)\n",
    "* ⚓ Metaheuristics (3 C, 14 P)\n",
    "* * ⚓ Artificial immune systems (5 P)\n",
    "* * ⚓ Evolutionary algorithms (4 C, 44 P, 2 F)\n",
    "* * * ⚓ Gene expression programming (1 P)\n",
    "* * * ⚓ Genetic algorithms (2 C, 43 P)\n",
    "* * * ⚓ Genetic programming (14 P)\n",
    "* * * ⚓ Nature-inspired metaheuristics (20 P)\n",
    "* ⚓ Optimal scheduling (23 P)\n",
    "* List of algorithms\n",
    "* Active-set method\n",
    "* Adaptive coordinate descent\n",
    "* Adaptive dimensional search\n",
    "* Adaptive simulated annealing\n",
    "* Affine scaling\n",
    "* Alpha–beta pruning\n",
    "* Ant colony optimization algorithms\n",
    "* Auction algorithm\n",
    "* Augmented Lagrangian method\n",
    "* Automatic label placement\n",
    "* Backtracking line search\n",
    "* Bacterial colony optimization\n",
    "* Basin-hopping\n",
    "* Benson's algorithm\n",
    "* Berndt–Hall–Hall–Hausman algorithm\n",
    "* Bin covering problem\n",
    "* Bin packing problem\n",
    "* Bland's rule\n",
    "* Branch and bound\n",
    "* Branch and cut\n",
    "* Branch and price\n",
    "* Bregman Lagrangian\n",
    "* Bregman method\n",
    "* Broyden–Fletcher–Goldfarb–Shanno algorithm\n",
    "* CMA-ES\n",
    "* Column generation\n",
    "* Communication-avoiding algorithm\n",
    "* Constructive heuristic\n",
    "* Crew scheduling\n",
    "* Criss-cross algorithm\n",
    "* Critical line method\n",
    "* Cross-entropy method\n",
    "* Cunningham's rule\n",
    "* Cutting-plane method\n",
    "* DATADVANCE\n",
    "* Davidon–Fletcher–Powell formula\n",
    "* Derivation of the conjugate gradient method\n",
    "* Derivative-free optimization\n",
    "* Destination dispatch\n",
    "* Divide-and-conquer algorithm\n",
    "* Dykstra's projection algorithm\n",
    "* Dynamic programming\n",
    "* Envy minimization\n",
    "* Evolutionary algorithm\n",
    "* Evolutionary programming\n",
    "* Exact algorithm\n",
    "* Expectation–maximization algorithm\n",
    "* Extremal optimization\n",
    "* Fernandez's method\n",
    "* Fireworks algorithm\n",
    "* Fly algorithm\n",
    "* Fourier–Motzkin elimination\n",
    "* Fractional programming\n",
    "* Frank–Wolfe algorithm\n",
    "* Gauss–Newton algorithm\n",
    "* Generalized iterative scaling\n",
    "* Genetic algorithms in economics\n",
    "* Genetic improvement (computer science)\n",
    "* Golden-section search\n",
    "* Gradient descent\n",
    "* Gradient method\n",
    "* Graduated optimization\n",
    "* Great deluge algorithm\n",
    "* Greedy algorithm\n",
    "* Greedy triangulation\n",
    "* Guided local search\n",
    "* Guillotine cutting\n",
    "* Guillotine partition\n",
    "* HiGHS optimization solver\n",
    "* Hyper-heuristic\n",
    "* In-crowd algorithm\n",
    "* Interior-point method\n",
    "* Interval contractor\n",
    "* IOSO\n",
    "* IPOPT\n",
    "* Iterated conditional modes\n",
    "* Iterated local search\n",
    "* Kantorovich theorem\n",
    "* Karmarkar's algorithm\n",
    "* Killer heuristic\n",
    "* Learning rate\n",
    "* Least squares\n",
    "* Least-squares spectral analysis\n",
    "* Lemke's algorithm\n",
    "* Level-set method\n",
    "* Levenberg–Marquardt algorithm\n",
    "* Limited-memory BFGS\n",
    "* Line search\n",
    "* Linear-fractional programming\n",
    "* Lloyd's algorithm\n",
    "* Local convergence\n",
    "* Local search (optimization)\n",
    "* Luus–Jaakola\n",
    "* Matheuristics\n",
    "* Matrix chain multiplication\n",
    "* Maximum subarray problem\n",
    "* MCS algorithm\n",
    "* Mehrotra predictor–corrector method\n",
    "* Minimax\n",
    "* Mirror descent\n",
    "* MM algorithm\n",
    "* Multiple subset sum\n",
    "* Natural evolution strategy\n",
    "* Negamax\n",
    "* Nelder–Mead method\n",
    "* Network simplex algorithm\n",
    "* Newton's method\n",
    "* Newton's method in optimization\n",
    "* Nonlinear conjugate gradient method\n",
    "* Nonlinear programming\n",
    "* Odds algorithm\n",
    "* OR-Tools\n",
    "* Ordered subset expectation maximization\n",
    "* Parallel metaheuristic\n",
    "* Parametric programming\n",
    "* Pattern search (optimization)\n",
    "* Penalty method\n",
    "* Powell's dog leg method\n",
    "* Powell's method\n",
    "* PSeven\n",
    "* Quadratic programming\n",
    "* Quantum annealing\n",
    "* Quasi-Newton method\n",
    "* Random optimization\n",
    "* Random search\n",
    "* Robust fuzzy programming\n",
    "* Rosenbrock methods\n",
    "* Ruzzo–Tompa algorithm\n",
    "* Search-based software engineering\n",
    "* Second-order cone programming\n",
    "* Semidefinite embedding\n",
    "* Sequential linear-quadratic programming\n",
    "* Sequential minimal optimization\n",
    "* Sequential quadratic programming\n",
    "* Simplex algorithm\n",
    "* Simulated annealing\n",
    "* Simultaneous perturbation stochastic approximation\n",
    "* Social cognitive optimization\n",
    "* Space allocation problem\n",
    "* Space mapping\n",
    "* Special ordered set\n",
    "* Spiral optimization algorithm\n",
    "* Stochastic dynamic programming\n",
    "* Stochastic gradient Langevin dynamics\n",
    "* Stochastic hill climbing\n",
    "* Stochastic programming\n",
    "* Subgradient method\n",
    "* Successive linear programming\n",
    "* Successive parabolic interpolation\n",
    "* Symmetric rank-one\n",
    "* Ternary search\n",
    "* Tree rearrangement\n",
    "* Truncated Newton method\n",
    "* Trust region\n",
    "* Very large-scale neighborhood search\n",
    "* Zadeh's rule\n",
    "* Zionts–Wallenius method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

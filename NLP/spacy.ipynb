{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spacy**\n",
    "\n",
    "Pour ne pas tomber dans le piège de la monolib comme pour SKL ou beautifulsoup.\n",
    "\n",
    "https://spacy.io/\n",
    "\n",
    "Un premier sprint de découverte de 20 minutes\n",
    "\n",
    "Il y a aussi une lib plus 'recherche' alternative à NLTK, [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)\n",
    "\n",
    "https://spacy.io/usage/models#languages : à l'air plus 'fr' que NLTK\n",
    "\n",
    "Le tokeniseur est adaptable : https://spacy.io/usage/linguistic-features#tokenization\n",
    "\n",
    "https://spacy.io/usage/visualizers : un sacré +\n",
    "\n",
    "A poursuivre..\n",
    "\n",
    "J'en suis à la présentation des features : Named Entities (entités du monde réel)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [get started](https://spacy.io/usage/spacy-101)\n",
    "\n",
    "Il y a un cours : https://course.spacy.io/en/\n",
    "\n",
    "4 chapitres\n",
    "\n",
    "Chapter 1: Finding words, phrases, names and concepts\n",
    "\n",
    "This chapter will introduce you to the basics of text processing with spaCy. You'll learn about the data structures, how to work with trained pipelines, and how to use them to predict linguistic features in your text.\n",
    "\n",
    "Chapter 2: Large-scale data analysis with spaCy\n",
    "\n",
    "In this chapter, you'll use your new skills to extract specific information from large volumes of text. You'll learn how to make the most of spaCy's data structures, and how to effectively combine statistical and rule-based approaches for text analysis.\n",
    "\n",
    "Chapter 3: Processing Pipelines\n",
    "\n",
    "This chapter will show you everything you need to know about spaCy's processing pipeline. You'll learn what goes on under the hood when you process a text, how to write your own components and add them to the pipeline, and how to use custom attributes to add your own metadata to the documents, spans and tokens.\n",
    "\n",
    "Chapter 4: Training a neural network model\n",
    "\n",
    "In this chapter, you'll learn how to update spaCy's statistical models to customize them for your use case – for example, to predict a new entity type in online comments. You'll train your own model from scratch, and understand the basics of how training works, along with tips and tricks that can make your custom NLP projects more successful.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

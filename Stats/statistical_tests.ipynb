{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tests statistiques**\n",
    "\n",
    "**Note** :\n",
    "* Déclencheur du besoin d'une synthèse sur les tests statistiques : besoin de reproduire `sm.summary` dans le cadre de la feature importance sur les OLS SKL.\n",
    "* Je me suis rendu compte à quel point je maîtrisais mal les mesures essentielles mobilisées par `summary`, comme la $p$-value ou le $t$-test de Student.\n",
    "\n",
    "**Pré-requis** (renvoie à un autre NB) :\n",
    "* https://en.wikipedia.org/wiki/Variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test d'hypothèses statistiques\n",
    "\n",
    "https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test de Fisher d'égalité de deux variances** (*$F$-test of equality of variances*)\n",
    "\n",
    "**Wikipedia** : [**$F$-test of equality of variances**](https://en.wikipedia.org/wiki/F-test_of_equality_of_variances) ([*Test de Fisher d'égalité de deux variances*](https://fr.wikipedia.org/wiki/Test_de_Fisher_d%27%C3%A9galit%C3%A9_de_deux_variances))\n",
    "\n",
    "En statistique, un $F$-test d'égalité des variances est un [**test d'hypothèse statistique**](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) pour l'[**hypothèse nulle**](https://en.wikipedia.org/wiki/Null_hypothesis) selon laquelle deux populations normales ont la même variance.\n",
    "\n",
    "Théoriquement, tout [test F](https://en.wikipedia.org/wiki/F-test) peut être considéré comme une comparaison de deux variances, mais le cas spécifique discuté dans cet article est celui de deux populations, où la statistique de test utilisée est le rapport de deux [variances d'échantillon](https://en.wikipedia.org/wiki/Variance#Sample_variance).[1] Cette situation particulière est importante en [statistique mathématique](https://en.wikipedia.org/wiki/Mathematical_statistics) car elle fournit un cas exemplaire de base dans lequel la [distribution F](https://en.wikipedia.org/wiki/F-distribution) peut être dérivée. Pour l'application dans les [statistiques appliquées](https://en.wikipedia.org/wiki/Statistics#Applications), on craint que le test soit si sensible à l'hypothèse de normalité qu'il serait déconseillé de l'utiliser comme test de routine pour l'égalité des variances. En d'autres termes, il s'agit d'un cas où la \"normalité approximative\" (qui, dans des contextes similaires, serait souvent justifiée en utilisant le [théorème central limite](https://en.wikipedia.org/wiki/Central_limit_theorem)), n'est pas assez bonne pour rendre la procédure de test approximativement valide à un degré acceptable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le test\n",
    "\n",
    "Soient $X_1, \\cdots, X_n$ et $Y_1, \\cdots, Y_m$ des échantillons [indépendants et identiquement distribués (iid)](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) de deux populations ayant chacune une [distribution normale](https://en.wikipedia.org/wiki/Normal_distribution). Les [valeurs attendues](https://en.wikipedia.org/wiki/Expected_value) pour les deux populations peuvent être différentes, et l'hypothèse à tester est que les variances sont égales. Soient\n",
    "\n",
    "$\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$ et $\\overline{Y} = \\frac{1}{m}\\sum_{i=1}^m Y_i$\n",
    "\n",
    "les [moyennes des échantillons](https://en.wikipedia.org/wiki/Sample_mean_and_covariance). Soient\n",
    "\n",
    "$S_X^2 = \\frac{1}{n-1}\\sum_{i=1}^n \\left(X_i - \\overline{X}\\right)^2$ et $S_Y^2 = \\frac{1}{m-1}\\sum_{i=1}^m \\left(Y_i - \\overline{Y}\\right)^2$\n",
    "\n",
    "les [variances des échantillons](https://en.wikipedia.org/wiki/Variance#Sample_variance). Alors la statistique de test\n",
    "\n",
    "$F = \\frac{S_X^2}{S_Y^2}$\n",
    "\n",
    "a une [$F$-distribution](https://en.wikipedia.org/wiki/F-distribution) avec $n − 1$ et $m − 1$ degrés de liberté si l'[hypothèse nulle](https://en.wikipedia.org/wiki/Null_hypothesis) d'égalité des variances est vraie. Sinon, il suit une distribution $F$ mise à l'échelle par le rapport des variances vraies. L'hypothèse nulle est rejetée si $F$ est trop grand ou trop petit en fonction du niveau alpha souhaité (c'est-à-dire la [signification statistique](https://en.wikipedia.org/wiki/Statistical_significance))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propriétés\n",
    "\n",
    "Ce F-test est connu pour être extrêmement sensible à la [non-normalité](https://en.wikipedia.org/wiki/Normal_distribution) [3] [4], ce qui fait des [test de Levene](https://en.wikipedia.org/wiki/Levene%27s_test), [test de Bartlett](https://en.wikipedia.org/wiki/Bartlett%27s_test) ou [test de Brown-Forsythe](https://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test) de meilleurs tests pour d'égalité de deux variances. (Cependant, tous ces tests créent des inflations d'[erreurs expérimentales de type I](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Type_I_error) lorsqu'ils sont effectués comme test de l'hypothèse d'[homoscédasticité](https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity) avant un test des effets. [5]) Les tests F pour l'égalité des variances peuvent être utilisés dans la pratique, avec précaution, notamment lorsqu'une vérification rapide est requise, et sous réserve d'une vérification diagnostique associée : des manuels pratiques[6] proposent des vérifications à la fois graphiques et formelles de l'hypothèse.\n",
    "\n",
    "Les [tests F](https://en.wikipedia.org/wiki/F-test) sont utilisés pour d'autres [tests statistiques d'hypothèses](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing), tels que le test des différences de moyennes dans trois groupes ou plus, ou dans des schémas factoriels. Ces tests F ne sont généralement pas [robustes](https://en.wikipedia.org/wiki/Robust_statistics) lorsqu'il y a des violations de l'hypothèse selon laquelle chaque population suit la [distribution normale](https://en.wikipedia.org/wiki/Normal_distribution), en particulier pour les petits niveaux alpha et les mises en page déséquilibrées.[7] Cependant, pour les grands niveaux alpha (par exemple, au moins 0,05) et les mises en page équilibrées, le test F est relativement robuste, bien que (si l'hypothèse de normalité ne tient pas) il souffre d'une perte de puissance statistique comparative par rapport aux homologues non-paramétriques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Généralisation\n",
    "\n",
    "La généralisation immédiate du problème décrit ci-dessus concerne les situations où il y a plus de deux groupes ou populations, et l'hypothèse est que toutes les variances sont égales. C'est le problème traité par le [test de Hartley](https://en.wikipedia.org/wiki/Hartley%27s_test) et le [test de Bartlett](https://en.wikipedia.org/wiki/Bartlett%27s_test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voir également\n",
    "\n",
    "* [**Test de Goldfeld-Quandt**](https://en.wikipedia.org/wiki/Goldfeld%E2%80%93Quandt_test)\n",
    "* [**Test de Levene**](https://en.wikipedia.org/wiki/Levene%27s_test)\n",
    "* [**Test de Bartlett**](https://en.wikipedia.org/wiki/Bartlett%27s_test)\n",
    "* [**Test de Brown-Forsythe**](https://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Références\n",
    "\n",
    "1. Snedecor, George W. and Cochran, William G. (1989), *Statistical Methods*, Eighth Edition, Iowa State University Press.\n",
    "2. Johnson, N.L., Kotz, S., Balakrishnan, N. (1995) *Continuous Univariate Distributions*, Volume 2, Wiley. ISBN 0-471-58494-0 (Section 27.1)\n",
    "3. Box, G.E.P. (1953). \"*Non-Normality and Tests on Variances*\". Biometrika. 40 (3/4): 318–335. doi:10.1093/biomet/40.3-4.318. JSTOR 2333350.\n",
    "4. Markowski, Carol A; Markowski, Edward P. (1990). \"*Conditions for the Effectiveness of a Preliminary Test of Variance*\". The American Statistician. 44 (4): 322–326. doi:10.2307/2684360. JSTOR 2684360.\n",
    "5. Sawilowsky, S. (2002). \"*Fermat, Schubert, Einstein, and Behrens–Fisher:The Probable Difference Between Two Means When σ12 ≠ σ22*\", Journal of Modern Applied Statistical Methods, 1(2), 461–472.\n",
    "6. Rees, D.G. (2001) *Essential Statistics* (4th Edition), Chapman & Hall/CRC, ISBN 1-58488-007-4. Section 10.15\n",
    "7. Blair, R. C. (1981). \"*A reaction to 'Consequences of failure to meet assumptions underlying the fixed effects analysis of variance and covariance'*\". Review of Educational Research. 51 (4): 499–507. doi:10.3102/00346543051004499. S2CID 121873115."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catégories\n",
    "\n",
    "* [**Rapports statistiques**](https://en.wikipedia.org/wiki/Category:Statistical_ratios)\n",
    "* [**Tests statistiques**](https://en.wikipedia.org/wiki/Category:Statistical_tests)\n",
    "* [**Écart et dispersion statistiques**](https://en.wikipedia.org/wiki/Category:Statistical_deviation_and_dispersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test $t$ de Student** (*Student's $t$-test*)\n",
    "\n",
    "**Wikipedia** : [**Student's $t$-test**](https://en.wikipedia.org/wiki/Student's_t-test) ([*Test $t$ de Student*](https://fr.wikipedia.org/wiki/Test_de_Student))\n",
    "\n",
    "**Python** : [`scipy.stats.ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)\n",
    "\n",
    "Un test $t$ est un [**test d'hypothèse statistique**](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) dans lequel la [**statistique de test**](https://en.wikipedia.org/wiki/Test_statistic) suit une [**distribution $t$ de Student**](https://en.wikipedia.org/wiki/Student%27s_t-distribution) sous l'[**hypothèse nulle**](https://en.wikipedia.org/wiki/Null_hypothesis).\n",
    "\n",
    "Il est le plus souvent appliqué lorsque la statistique de test suivrait une [distribution normale](https://en.wikipedia.org/wiki/Normal_distribution) si la valeur d'un [terme d'échelle](https://en.wikipedia.org/wiki/Scale_parameter) dans la statistique de test était connue (généralement, le terme d'échelle est inconnu et donc un [paramètre de nuisance](https://en.wikipedia.org/wiki/Nuisance_parameter)). Lorsque le terme de mise à l'échelle est estimé sur la base des [données](https://en.wikipedia.org/wiki/Data), la statistique de test, sous certaines conditions, suit une distribution $t$ de Student. L'application la plus courante du test $t$ est de tester si les moyennes de deux populations sont différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histoire\n",
    "\n",
    "Le terme \"statistique $t$\" est l'abrégé de \"statistique de test d'hypothèse\".[1] En statistiques, la distribution $t$ a été dérivée pour la première fois en tant que [distribution postérieure](https://en.wikipedia.org/wiki/Posterior_probability) en 1876 par [Helmert](https://en.wikipedia.org/wiki/Friedrich_Robert_Helmert) [2] [3] [4] et [Lüroth](https://en.wikipedia.org/wiki/Jacob_L%C3%BCroth). [5] [6] [7] La distribution t est également apparue sous une forme plus générale en tant que [distribution de type IV de Pearson](https://en.wikipedia.org/wiki/Pearson_distribution) dans l'article de [Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson) de 1895.[8] Cependant, la distribution T, également connue sous le nom de [distribution t de Student](https://en.wikipedia.org/wiki/Student%27s_t-distribution), tire son nom de [William Sealy Gosset](https://en.wikipedia.org/wiki/William_Sealy_Gosset) qui l'a publiée pour la première fois en anglais en 1908 dans la revue scientifique [Biometrika](https://en.wikipedia.org/wiki/Biometrika) sous le pseudonyme \"Student\" [9] [10] parce que son employeur a préféré utiliser des pseudonymes lors de la publication d'articles scientifiques.[11] Gosset travaillait à la [brasserie Guinness](https://en.wikipedia.org/wiki/Guinness_Brewery) à Dublin, en Irlande, et s'intéressait aux problèmes des petits échantillons - par exemple, les propriétés chimiques de l'orge avec des échantillons de petite taille. D'où une deuxième version de l'étymologie du terme Student est que Guinness ne voulait pas que ses concurrents sachent qu'ils utilisaient le test t pour déterminer la qualité de la matière première (voir la [distribution t de Student](https://en.wikipedia.org/wiki/Student%27s_t-distribution) pour un historique détaillé de ce pseudonyme, qui ne doit pas être confondu avec le terme littéral étudiant). Bien que ce soit William Gosset d'après qui le terme \"Student\" est écrit, c'est en fait grâce au travail de Ronald Fisher que la distribution est devenue bien connue sous le nom de \"distribution de Student\"[12] et \"test t de Student\".\n",
    "\n",
    "Gosset avait été embauché en raison de la politique de Claude Guinness de recruter les meilleurs diplômés d'Oxford et de Cambridge pour appliquer la biochimie et les statistiques aux processus industriels de Guinness.[13] Gosset a conçu le test $t$ comme un moyen économique de surveiller la qualité de la [stout](https://en.wikipedia.org/wiki/Stout). Le travail de test $t$ a été soumis et accepté dans la revue [Biometrika](https://en.wikipedia.org/wiki/Biometrika) et publié en 1908.[14]\n",
    "\n",
    "Guinness avait pour politique d'autoriser le congé du personnel technique pour étudier (soi-disant «congé d'étude»), que Gosset a utilisé pendant les deux premiers trimestres de l'année universitaire 1906-1907 au laboratoire biométrique du professeur Karl Pearson à l'University College London. L'identité de Gosset était alors connue de ses collègues statisticiens et du rédacteur en chef Karl Pearson.[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usages\n",
    "\n",
    "Les tests $t$ les plus fréquemment utilisés sont les tests à un échantillon et à deux échantillons :\n",
    "\n",
    "* Un [test de localisation](https://en.wikipedia.org/wiki/Location_test) à un échantillon pour déterminer si la moyenne d'une population a une valeur spécifiée dans une [hypothèse nulle](https://en.wikipedia.org/wiki/Null_hypothesis).\n",
    "* Un test de localisation à deux échantillons de l'hypothèse nulle tel que les [moyennes](https://en.wikipedia.org/wiki/Expected_value) de deux populations sont égales. Tous ces tests sont généralement appelés **tests $t$ de Student**, bien qu'à proprement parler, ce nom ne doive être utilisé que si les [variances](https://en.wikipedia.org/wiki/Variance) des deux populations sont également supposées égales; la forme du test utilisé lorsque cette hypothèse est abandonnée est parfois appelée [test $t$ de Welch](https://en.wikipedia.org/wiki/Welch%27s_t-test). Ces tests sont souvent appelés tests t pour échantillons **non appariés** ou *indépendants*, car ils sont généralement appliqués lorsque les [unités statistiques](https://en.wikipedia.org/wiki/Statistical_unit) sous-jacentes aux deux échantillons comparés ne se chevauchent pas.[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèses ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
